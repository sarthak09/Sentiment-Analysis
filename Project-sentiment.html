<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>Project-sentiment</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Sentiment-Classification">Sentiment Classification<a class="anchor-link" href="#Sentiment-Classification">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note: I have used following steps in the project</p>
<ol>
<li>Import libs: This is I just imported libruary used in the project</li>
<li>Loading the dataset: This step is just data loading IMDB dataset step only with max vocabulary size and splitting it in train and test set which include dependent and independent variable</li>
<li>EDA: This step is used for exploring the dataset. Here I have crossed various dateset like vaocab size, unique values of the target variable and also used visualization techniques, seen the average sequence length of the dataset, Standard deviation as well. These step helped me to decide max sequence padding length for padding  </li>
<li>word embedding: In this step I have prepared word to index dictionary, index to word dictionary and words list. Also In this I have made a function so to translate the sequence back to words using above dictionary.</li>
<li>Model building: Here I have made various model starting with normal neural network model with sequence length of 20 but this model was overfitting, Then I made the same model with sequence length of 300, Then I have done grid search on this model and made final model with improved parameter with sequence length of 300 but here also it was overfitting. Then I have made an LSTM model without pretrained embeddings as this model was underperforming from before models thus I decided to make an LSTM model with pretrained GLOVE embedding, Here I have used GLOVE 100 which encodes each words with 100 embedding dimension.</li>
</ol>
<p>NOTE I have shown predictions, performance evaluation, performance graph and AUC curve for LSTM with pretrained glove and for normal NN with imporved hyperparameter</p>
<ol>
<li>Output: Here based on above model I have shown the output of each layer and the shape of each layer for 2 different model i.e Final normal model after grid search and LSTM with GLove vector</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Import-libs">Import libs<a class="anchor-link" href="#Import-libs">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Importing libs</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">GlobalMaxPool1D</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="k">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span>  <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ReduceLROnPlateau</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span><span class="p">,</span><span class="n">classification_report</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">,</span><span class="n">precision_score</span><span class="p">,</span><span class="n">recall_score</span><span class="p">,</span><span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="k">import</span> <span class="n">imdb</span>
<span class="kn">from</span> <span class="nn">keras.wrappers.scikit_learn</span> <span class="k">import</span> <span class="n">KerasClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_predict</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">GlobalMaxPool1D</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Loading-the-dataset">Loading the dataset<a class="anchor-link" href="#Loading-the-dataset">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Initialize variables</span>
<span class="n">MAX_VOCAB</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">EMBEDDING_DIM</span><span class="o">=</span><span class="mi">50</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Loading of preprocessed movie review dataset with vocal size 10000 </span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">MAX_VOCAB</span><span class="p">)</span> <span class="c1"># vocab_size is no.of words to consider from the dataset, ordering based on frequency.</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Printing important information about the loaded dataset into train and test</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train data length = &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train label length = &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data length = &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test label length = &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train data type = &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train label type = &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data type = &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test label type = &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train data shape = &quot;</span><span class="p">,</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train label shape = &quot;</span><span class="p">,</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data shape = &quot;</span><span class="p">,</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test label shape = &quot;</span><span class="p">,</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train data length =  25000
Train label length =  25000
Test data length =  25000
Test label length =  25000


Train data type =  &lt;class &#39;numpy.ndarray&#39;&gt;
Train label type =  &lt;class &#39;numpy.ndarray&#39;&gt;
Test data type =  &lt;class &#39;numpy.ndarray&#39;&gt;
Test label type =  &lt;class &#39;numpy.ndarray&#39;&gt;


Train data shape =  (25000,)
Train label shape =  (25000,)
Test data shape =  (25000,)
Test label shape =  (25000,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Seeing value in train set to see if everything is correct</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Seeing value in test set to see if everything is correct</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_test</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[1, 40, 49, 85, 84, 1040, 146, 6, 783, 254, 4386, 337, 5, 13, 447, 14, 500, 10, 10, 14, 500, 517, 1076, 357, 21, 1684, 72, 45, 290, 12, 17, 515, 17, 25, 380, 129, 3305, 4, 2191, 26, 253, 5, 2, 36, 80, 4357, 25, 2, 129, 330, 505, 8, 2, 146, 24, 3988, 14, 500, 9, 82, 2, 5, 9, 1293, 224, 10, 10, 8, 401, 14, 1361, 879, 13, 28, 8, 401, 61, 1642, 2925, 44, 1373, 21, 591, 353, 14, 500, 4092, 30, 290, 12, 10, 10, 65, 790, 790, 206, 158, 300, 45, 15, 52, 2, 158, 692, 2, 158, 856, 158]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="EDA">EDA<a class="anchor-link" href="#EDA">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print max value( max vocabulary value not vocalbulary size) in train set and printing max seq that any review can have</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum value of a word index &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">max</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">x_train</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum length num words of review in train &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">x_train</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Maximum value of a word index 
9999
Maximum length num words of review in train 
2494
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print max value( max vocabulary value not vocalbulary size) in test set and printing max seq that any review can have</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum value of a word index &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">max</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">x_test</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum length num words of review in train &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">x_test</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Maximum value of a word index 
9999
Maximum length num words of review in train 
2315
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#print number of classes in target variable for both train and test set</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total classes in test =&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total classes in train = &quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Total classes in test = [0 1]
Total classes in train =  [0 1]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#To see number of words in both test and train set</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of words in train = &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">x_train</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of words in test =&quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">x_test</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Total number of words in train =  9998
Total number of words in test = 9951
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Visualize-step">Visualize step<a class="anchor-link" href="#Visualize-step">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Visualize step</span>
<span class="c1"># Summarize review length for train</span>
<span class="c1">#This cell shows how long each review is and based on that it give mean and std of lenght of each sequence</span>
<span class="c1">#For train set</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Review length: &quot;</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_train</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean </span><span class="si">%.2f</span><span class="s2"> words (</span><span class="si">%f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">result</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">result</span><span class="p">)))</span>
<span class="c1"># plot review length</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">#Here you can see mean is 238.71 and std 176.49</span>
<span class="c1">#This helps us to decide best sequence length</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Review length: 
Mean 238.71 words (176.493674)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Visualize step</span>
<span class="c1"># Summarize review length for train</span>
<span class="c1">#This cell shows how long each review is and based on that it give mean and std of lenght of each sequence</span>
<span class="c1">#For train set</span>
<span class="n">result</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_test</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean </span><span class="si">%.2f</span><span class="s2"> words (</span><span class="si">%f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">result</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">result</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">#Here you can see mean is 230.80 and std 169.16</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mean 230.80 words (169.161087)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="word-embedding">word embedding<a class="anchor-link" href="#word-embedding">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Load original word to index dictionary</span>
<span class="n">voca</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">voca</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;dict&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Getting words into list this gives index to word mapping where each index has a word in that position</span>
<span class="c1">#This list has all the words that we want</span>
<span class="c1">#This has all the words in the dictionary</span>
<span class="c1">#words=[&#39;&lt;PAD&gt;&#39;,&#39;&lt;START&gt;&#39;,&#39;&lt;UNK&gt;&#39;,&#39;&lt;UNUSED&gt;&#39;]</span>
<span class="n">count</span><span class="o">=</span><span class="mi">0</span>
<span class="n">words</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">voca</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">voca</span><span class="o">.</span><span class="n">get</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">count</span><span class="o">&lt;=</span><span class="n">MAX_VOCAB</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="n">count</span><span class="o">+=</span><span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check steps</span>
<span class="c1">#print words in that index</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>the
and
a
of
to
beaver
approved


10000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#This steps has all the word to index original mapping but only till vocab size i.e 10000 and they are stored in variable word2idx</span>
<span class="c1">#This step also stores index values i.e numbers from 1 to 10000</span>
<span class="n">count</span><span class="o">=</span><span class="mi">0</span>
<span class="n">word2idx</span><span class="o">=</span><span class="p">{}</span>
<span class="n">index</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">voca</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">&lt;=</span><span class="n">MAX_VOCAB</span><span class="p">:</span>  <span class="c1">#Here it is leass or equal because index starts from 1 as 0 is a special character </span>
        <span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">j</span><span class="o">+</span><span class="mi">3</span>   <span class="c1">#Here it is storing dict based on above vocab size condition but with plus 3 as from 0 to 3 are storing special character</span>
        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span>

<span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;&lt;PAD&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># This is special character for padding</span>
<span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;&lt;START&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1">#Start od sequence</span>
<span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># unknown</span>
<span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;&lt;UNUSED&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
    
<span class="c1">#Note first 4 are used for special chacter and it starts from 4 </span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#This is reverse mapping of word to index</span>
<span class="c1">#This is dictionary off index to word where key = value and value = word</span>

<span class="n">idx2word</span><span class="o">=</span><span class="p">{</span><span class="n">j</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">word2idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step where 1st statement i.e word2idx returns value of 2nd dict i.e idx2word and 2nd statement idx2word return 1st dict i.e word2idx value</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;approved&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">idx2word</span><span class="p">[</span><span class="mi">10003</span><span class="p">])</span>

<span class="c1">#value of second should match index of 1st</span>

<span class="c1">#Note here len is 10003 because first few are speacial character in these dictionay</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>10003
approved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check steps which tell if we are doing things right</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word2idx</span><span class="p">))</span> <span class="c1">#This tells us that our max value is 10004 where first 4 are special words</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>10004
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see index value of &quot;and&quot; word</span>
<span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;and&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>5</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step which compare data from word(list) and word2idx(dict)</span>
<span class="c1">#Here I am seeing when i provide i to specific condition word2idx should return some value and on next step if I supply that word it should return the same index</span>
<span class="k">for</span> <span class="n">i</span> <span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">voca</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Word corresponds to 0 index = &quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1">#This should be 0 as 0 corresponds to special word</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We got same word with value = &quot;</span><span class="p">,</span><span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Word corresponds to 3 index = &quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1">#Most common word</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We got same word with value = &quot;</span><span class="p">,</span><span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Word corresponds to 5 index = &quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1">#2nd most common word</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We got same word with value = &quot;</span><span class="p">,</span><span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Word corresponds to 6 index = &quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1">#3rd most common word</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We got same word with value = &quot;</span><span class="p">,</span><span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">10000</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Word corresponds to 10003 index = &quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1">#Last word</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We got same word with value = &quot;</span><span class="p">,</span><span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
<span class="c1">#Note first 4 values are special words</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Word corresponds to 6 index =  a
We got same word with value =  6


Word corresponds to 10003 index =  approved
We got same word with value =  10003


Word corresponds to 3 index =  the
We got same word with value =  4


Word corresponds to 5 index =  and
We got same word with value =  5


</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see word to index mapping</span>
<span class="n">word2idx</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;woods&#39;: 1411,
 &#39;hanging&#39;: 2348,
 &#39;woody&#39;: 2292,
 &#39;arranged&#39;: 6749,
 &#39;bringing&#39;: 2341,
 &#39;wooden&#39;: 1639,
 &#39;errors&#39;: 4013,
 &#39;dialogs&#39;: 3233,
 &#39;kids&#39;: 362,
 &#39;uplifting&#39;: 5037,
 &#39;controversy&#39;: 7096,
 &#39;projection&#39;: 9881,
 &#39;stern&#39;: 7183,
 &#39;morally&#39;: 5624,
 &#39;wang&#39;: 5286,
 &#39;want&#39;: 181,
 &#39;travel&#39;: 2106,
 &#39;barbra&#39;: 6705,
 &#39;dinosaurs&#39;: 3933,
 &#39;wrong&#39;: 355,
 &#39;subplots&#39;: 4763,
 &#39;welcomed&#39;: 9095,
 &#39;butcher&#39;: 6706,
 &#39;fit&#39;: 1183,
 &#39;screaming&#39;: 1930,
 &#39;fix&#39;: 4290,
 &#39;hurting&#39;: 9657,
 &#39;effects&#39;: 302,
 &#39;barton&#39;: 8778,
 &#39;ingrid&#39;: 6195,
 &#39;adapt&#39;: 7919,
 &#39;disturbed&#39;: 4014,
 &#39;purpose&#39;: 1288,
 &#39;olds&#39;: 6795,
 &#39;needed&#39;: 887,
 &#39;master&#39;: 1300,
 &#39;positively&#39;: 5402,
 &#39;zatoichi&#39;: 9839,
 &#39;feeling&#39;: 547,
 &#39;affairs&#39;: 5625,
 &#39;wholesome&#39;: 7802,
 &#39;cinematic&#39;: 1360,
 &#39;tech&#39;: 4991,
 &#39;saying&#39;: 660,
 &#39;padded&#39;: 8425,
 &#39;tempted&#39;: 5748,
 &#39;plate&#39;: 7479,
 &#39;altogether&#39;: 3902,
 &#39;lds&#39;: 8779,
 &#39;nicely&#39;: 1780,
 &#39;mummy&#39;: 4591,
 &#39;lots&#39;: 775,
 &#39;lotr&#39;: 9262,
 &#39;irs&#39;: 9882,
 &#39;ira&#39;: 6890,
 &#39;discipline&#39;: 7696,
 &#39;nature&#39;: 876,
 &#39;superficial&#39;: 3903,
 &#39;extent&#39;: 2826,
 &#39;bothers&#39;: 8780,
 &#39;much&#39;: 76,
 &#39;spit&#39;: 6262,
 &#39;arkin&#39;: 7367,
 &#39;doubts&#39;: 4992,
 &#39;spin&#39;: 3087,
 &#39;hong&#39;: 2579,
 &#39;academic&#39;: 9097,
 &#39;corporate&#39;: 4452,
 &#39;hal&#39;: 4314,
 &#39;ham&#39;: 4895,
 &#39;had&#39;: 69,
 &#39;has&#39;: 47,
 &#39;hat&#39;: 2404,
 &#39;crowd&#39;: 2293,
 &#39;crown&#39;: 6630,
 &#39;bottom&#39;: 1324,
 &#39;starring&#39;: 1184,
 &#39;marshall&#39;: 5343,
 &#39;honeymoon&#39;: 9098,
 &#39;shoots&#39;: 3234,
 &#39;fabric&#39;: 8292,
 &#39;raped&#39;: 3540,
 &#39;rapes&#39;: 8929,
 &#34;else&#39;s&#34;: 5927,
 &#39;martian&#39;: 7256,
 &#39;passenger&#39;: 9460,
 &#39;disgrace&#39;: 6044,
 &#39;barrymore&#39;: 5123,
 &#39;cambodia&#39;: 9883,
 &#39;palma&#39;: 5561,
 &#39;explosions&#39;: 3978,
 &#39;loren&#39;: 8062,
 &#39;shootout&#39;: 6707,
 &#39;chain&#39;: 3629,
 &#39;whoever&#39;: 2500,
 &#39;chair&#39;: 3039,
 &#39;ballet&#39;: 4520,
 &#39;macho&#39;: 5626,
 &#39;jerk&#39;: 3399,
 &#39;gloomy&#39;: 7368,
 &#39;locked&#39;: 2897,
 &#39;exact&#39;: 2591,
 &#39;minute&#39;: 786,
 &#39;celebrated&#39;: 6541,
 &#39;unintentionally&#39;: 3386,
 &#39;climbs&#39;: 9099,
 &#39;honour&#39;: 9658,
 &#39;address&#39;: 5517,
 &#39;benson&#39;: 9461,
 &#39;cusack&#39;: 3843,
 &#39;opposed&#39;: 3630,
 &#39;following&#39;: 1045,
 &#39;convincingly&#39;: 4521,
 &#39;surfing&#39;: 4255,
 &#39;jim&#39;: 1240,
 &#39;quarter&#39;: 6542,
 &#39;entering&#39;: 6263,
 &#39;seriously&#39;: 615,
 &#39;raunchy&#39;: 7820,
 &#39;grandma&#39;: 7097,
 &#39;modest&#39;: 6111,
 &#39;spoken&#39;: 2850,
 &#39;concert&#39;: 3252,
 &#39;lingering&#39;: 8427,
 &#39;snatch&#39;: 9100,
 &#34;miyazaki&#39;s&#34;: 9263,
 &#39;wandering&#39;: 4635,
 &#39;turned&#39;: 679,
 &#39;turner&#39;: 3768,
 &#39;opposite&#39;: 1961,
 &#39;grateful&#39;: 6089,
 &#39;inconsistent&#39;: 5562,
 &#39;imagined&#39;: 3792,
 &#39;enthralled&#39;: 9884,
 &#39;tsui&#39;: 8599,
 &#39;menacing&#39;: 3541,
 &#39;convoluted&#39;: 3660,
 &#39;millionaire&#39;: 5288,
 &#39;west&#39;: 1263,
 &#39;motives&#39;: 4204,
 &#39;photos&#39;: 4453,
 &#39;unlikeable&#39;: 6112,
 &#39;technology&#39;: 2131,
 &#39;otto&#39;: 6988,
 &#39;visually&#39;: 2009,
 &#39;being&#39;: 112,
 &#39;grounded&#39;: 9355,
 &#39;excuses&#39;: 6878,
 &#39;sums&#39;: 5289,
 &#39;traffic&#39;: 5847,
 &#39;sensational&#39;: 8428,
 &#39;satisfactory&#39;: 8781,
 &#39;substance&#39;: 2327,
 &#39;thailand&#39;: 7697,
 &#39;hopkins&#39;: 5677,
 &#39;sealed&#39;: 9659,
 &#39;brazilian&#39;: 8063,
 &#39;bubble&#39;: 6708,
 &#39;wits&#39;: 9264,
 &#39;societal&#39;: 9660,
 &#39;with&#39;: 19,
 &#39;abused&#39;: 5233,
 &#39;rage&#39;: 3980,
 &#39;tripe&#39;: 5174,
 &#39;dirty&#39;: 1641,
 &#39;watches&#39;: 3631,
 &#39;watcher&#39;: 7579,
 &#39;ensuing&#39;: 9885,
 &#39;watched&#39;: 296,
 &#39;cream&#39;: 5234,
 &#39;waving&#39;: 9265,
 &#39;natalie&#39;: 6264,
 &#39;tricks&#39;: 3351,
 &#39;caused&#39;: 2164,
 &#39;beware&#39;: 5518,
 &#39;causes&#39;: 2906,
 &#39;nora&#39;: 8782,
 &#39;norm&#39;: 5797,
 &#39;sans&#39;: 9462,
 &#39;sang&#39;: 6796,
 &#39;sand&#39;: 6439,
 &#39;sane&#39;: 7921,
 &#39;leia&#39;: 9886,
 &#39;portrays&#39;: 2235,
 &#39;traumatized&#39;: 9266,
 &#39;more&#39;: 53,
 &#39;company&#39;: 1169,
 &#39;learn&#39;: 850,
 &#39;knocked&#39;: 5290,
 &#39;huge&#39;: 666,
 &#39;hugo&#39;: 7922,
 &#39;hugh&#39;: 3934,
 &#39;scifi&#39;: 6196,
 &#39;brett&#39;: 7580,
 &#39;resemble&#39;: 5124,
 &#39;paper&#39;: 2300,
 &#39;scott&#39;: 1091,
 &#39;colleague&#39;: 7698,
 &#39;gadget&#39;: 4315,
 &#34;victoria&#39;s&#34;: 9463,
 &#39;shocking&#39;: 1621,
 &#39;ernie&#39;: 7581,
 &#39;research&#39;: 2301,
 &#39;1990s&#39;: 5974,
 &#39;saint&#39;: 5563,
 &#34;paul&#39;s&#34;: 9981,
 &#39;word&#39;: 681,
 &#39;blond&#39;: 4384,
 &#39;understands&#39;: 5627,
 &#39;overwhelmed&#39;: 9101,
 &#39;indifference&#39;: 9661,
 &#39;lombard&#39;: 9662,
 &#39;pleasures&#39;: 8794,
 &#39;exercise&#39;: 3435,
 &#39;insane&#39;: 2140,
 &#39;callahan&#39;: 9464,
 &#39;objects&#39;: 5344,
 &#39;retarded&#39;: 3000,
 &#39;illiterate&#39;: 9267,
 &#39;bell&#39;: 4015,
 &#39;bela&#39;: 4679,
 &#39;adaptation&#39;: 1253,
 &#39;luis&#39;: 6045,
 &#39;belt&#39;: 5848,
 &#39;satire&#39;: 2006,
 &#39;geoffrey&#39;: 8453,
 &#39;treatment&#39;: 2199,
 &#39;awake&#39;: 4141,
 &#39;33&#39;: 9633,
 &#39;pressed&#39;: 7369,
 &#39;30&#39;: 1088,
 &#39;tin&#39;: 8172,
 &#39;parents&#39;: 846,
 &#39;couple&#39;: 378,
 &#39;pounds&#39;: 5678,
 &#39;chorus&#39;: 4316,
 &#39;behave&#39;: 4486,
 &#39;mouth&#39;: 1642,
 &#39;terrorists&#39;: 4847,
 &#39;into&#39;: 83,
 &#39;katie&#39;: 8367,
 &#39;atlantis&#39;: 4016,
 &#39;singer&#39;: 1950,
 &#39;atlantic&#39;: 8064,
 &#39;paired&#39;: 8600,
 &#34;chan&#39;s&#34;: 9268,
 &#39;haunt&#39;: 7370,
 &#39;puzzling&#39;: 9269,
 &#39;creasy&#39;: 7923,
 &#39;detectives&#39;: 5928,
 &#39;turkish&#39;: 7481,
 &#39;dickinson&#39;: 8931,
 &#34;show&#39;s&#34;: 3769,
 &#39;cannibals&#39;: 8601,
 &#39;video&#39;: 374,
 &#39;dynamics&#39;: 6891,
 &#39;victor&#39;: 2273,
 &#39;flowing&#39;: 8065,
 &#39;orleans&#39;: 5097,
 &#39;makes&#39;: 166,
 &#39;maker&#39;: 3011,
 &#39;confidence&#39;: 4454,
 &#39;comedy&#39;: 212,
 &#39;intelligent&#39;: 1089,
 &#39;democracy&#39;: 9431,
 &#39;insight&#39;: 2618,
 &#34;wife&#39;s&#34;: 5078,
 &#39;derivative&#39;: 6277,
 &#39;snake&#39;: 4017,
 &#39;denzel&#39;: 3387,
 &#39;books&#39;: 1151,
 &#39;bigfoot&#39;: 8430,
 &#39;witness&#39;: 2413,
 &#34;&#39;&#34;: 758,
 &#39;greedy&#39;: 4636,
 &#39;prepare&#39;: 5403,
 &#39;could&#39;: 100,
 &#39;lumet&#39;: 4848,
 &#39;interests&#39;: 4993,
 &#39;gays&#39;: 9102,
 &#39;false&#39;: 2556,
 &#39;tonight&#39;: 4487,
 &#39;depict&#39;: 6357,
 &#39;sinatra&#39;: 2390,
 &#39;placement&#39;: 8293,
 &#39;tape&#39;: 2214,
 &#39;riding&#39;: 3053,
 &#39;stuff&#39;: 538,
 &#39;guessing&#39;: 3099,
 &#39;frame&#39;: 2122,
 &#39;destiny&#39;: 4205,
 &#39;nuclear&#39;: 3478,
 &#39;preminger&#39;: 6892,
 &#39;staring&#39;: 4488,
 &#39;marty&#39;: 4897,
 &#39;boyer&#39;: 6543,
 &#39;english&#39;: 631,
 &#39;genetic&#39;: 8783,
 &#39;hateful&#39;: 6798,
 &#39;greater&#39;: 2798,
 &#39;off&#39;: 125,
 &#39;crack&#39;: 4080,
 &#39;become&#39;: 413,
 &#39;recognition&#39;: 4637,
 &#39;morris&#39;: 4849,
 &#39;passion&#39;: 1797,
 &#39;imaginary&#39;: 7265,
 &#39;union&#39;: 3617,
 &#39;swimming&#39;: 4419,
 &#39;letters&#39;: 4455,
 &#39;pairing&#39;: 8173,
 &#39;peters&#39;: 5038,
 &#39;stopping&#39;: 5564,
 &#39;moonstruck&#39;: 8784,
 &#39;tossed&#39;: 6265,
 &#39;evident&#39;: 3523,
 &#39;excitement&#39;: 2318,
 &#39;garbo&#39;: 4942,
 &#39;problem&#39;: 439,
 &#39;nonetheless&#39;: 2935,
 &#39;details&#39;: 1373,
 &#39;exposure&#39;: 4994,
 &#39;dave&#39;: 3833,
 &#39;strings&#39;: 5849,
 &#39;compete&#39;: 6113,
 &#39;villainous&#39;: 7582,
 &#39;madsen&#39;: 7683,
 &#39;integrity&#39;: 5039,
 &#39;stinks&#39;: 4385,
 &#39;porno&#39;: 4522,
 &#39;worth&#39;: 290,
 &#39;progression&#39;: 8066,
 &#39;samurai&#39;: 3632,
 &#39;machines&#39;: 3869,
 &#39;viewings&#39;: 4719,
 &#39;equals&#39;: 9538,
 &#39;achieve&#39;: 2715,
 &#39;1991&#39;: 6047,
 &#39;1990&#39;: 4523,
 &#39;1993&#39;: 5040,
 &#39;1992&#39;: 7371,
 &#39;1995&#39;: 5125,
 &#39;1994&#39;: 6114,
 &#39;divorced&#39;: 6284,
 &#39;1996&#39;: 4142,
 &#39;1999&#39;: 4206,
 &#39;1998&#39;: 6631,
 &#39;era&#39;: 999,
 &#39;nuts&#39;: 4765,
 &#39;ladder&#39;: 5404,
 &#39;vera&#39;: 7109,
 &#39;schneider&#39;: 7266,
 &#39;davies&#39;: 3770,
 &#39;innovative&#39;: 3972,
 &#39;production&#39;: 365,
 &#39;understated&#39;: 4638,
 &#39;reasonably&#39;: 3716,
 &#39;routines&#39;: 6709,
 &#39;reasonable&#39;: 3793,
 &#39;daniel&#39;: 2274,
 &#34;character&#39;s&#34;: 1730,
 &#39;flawless&#39;: 3562,
 &#39;another&#39;: 160,
 &#39;illustrate&#39;: 8785,
 &#34;o&#39;toole&#34;: 9887,
 &#39;seduction&#39;: 9272,
 &#39;dogs&#39;: 2515,
 &#39;cabin&#39;: 2816,
 &#39;historical&#39;: 1379,
 &#39;enchanted&#39;: 7372,
 &#39;convenient&#39;: 7699,
 &#39;subjects&#39;: 4046,
 &#39;swamp&#39;: 9466,
 &#39;aunt&#39;: 2965,
 &#39;haunted&#39;: 2368,
 &#39;runs&#39;: 1129,
 &#39;horrendous&#39;: 3388,
 &#39;draws&#39;: 3771,
 &#39;drawn&#39;: 1309,
 &#39;encounters&#39;: 3267,
 &#39;handful&#39;: 3516,
 &#39;kitchen&#39;: 3904,
 &#39;essentially&#39;: 2027,
 &#39;han&#39;: 8061,
 &#39;tone&#39;: 1163,
 &#39;imaginative&#39;: 3268,
 &#39;condescending&#39;: 9273,
 &#39;tons&#39;: 3400,
 &#39;massive&#39;: 2557,
 &#39;tony&#39;: 1223,
 &#39;unlikely&#39;: 2388,
 &#39;brilliantly&#39;: 2105,
 &#39;apparently&#39;: 684,
 &#39;survival&#39;: 4098,
 &#39;fuss&#39;: 8602,
 &#39;quentin&#39;: 6632,
 &#39;humble&#39;: 4489,
 &#39;mid&#39;: 1696,
 &#39;thanks&#39;: 1216,
 &#39;similarities&#39;: 4351,
 &#39;sparse&#39;: 9467,
 &#39;night&#39;: 314,
 &#39;jacques&#39;: 6990,
 &#39;attorney&#39;: 4817,
 &#39;rendering&#39;: 7700,
 &#39;czech&#39;: 8426,
 &#39;captive&#39;: 8431,
 &#39;test&#39;: 2181,
 &#39;tess&#39;: 8067,
 &#39;songs&#39;: 690,
 &#39;concept&#39;: 1120,
 &#39;battle&#39;: 985,
 &#39;hurry&#39;: 8605,
 &#39;rebecca&#39;: 9274,
 &#39;cunningham&#39;: 7098,
 &#39;turns&#39;: 505,
 &#39;gun&#39;: 1056,
 &#39;gus&#39;: 7267,
 &#39;gut&#39;: 5565,
 &#39;guy&#39;: 232,
 &#39;rapist&#39;: 5749,
 &#39;shares&#39;: 5519,
 &#39;shared&#39;: 5345,
 &#34;hadn&#39;t&#34;: 1869,
 &#39;teaches&#39;: 5291,
 &#39;teacher&#39;: 1750,
 &#39;sending&#39;: 5679,
 &#39;franklin&#39;: 6893,
 &#39;plotted&#39;: 8432,
 &#39;regardless&#39;: 3563,
 &#39;extra&#39;: 1727,
 &#39;woefully&#39;: 8174,
 &#39;chip&#39;: 8175,
 &#39;lacks&#39;: 1503,
 &#39;discussion&#39;: 3772,
 &#39;kurt&#39;: 3199,
 &#39;chops&#39;: 7924,
 &#39;brain&#39;: 1224,
 &#39;still&#39;: 131,
 &#39;drop&#39;: 2440,
 &#39;challenged&#39;: 5235,
 &#39;yeah&#39;: 1243,
 &#39;challenges&#39;: 5459,
 &#39;year&#39;: 291,
 &#39;gibson&#39;: 8294,
 &#39;transition&#39;: 4592,
 &#39;suffice&#39;: 4917,
 &#39;romania&#39;: 8606,
 &#39;flipping&#39;: 8954,
 &#39;tomorrow&#39;: 5520,
 &#39;seymour&#39;: 6759,
 &#39;brains&#39;: 4081,
 &#39;professionals&#39;: 7099,
 &#39;transferred&#39;: 9888,
 &#39;importantly&#39;: 3517,
 &#39;premiered&#39;: 8433,
 &#39;teamed&#39;: 9663,
 &#39;burst&#39;: 5566,
 &#39;colours&#39;: 6267,
 &#39;madness&#39;: 3001,
 &#39;foreboding&#39;: 8607,
 &#39;inexplicable&#39;: 5750,
 &#39;exploit&#39;: 6471,
 &#39;charismatic&#39;: 3389,
 &#39;dictator&#39;: 8434,
 &#39;elvis&#39;: 3479,
 &#39;offbeat&#39;: 6358,
 &#39;develop&#39;: 2061,
 &#39;food&#39;: 1644,
 &#39;death&#39;: 341,
 &#39;earnest&#39;: 6359,
 &#39;fortune&#39;: 3200,
 &#39;fully&#39;: 1314,
 &#39;verbal&#39;: 6894,
 &#39;exposed&#39;: 3773,
 &#39;exposes&#39;: 9889,
 &#39;francis&#39;: 4804,
 &#34;isn&#39;t&#34;: 218,
 &#39;pitched&#39;: 7925,
 &#39;freddy&#39;: 2281,
 &#39;fools&#39;: 6799,
 &#39;poor&#39;: 338,
 &#39;pool&#39;: 3073,
 &#39;corey&#39;: 7184,
 &#39;overseas&#39;: 9469,
 &#39;robert&#39;: 670,
 &#39;thoughtful&#39;: 4353,
 &#39;religious&#39;: 1736,
 &#39;decide&#39;: 1197,
 &#39;ass&#39;: 1995,
 &#39;streets&#39;: 1986,
 &#39;bass&#39;: 9470,
 &#39;excess&#39;: 5850,
 &#39;advertising&#39;: 4593,
 &#39;cathy&#39;: 9664,
 &#39;heroic&#39;: 3818,
 &#39;budgets&#39;: 6441,
 &#39;reject&#39;: 7970,
 &#39;surpasses&#39;: 9471,
 &#39;criticize&#39;: 7100,
 &#39;anytime&#39;: 6800,
 &#39;roommates&#39;: 9103,
 &#39;absence&#39;: 3819,
 &#34;haven&#39;t&#34;: 774,
 &#39;ninja&#39;: 4850,
 &#39;bless&#39;: 8295,
 &#39;fairy&#39;: 2447,
 &#39;heavy&#39;: 1185,
 &#39;jolly&#39;: 9104,
 &#39;lord&#39;: 1635,
 &#39;earns&#39;: 8609,
 &#39;hapless&#39;: 5680,
 &#39;american&#39;: 298,
 &#39;visions&#39;: 5567,
 &#39;trapped&#39;: 2605,
 &#39;toward&#39;: 1841,
 &#39;randomly&#39;: 4851,
 &#39;organs&#39;: 9472,
 &#39;caliber&#39;: 4898,
 &#39;physics&#39;: 5681,
 &#39;stalked&#39;: 7185,
 &#39;phenomenon&#39;: 5682,
 &#39;stalker&#39;: 5851,
 &#39;heavens&#39;: 9105,
 &#39;competing&#39;: 9890,
 &#39;imitating&#39;: 9156,
 &#39;fluff&#39;: 5628,
 &#39;hype&#39;: 3401,
 &#39;locale&#39;: 8435,
 &#39;portrait&#39;: 3213,
 &#39;locals&#39;: 5751,
 &#39;abruptly&#39;: 6197,
 &#39;league&#39;: 2756,
 &#34;wouldn&#39;t&#34;: 586,
 &#39;empty&#39;: 1896,
 &#39;juice&#39;: 7926,
 &#39;match&#39;: 1014,
 &#39;grant&#39;: 2107,
 &#39;sensual&#39;: 8077,
 &#39;grand&#39;: 1758,
 &#39;composition&#39;: 7269,
 &#39;classmates&#39;: 8176,
 &#39;obviously&#39;: 540,
 &#39;synopsis&#39;: 3935,
 &#39;reviewed&#39;: 6801,
 &#39;reviewer&#39;: 2215,
 &#39;showing&#39;: 800,
 &#39;sketch&#39;: 5405,
 &#39;lips&#39;: 4047,
 &#39;towards&#39;: 949,
 &#39;silence&#39;: 3542,
 &#39;alison&#39;: 5406,
 &#39;placing&#39;: 9106,
 &#39;ideals&#39;: 7843,
 &#39;similar&#39;: 729,
 &#39;ordered&#39;: 5175,
 &#39;fears&#39;: 3564,
 &#39;department&#39;: 2550,
 &#39;smiles&#39;: 5852,
 &#39;unfunny&#39;: 1960,
 &#39;riders&#39;: 8234,
 &#39;telling&#39;: 979,
 &#39;yourselves&#39;: 9891,
 &#39;watered&#39;: 9107,
 &#39;jump&#39;: 1783,
 &#39;notwithstanding&#39;: 8786,
 &#39;vampire&#39;: 1362,
 &#39;lugosi&#39;: 2784,
 &#39;clark&#39;: 2595,
 &#39;manage&#39;: 1921,
 &#39;clara&#39;: 6544,
 &#39;camera&#39;: 370,
 &#39;boards&#39;: 8296,
 &#39;meek&#39;: 8068,
 &#39;servants&#39;: 6360,
 &#39;meet&#39;: 909,
 &#39;pulling&#39;: 3661,
 &#39;sought&#39;: 6442,
 &#39;orson&#39;: 4420,
 &#39;rohmer&#39;: 9473,
 &#39;sentiments&#39;: 9892,
 &#39;ronald&#39;: 6268,
 &#39;scoop&#39;: 6443,
 &#39;favourites&#39;: 7482,
 &#34;its&#39;&#34;: 9665,
 &#39;university&#39;: 3436,
 &#39;slide&#39;: 6444,
 &#39;special&#39;: 318,
 &#39;butch&#39;: 6445,
 &#39;obsessive&#39;: 6633,
 &#39;darkly&#39;: 8069,
 &#39;jill&#39;: 6361,
 &#39;times&#39;: 211,
 &#39;timed&#39;: 8177,
 &#39;bitch&#39;: 5460,
 &#39;wrapped&#39;: 4561,
 &#39;hines&#39;: 7701,
 &#39;bastard&#39;: 8436,
 &#39;battles&#39;: 3353,
 &#39;mansion&#39;: 3025,
 &#39;repeated&#39;: 2448,
 &#39;manga&#39;: 8437,
 &#39;unfinished&#39;: 9666,
 &#39;sheriff&#39;: 2249,
 &#39;hector&#39;: 9164,
 &#39;won&#39;: 1199,
 &#39;cameos&#39;: 3201,
 &#39;inherited&#39;: 9275,
 &#39;episodes&#39;: 672,
 &#39;ken&#39;: 3662,
 &#39;kicking&#39;: 4562,
 &#39;key&#39;: 1317,
 &#39;limits&#39;: 4317,
 &#39;cena&#39;: 7702,
 &#39;troopers&#39;: 8297,
 &#39;controlled&#39;: 5407,
 &#39;surface&#39;: 2558,
 &#39;examined&#39;: 8932,
 &#39;http&#39;: 5752,
 &#39;riff&#39;: 7927,
 &#39;montages&#39;: 9474,
 &#39;increasingly&#39;: 3437,
 &#39;distant&#39;: 3609,
 &#39;gamut&#39;: 9835,
 &#39;disappearance&#39;: 8070,
 &#39;demonstrates&#39;: 5629,
 &#39;cradle&#39;: 8933,
 &#39;demonstrated&#39;: 6710,
 &#39;limitations&#39;: 6198,
 &#39;unhinged&#39;: 7619,
 &#39;nightclub&#39;: 6446,
 &#39;pointless&#39;: 1149,
 &#39;additional&#39;: 5461,
 &#39;gain&#39;: 3235,
 &#39;highest&#39;: 4082,
 &#39;kisses&#39;: 9893,
 &#39;beats&#39;: 3936,
 &#39;education&#39;: 4421,
 &#39;disasters&#39;: 8930,
 &#39;foil&#39;: 7186,
 &#39;consists&#39;: 3202,
 &#39;sorry&#39;: 806,
 &#39;void&#39;: 6991,
 &#39;suspenseful&#39;: 2570,
 &#39;herbert&#39;: 6992,
 &#39;unrelated&#39;: 5684,
 &#39;enhance&#39;: 6802,
 &#39;iturbi&#39;: 7373,
 &#39;kidnap&#39;: 7101,
 &#39;blandings&#39;: 7928,
 &#39;meg&#39;: 5799,
 &#39;mel&#39;: 3774,
 &#39;men&#39;: 349,
 &#39;mitchell&#39;: 3717,
 &#39;robertson&#39;: 7270,
 &#39;berlin&#39;: 4456,
 &#39;shahid&#39;: 7733,
 &#39;room&#39;: 673,
 &#39;roof&#39;: 5370,
 &#39;movies&#39;: 102,
 &#39;exceptions&#39;: 5630,
 &#39;root&#39;: 3663,
 &#39;titular&#39;: 7803,
 &#39;gordon&#39;: 2236,
 &#39;vicious&#39;: 3839,
 &#39;third&#39;: 840,
 &#39;fable&#39;: 9108,
 &#39;budding&#39;: 8178,
 &#39;personal&#39;: 965,
 &#39;crew&#39;: 1051,
 &#39;anil&#39;: 6301,
 &#39;combination&#39;: 2221,
 &#39;one&#39;: 31,
 &#39;forgot&#39;: 2738,
 &#39;aids&#39;: 4422,
 &#39;comedies&#39;: 1290,
 &#39;mandy&#39;: 7703,
 &#39;uses&#39;: 1077,
 &#39;floors&#39;: 9667,
 &#39;downside&#39;: 9668,
 &#39;gandolfini&#39;: 8179,
 &#39;begins&#39;: 778,
 &#39;mario&#39;: 4386,
 &#39;maria&#39;: 2907,
 &#39;zealand&#39;: 9109,
 &#39;mildred&#39;: 4049,
 &#39;testing&#39;: 7704,
 &#39;narrated&#39;: 6993,
 &#39;guaranteed&#39;: 5523,
 &#39;represented&#39;: 4359,
 &#39;quinn&#39;: 5800,
 &#39;mathieu&#39;: 6269,
 &#39;asks&#39;: 1643,
 &#39;entered&#39;: 5978,
 &#39;lovely&#39;: 1334,
 &#39;locations&#39;: 1979,
 &#39;lionel&#39;: 6994,
 &#39;ugly&#39;: 1558,
 &#39;cant&#39;: 2488,
 &#39;realizing&#39;: 4354,
 &#39;ella&#39;: 9476,
 &#39;programs&#39;: 5872,
 &#39;failing&#39;: 3718,
 &#39;reese&#39;: 8298,
 &#39;yours&#39;: 6447,
 &#39;assigned&#39;: 4943,
 &#39;fighters&#39;: 8438,
 &#39;goodman&#39;: 8299,
 &#39;stunts&#39;: 3289,
 &#39;nude&#39;: 2516,
 &#39;dean&#39;: 2643,
 &#39;deal&#39;: 855,
 &#39;deaf&#39;: 5080,
 &#39;dear&#39;: 3214,
 &#39;shakespeare&#39;: 2282,
 &#39;confrontation&#39;: 5127,
 &#39;afternoon&#39;: 2655,
 &#39;automatically&#39;: 5347,
 &#39;down&#39;: 180,
 &#39;narration&#39;: 2559,
 &#39;editor&#39;: 3794,
 &#39;creation&#39;: 3565,
 &#39;batman&#39;: 1354,
 &#39;landing&#39;: 5128,
 &#39;feminine&#39;: 6895,
 &#39;awhile&#39;: 5236,
 &#39;happening&#39;: 1448,
 &#39;pseudo&#39;: 3905,
 &#39;restored&#39;: 4639,
 &#39;father&#39;: 336,
 &#39;turgid&#39;: 9895,
 &#39;talked&#39;: 3543,
 &#39;targets&#39;: 6995,
 &#39;suspect&#39;: 1781,
 &#39;box&#39;: 953,
 &#39;boy&#39;: 430,
 &#39;maguire&#39;: 9477,
 &#39;bow&#39;: 5631,
 &#39;bon&#39;: 8610,
 &#39;boo&#39;: 7804,
 &#39;bob&#39;: 2046,
 &#39;teenage&#39;: 1667,
 &#39;transplant&#39;: 8300,
 &#39;drags&#39;: 3465,
 &#39;dennis&#39;: 2801,
 &#39;snl&#39;: 4490,
 &#39;blooded&#39;: 6448,
 &#39;police&#39;: 568,
 &#39;policy&#39;: 6896,
 &#39;tucker&#39;: 9669,
 &#39;lunch&#39;: 6803,
 &#39;elephants&#39;: 8787,
 &#39;ajay&#39;: 7483,
 &#39;stanwyck&#39;: 3334,
 &#39;carnival&#39;: 9110,
 &#39;frequent&#39;: 4852,
 &#39;first&#39;: 86,
 &#39;fleeing&#39;: 8934,
 &#39;speaking&#39;: 1386,
 &#39;kevin&#39;: 1842,
 &#39;complexity&#39;: 4640,
 &#39;shocked&#39;: 2414,
 &#39;shocker&#39;: 8301,
 &#39;200&#39;: 6305,
 &#39;arguing&#39;: 6545,
 &#39;angst&#39;: 5568,
 &#39;harvey&#39;: 4355,
 &#39;russian&#39;: 1766,
 &#39;treasure&#39;: 2528,
 &#39;travesty&#39;: 4995,
 &#39;enthusiasm&#39;: 4805,
 &#39;get&#39;: 79,
 &#39;gee&#39;: 9111,
 &#39;gen&#39;: 8611,
 &#39;gem&#39;: 1528,
 &#39;london&#39;: 1316,
 &#39;seat&#39;: 2224,
 &#39;declares&#39;: 9896,
 &#39;seal&#39;: 9276,
 &#39;wonder&#39;: 594,
 &#39;satisfying&#39;: 2349,
 &#39;label&#39;: 6049,
 &#39;boundaries&#39;: 7484,
 &#39;across&#39;: 638,
 &#39;august&#39;: 6996,
 &#39;considering&#39;: 1069,
 &#39;capable&#39;: 2250,
 &#39;sort&#39;: 432,
 &#39;wake&#39;: 3290,
 &#39;hardcore&#39;: 4208,
 &#39;promising&#39;: 2428,
 &#39;rupert&#39;: 7285,
 &#34;o&#39;brien&#34;: 7805,
 &#39;extended&#39;: 3844,
 &#39;concentrates&#39;: 9366,
 &#39;northam&#39;: 7485,
 &#39;consisted&#39;: 9277,
 &#39;flavor&#39;: 6897,
 &#39;clueless&#39;: 5753,
 &#39;adams&#39;: 4601,
 &#39;passionate&#39;: 4387,
 &#39;each&#39;: 257,
 &#39;demonic&#39;: 5979,
 &#39;distracted&#39;: 7136,
 &#39;spice&#39;: 6711,
 &#39;vhs&#39;: 1856,
 &#39;examine&#39;: 8302,
 &#34;she&#39;d&#34;: 6449,
 &#39;hey&#39;: 1400,
 &#34;she&#39;s&#34;: 442,
 &#39;u&#39;: 1206,
 &#39;motel&#39;: 7705,
 &#39;plodding&#39;: 7187,
 &#39;former&#39;: 1138,
 &#39;paperhouse&#39;: 9670,
 &#39;strung&#39;: 7583,
 &#39;zero&#39;: 1456,
 &#39;newspaper&#39;: 3994,
 &#39;masterpiece&#39;: 991,
 &#39;mentions&#39;: 4899,
 &#39;africa&#39;: 2415,
 &#39;tacky&#39;: 5237,
 &#39;engaged&#39;: 3953,
 &#39;mill&#39;: 4209,
 &#39;hour&#39;: 534,
 &#39;recall&#39;: 2283,
 &#39;sucks&#39;: 1870,
 &#39;remain&#39;: 2416,
 &#39;stubborn&#39;: 9278,
 &#39;ford&#39;: 2108,
 &#39;colman&#39;: 8071,
 &#39;biography&#39;: 5041,
 &#39;homicide&#39;: 6071,
 &#39;needs&#39;: 738,
 &#39;acts&#39;: 1421,
 &#39;sacred&#39;: 9788,
 &#39;kitty&#39;: 5685,
 &#39;sophistication&#39;: 8439,
 &#39;brady&#39;: 4143,
 &#39;dragon&#39;: 2785,
 &#39;heartfelt&#39;: 5348,
 &#39;appeals&#39;: 6450,
 &#39;comedic&#39;: 1717,
 &#39;compound&#39;: 9671,
 &#39;viewers&#39;: 797,
 &#39;mystery&#39;: 736,
 &#39;repeating&#39;: 5686,
 &#39;rhys&#39;: 9478,
 &#39;engaging&#39;: 1728,
 &#39;edged&#39;: 9999,
 &#39;perry&#39;: 4050,
 &#34;they&#39;ll&#34;: 3664,
 &#39;extraordinary&#39;: 2802,
 &#39;backed&#39;: 6712,
 &#39;top&#39;: 350,
 &#39;razor&#39;: 6997,
 &#39;mercilessly&#39;: 9898,
 &#39;ton&#39;: 5853,
 &#39;tom&#39;: 827,
 &#39;lifts&#39;: 8440,
 &#39;godfather&#39;: 3518,
 &#39;eggs&#39;: 9672,
 &#39;charm&#39;: 1382,
 &#39;services&#39;: 7272,
 &#39;rebels&#39;: 7584,
 &#39;chock&#39;: 8303,
 &#39;ebert&#39;: 6451,
 &#39;premise&#39;: 863,
 &#39;foreign&#39;: 2189,
 &#39;point&#39;: 213,
 &#39;expensive&#39;: 3269,
 &#39;screened&#39;: 7930,
 &#39;variation&#39;: 8022,
 &#39;politician&#39;: 5854,
 &#39;widescreen&#39;: 5633,
 &#39;century&#39;: 1117,
 &#39;tashan&#39;: 7931,
 &#39;1965&#39;: 8912,
 &#39;1967&#39;: 7170,
 &#39;knock&#39;: 3296,
 &#39;foolish&#39;: 6393,
 &#39;candle&#39;: 7585,
 &#39;though&#39;: 151,
 &#39;manipulate&#39;: 8803,
 &#39;abusive&#39;: 4595,
 &#39;underused&#39;: 9673,
 &#39;murphy&#39;: 2693,
 &#39;stripped&#39;: 9480,
 &#39;scarlet&#39;: 8304,
 &#39;cure&#39;: 4318,
 &#39;stripper&#39;: 8788,
 &#39;utterly&#39;: 1254,
 &#39;implied&#39;: 6270,
 &#39;portraying&#39;: 2265,
 &#39;literary&#39;: 5292,
 &#39;pleasing&#39;: 5754,
 &#39;entire&#39;: 436,
 &#39;rivers&#39;: 6998,
 &#39;fat&#39;: 1922,
 &#39;archer&#39;: 9112,
 &#39;healing&#39;: 8935,
 &#39;escaped&#39;: 3954,
 &#39;closing&#39;: 2722,
 &#39;didnt&#39;: 9279,
 &#39;continuity&#39;: 2386,
 &#39;varied&#39;: 7188,
 &#39;holds&#39;: 1777,
 &#39;suspend&#39;: 4984,
 &#39;profile&#39;: 7486,
 &#39;watch&#39;: 106,
 &#39;incompetence&#39;: 9369,
 &#39;chasing&#39;: 3187,
 &#39;subsequently&#39;: 7706,
 &#39;grendel&#39;: 8789,
 &#39;grayson&#39;: 5081,
 &#39;blatant&#39;: 4144,
 &#39;lively&#39;: 4764,
 &#39;sexual&#39;: 861,
 &#39;yard&#39;: 5042,
 &#39;yarn&#39;: 8441,
 &#39;reaches&#39;: 4231,
 &#39;reached&#39;: 3820,
 &#39;spelling&#39;: 8442,
 &#39;sweden&#39;: 7189,
 &#39;have&#39;: 28,
 &#39;prisoner&#39;: 4766,
 &#39;disease&#39;: 3497,
 &#39;occasion&#39;: 4083,
 &#39;hamlet&#39;: 3420,
 &#39;knowledge&#39;: 1857,
 &#39;perfection&#39;: 3203,
 &#39;teams&#39;: 6271,
 &#39;showdown&#39;: 4901,
 &#39;bruno&#39;: 6362,
 &#39;incarnation&#39;: 9674,
 &#39;antics&#39;: 3871,
 &#39;russ&#39;: 7487,
 &#39;joke&#39;: 975,
 &#39;equal&#39;: 3215,
 &#39;fassbinder&#39;: 7707,
 &#34;it&#39;s&#34;: 45,
 &#34;it&#39;d&#34;: 9899,
 &#39;locales&#39;: 9113,
 &#39;meredith&#39;: 7932,
 &#39;frustrating&#39;: 5129,
 &#39;powell&#39;: 2592,
 &#39;exceedingly&#39;: 9900,
 &#39;stores&#39;: 5687,
 &#39;griffith&#39;: 5178,
 &#39;resolved&#39;: 6272,
 &#39;doyle&#39;: 7933,
 &#39;like&#39;: 40,
 &#39;vibrant&#39;: 5755,
 &#39;admitted&#39;: 6999,
 &#39;chick&#39;: 2284,
 &#39;hair&#39;: 1153,
 &#39;recommendation&#39;: 5492,
 &#39;hysterically&#39;: 7273,
 &#39;lieutenant&#39;: 9280,
 &#39;uptight&#39;: 8443,
 &#39;introduces&#39;: 4319,
 &#39;rushed&#39;: 3312,
 &#39;rushes&#39;: 9481,
 &#34;&#39;80s&#34;: 7423,
 &#39;coke&#39;: 6804,
 &#39;flip&#39;: 7808,
 &#39;thorn&#39;: 9114,
 &#39;circus&#39;: 5601,
 &#39;dressed&#39;: 1810,
 &#39;detail&#39;: 1589,
 &#39;dresses&#39;: 5350,
 &#34;daughter&#39;s&#34;: 5569,
 &#34;ted&#39;s&#34;: 9901,
 &#39;harriet&#39;: 6452,
 &#39;direct&#39;: 1504,
 &#39;nail&#39;: 4423,
 &#39;doubt&#39;: 824,
 &#39;selected&#39;: 6546,
 &#39;revolves&#39;: 3054,
 &#39;revolver&#39;: 8180,
 &#39;liberty&#39;: 8181,
 &#39;leaves&#39;: 889,
 &#39;excellent&#39;: 321,
 &#39;salvage&#39;: 7809,
 &#39;estate&#39;: 3519,
 &#39;attract&#39;: 5688,
 &#39;ceremony&#39;: 8471,
 &#39;keen&#39;: 5855,
 &#39;drummer&#39;: 8445,
 &#39;description&#39;: 2786,
 &#39;insecure&#39;: 9902,
 &#39;parallel&#39;: 4680,
 &#39;amid&#39;: 8446,
 &#39;upside&#39;: 6805,
 &#39;succeeds&#39;: 2880,
 &#39;detroit&#39;: 7190,
 &#39;newly&#39;: 4700,
 &#39;independence&#39;: 5756,
 &#39;associate&#39;: 8182,
 &#39;days&#39;: 504,
 ...}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see index to word mapping</span>
<span class="n">idx2word</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{1411: &#39;woods&#39;,
 2348: &#39;hanging&#39;,
 2292: &#39;woody&#39;,
 6749: &#39;arranged&#39;,
 2341: &#39;bringing&#39;,
 1639: &#39;wooden&#39;,
 4013: &#39;errors&#39;,
 3233: &#39;dialogs&#39;,
 362: &#39;kids&#39;,
 5037: &#39;uplifting&#39;,
 7096: &#39;controversy&#39;,
 9881: &#39;projection&#39;,
 7183: &#39;stern&#39;,
 5624: &#39;morally&#39;,
 5286: &#39;wang&#39;,
 181: &#39;want&#39;,
 2106: &#39;travel&#39;,
 6705: &#39;barbra&#39;,
 3933: &#39;dinosaurs&#39;,
 355: &#39;wrong&#39;,
 4763: &#39;subplots&#39;,
 9095: &#39;welcomed&#39;,
 6706: &#39;butcher&#39;,
 1183: &#39;fit&#39;,
 1930: &#39;screaming&#39;,
 4290: &#39;fix&#39;,
 9657: &#39;hurting&#39;,
 302: &#39;effects&#39;,
 8778: &#39;barton&#39;,
 6195: &#39;ingrid&#39;,
 7919: &#39;adapt&#39;,
 4014: &#39;disturbed&#39;,
 1288: &#39;purpose&#39;,
 6795: &#39;olds&#39;,
 887: &#39;needed&#39;,
 1300: &#39;master&#39;,
 5402: &#39;positively&#39;,
 9839: &#39;zatoichi&#39;,
 547: &#39;feeling&#39;,
 5625: &#39;affairs&#39;,
 7802: &#39;wholesome&#39;,
 1360: &#39;cinematic&#39;,
 4991: &#39;tech&#39;,
 660: &#39;saying&#39;,
 8425: &#39;padded&#39;,
 5748: &#39;tempted&#39;,
 7479: &#39;plate&#39;,
 3902: &#39;altogether&#39;,
 8779: &#39;lds&#39;,
 1780: &#39;nicely&#39;,
 4591: &#39;mummy&#39;,
 775: &#39;lots&#39;,
 9262: &#39;lotr&#39;,
 9882: &#39;irs&#39;,
 6890: &#39;ira&#39;,
 7696: &#39;discipline&#39;,
 876: &#39;nature&#39;,
 3903: &#39;superficial&#39;,
 2826: &#39;extent&#39;,
 8780: &#39;bothers&#39;,
 76: &#39;much&#39;,
 6262: &#39;spit&#39;,
 7367: &#39;arkin&#39;,
 4992: &#39;doubts&#39;,
 3087: &#39;spin&#39;,
 2579: &#39;hong&#39;,
 9097: &#39;academic&#39;,
 4452: &#39;corporate&#39;,
 4314: &#39;hal&#39;,
 4895: &#39;ham&#39;,
 69: &#39;had&#39;,
 47: &#39;has&#39;,
 2404: &#39;hat&#39;,
 2293: &#39;crowd&#39;,
 6630: &#39;crown&#39;,
 1324: &#39;bottom&#39;,
 1184: &#39;starring&#39;,
 5343: &#39;marshall&#39;,
 9098: &#39;honeymoon&#39;,
 3234: &#39;shoots&#39;,
 8292: &#39;fabric&#39;,
 3540: &#39;raped&#39;,
 8929: &#39;rapes&#39;,
 5927: &#34;else&#39;s&#34;,
 7256: &#39;martian&#39;,
 9460: &#39;passenger&#39;,
 6044: &#39;disgrace&#39;,
 5123: &#39;barrymore&#39;,
 9883: &#39;cambodia&#39;,
 5561: &#39;palma&#39;,
 3978: &#39;explosions&#39;,
 8062: &#39;loren&#39;,
 6707: &#39;shootout&#39;,
 3629: &#39;chain&#39;,
 2500: &#39;whoever&#39;,
 3039: &#39;chair&#39;,
 4520: &#39;ballet&#39;,
 5626: &#39;macho&#39;,
 3399: &#39;jerk&#39;,
 7368: &#39;gloomy&#39;,
 2897: &#39;locked&#39;,
 2591: &#39;exact&#39;,
 786: &#39;minute&#39;,
 6541: &#39;celebrated&#39;,
 3386: &#39;unintentionally&#39;,
 9099: &#39;climbs&#39;,
 9658: &#39;honour&#39;,
 5517: &#39;address&#39;,
 9461: &#39;benson&#39;,
 3843: &#39;cusack&#39;,
 3630: &#39;opposed&#39;,
 1045: &#39;following&#39;,
 4521: &#39;convincingly&#39;,
 4255: &#39;surfing&#39;,
 1240: &#39;jim&#39;,
 6542: &#39;quarter&#39;,
 6263: &#39;entering&#39;,
 615: &#39;seriously&#39;,
 7820: &#39;raunchy&#39;,
 7097: &#39;grandma&#39;,
 6111: &#39;modest&#39;,
 2850: &#39;spoken&#39;,
 3252: &#39;concert&#39;,
 8427: &#39;lingering&#39;,
 9100: &#39;snatch&#39;,
 9263: &#34;miyazaki&#39;s&#34;,
 4635: &#39;wandering&#39;,
 679: &#39;turned&#39;,
 3768: &#39;turner&#39;,
 1961: &#39;opposite&#39;,
 6089: &#39;grateful&#39;,
 5562: &#39;inconsistent&#39;,
 3792: &#39;imagined&#39;,
 9884: &#39;enthralled&#39;,
 8599: &#39;tsui&#39;,
 3541: &#39;menacing&#39;,
 3660: &#39;convoluted&#39;,
 5288: &#39;millionaire&#39;,
 1263: &#39;west&#39;,
 4204: &#39;motives&#39;,
 4453: &#39;photos&#39;,
 6112: &#39;unlikeable&#39;,
 2131: &#39;technology&#39;,
 6988: &#39;otto&#39;,
 2009: &#39;visually&#39;,
 112: &#39;being&#39;,
 9355: &#39;grounded&#39;,
 6878: &#39;excuses&#39;,
 5289: &#39;sums&#39;,
 5847: &#39;traffic&#39;,
 8428: &#39;sensational&#39;,
 8781: &#39;satisfactory&#39;,
 2327: &#39;substance&#39;,
 7697: &#39;thailand&#39;,
 5677: &#39;hopkins&#39;,
 9659: &#39;sealed&#39;,
 8063: &#39;brazilian&#39;,
 6708: &#39;bubble&#39;,
 9264: &#39;wits&#39;,
 9660: &#39;societal&#39;,
 19: &#39;with&#39;,
 5233: &#39;abused&#39;,
 3980: &#39;rage&#39;,
 5174: &#39;tripe&#39;,
 1641: &#39;dirty&#39;,
 3631: &#39;watches&#39;,
 7579: &#39;watcher&#39;,
 9885: &#39;ensuing&#39;,
 296: &#39;watched&#39;,
 5234: &#39;cream&#39;,
 9265: &#39;waving&#39;,
 6264: &#39;natalie&#39;,
 3351: &#39;tricks&#39;,
 2164: &#39;caused&#39;,
 5518: &#39;beware&#39;,
 2906: &#39;causes&#39;,
 8782: &#39;nora&#39;,
 5797: &#39;norm&#39;,
 9462: &#39;sans&#39;,
 6796: &#39;sang&#39;,
 6439: &#39;sand&#39;,
 7921: &#39;sane&#39;,
 9886: &#39;leia&#39;,
 2235: &#39;portrays&#39;,
 9266: &#39;traumatized&#39;,
 53: &#39;more&#39;,
 1169: &#39;company&#39;,
 850: &#39;learn&#39;,
 5290: &#39;knocked&#39;,
 666: &#39;huge&#39;,
 7922: &#39;hugo&#39;,
 3934: &#39;hugh&#39;,
 6196: &#39;scifi&#39;,
 7580: &#39;brett&#39;,
 5124: &#39;resemble&#39;,
 2300: &#39;paper&#39;,
 1091: &#39;scott&#39;,
 7698: &#39;colleague&#39;,
 4315: &#39;gadget&#39;,
 9463: &#34;victoria&#39;s&#34;,
 1621: &#39;shocking&#39;,
 7581: &#39;ernie&#39;,
 2301: &#39;research&#39;,
 5974: &#39;1990s&#39;,
 5563: &#39;saint&#39;,
 9981: &#34;paul&#39;s&#34;,
 681: &#39;word&#39;,
 4384: &#39;blond&#39;,
 5627: &#39;understands&#39;,
 9101: &#39;overwhelmed&#39;,
 9661: &#39;indifference&#39;,
 9662: &#39;lombard&#39;,
 8794: &#39;pleasures&#39;,
 3435: &#39;exercise&#39;,
 2140: &#39;insane&#39;,
 9464: &#39;callahan&#39;,
 5344: &#39;objects&#39;,
 3000: &#39;retarded&#39;,
 9267: &#39;illiterate&#39;,
 4015: &#39;bell&#39;,
 4679: &#39;bela&#39;,
 1253: &#39;adaptation&#39;,
 6045: &#39;luis&#39;,
 5848: &#39;belt&#39;,
 2006: &#39;satire&#39;,
 8453: &#39;geoffrey&#39;,
 2199: &#39;treatment&#39;,
 4141: &#39;awake&#39;,
 9633: &#39;33&#39;,
 7369: &#39;pressed&#39;,
 1088: &#39;30&#39;,
 8172: &#39;tin&#39;,
 846: &#39;parents&#39;,
 378: &#39;couple&#39;,
 5678: &#39;pounds&#39;,
 4316: &#39;chorus&#39;,
 4486: &#39;behave&#39;,
 1642: &#39;mouth&#39;,
 4847: &#39;terrorists&#39;,
 83: &#39;into&#39;,
 8367: &#39;katie&#39;,
 4016: &#39;atlantis&#39;,
 1950: &#39;singer&#39;,
 8064: &#39;atlantic&#39;,
 8600: &#39;paired&#39;,
 9268: &#34;chan&#39;s&#34;,
 7370: &#39;haunt&#39;,
 9269: &#39;puzzling&#39;,
 7923: &#39;creasy&#39;,
 5928: &#39;detectives&#39;,
 7481: &#39;turkish&#39;,
 8931: &#39;dickinson&#39;,
 3769: &#34;show&#39;s&#34;,
 8601: &#39;cannibals&#39;,
 374: &#39;video&#39;,
 6891: &#39;dynamics&#39;,
 2273: &#39;victor&#39;,
 8065: &#39;flowing&#39;,
 5097: &#39;orleans&#39;,
 166: &#39;makes&#39;,
 3011: &#39;maker&#39;,
 4454: &#39;confidence&#39;,
 212: &#39;comedy&#39;,
 1089: &#39;intelligent&#39;,
 9431: &#39;democracy&#39;,
 2618: &#39;insight&#39;,
 5078: &#34;wife&#39;s&#34;,
 6277: &#39;derivative&#39;,
 4017: &#39;snake&#39;,
 3387: &#39;denzel&#39;,
 1151: &#39;books&#39;,
 8430: &#39;bigfoot&#39;,
 2413: &#39;witness&#39;,
 758: &#34;&#39;&#34;,
 4636: &#39;greedy&#39;,
 5403: &#39;prepare&#39;,
 100: &#39;could&#39;,
 4848: &#39;lumet&#39;,
 4993: &#39;interests&#39;,
 9102: &#39;gays&#39;,
 2556: &#39;false&#39;,
 4487: &#39;tonight&#39;,
 6357: &#39;depict&#39;,
 2390: &#39;sinatra&#39;,
 8293: &#39;placement&#39;,
 2214: &#39;tape&#39;,
 3053: &#39;riding&#39;,
 538: &#39;stuff&#39;,
 3099: &#39;guessing&#39;,
 2122: &#39;frame&#39;,
 4205: &#39;destiny&#39;,
 3478: &#39;nuclear&#39;,
 6892: &#39;preminger&#39;,
 4488: &#39;staring&#39;,
 4897: &#39;marty&#39;,
 6543: &#39;boyer&#39;,
 631: &#39;english&#39;,
 8783: &#39;genetic&#39;,
 6798: &#39;hateful&#39;,
 2798: &#39;greater&#39;,
 125: &#39;off&#39;,
 4080: &#39;crack&#39;,
 413: &#39;become&#39;,
 4637: &#39;recognition&#39;,
 4849: &#39;morris&#39;,
 1797: &#39;passion&#39;,
 7265: &#39;imaginary&#39;,
 3617: &#39;union&#39;,
 4419: &#39;swimming&#39;,
 4455: &#39;letters&#39;,
 8173: &#39;pairing&#39;,
 5038: &#39;peters&#39;,
 5564: &#39;stopping&#39;,
 8784: &#39;moonstruck&#39;,
 6265: &#39;tossed&#39;,
 3523: &#39;evident&#39;,
 2318: &#39;excitement&#39;,
 4942: &#39;garbo&#39;,
 439: &#39;problem&#39;,
 2935: &#39;nonetheless&#39;,
 1373: &#39;details&#39;,
 4994: &#39;exposure&#39;,
 3833: &#39;dave&#39;,
 5849: &#39;strings&#39;,
 6113: &#39;compete&#39;,
 7582: &#39;villainous&#39;,
 7683: &#39;madsen&#39;,
 5039: &#39;integrity&#39;,
 4385: &#39;stinks&#39;,
 4522: &#39;porno&#39;,
 290: &#39;worth&#39;,
 8066: &#39;progression&#39;,
 3632: &#39;samurai&#39;,
 3869: &#39;machines&#39;,
 4719: &#39;viewings&#39;,
 9538: &#39;equals&#39;,
 2715: &#39;achieve&#39;,
 6047: &#39;1991&#39;,
 4523: &#39;1990&#39;,
 5040: &#39;1993&#39;,
 7371: &#39;1992&#39;,
 5125: &#39;1995&#39;,
 6114: &#39;1994&#39;,
 6284: &#39;divorced&#39;,
 4142: &#39;1996&#39;,
 4206: &#39;1999&#39;,
 6631: &#39;1998&#39;,
 999: &#39;era&#39;,
 4765: &#39;nuts&#39;,
 5404: &#39;ladder&#39;,
 7109: &#39;vera&#39;,
 7266: &#39;schneider&#39;,
 3770: &#39;davies&#39;,
 3972: &#39;innovative&#39;,
 365: &#39;production&#39;,
 4638: &#39;understated&#39;,
 3716: &#39;reasonably&#39;,
 6709: &#39;routines&#39;,
 3793: &#39;reasonable&#39;,
 2274: &#39;daniel&#39;,
 1730: &#34;character&#39;s&#34;,
 3562: &#39;flawless&#39;,
 160: &#39;another&#39;,
 8785: &#39;illustrate&#39;,
 9887: &#34;o&#39;toole&#34;,
 9272: &#39;seduction&#39;,
 2515: &#39;dogs&#39;,
 2816: &#39;cabin&#39;,
 1379: &#39;historical&#39;,
 7372: &#39;enchanted&#39;,
 7699: &#39;convenient&#39;,
 4046: &#39;subjects&#39;,
 9466: &#39;swamp&#39;,
 2965: &#39;aunt&#39;,
 2368: &#39;haunted&#39;,
 1129: &#39;runs&#39;,
 3388: &#39;horrendous&#39;,
 3771: &#39;draws&#39;,
 1309: &#39;drawn&#39;,
 3267: &#39;encounters&#39;,
 3516: &#39;handful&#39;,
 3904: &#39;kitchen&#39;,
 2027: &#39;essentially&#39;,
 8061: &#39;han&#39;,
 1163: &#39;tone&#39;,
 3268: &#39;imaginative&#39;,
 9273: &#39;condescending&#39;,
 3400: &#39;tons&#39;,
 2557: &#39;massive&#39;,
 1223: &#39;tony&#39;,
 2388: &#39;unlikely&#39;,
 2105: &#39;brilliantly&#39;,
 684: &#39;apparently&#39;,
 4098: &#39;survival&#39;,
 8602: &#39;fuss&#39;,
 6632: &#39;quentin&#39;,
 4489: &#39;humble&#39;,
 1696: &#39;mid&#39;,
 1216: &#39;thanks&#39;,
 4351: &#39;similarities&#39;,
 9467: &#39;sparse&#39;,
 314: &#39;night&#39;,
 6990: &#39;jacques&#39;,
 4817: &#39;attorney&#39;,
 7700: &#39;rendering&#39;,
 8426: &#39;czech&#39;,
 8431: &#39;captive&#39;,
 2181: &#39;test&#39;,
 8067: &#39;tess&#39;,
 690: &#39;songs&#39;,
 1120: &#39;concept&#39;,
 985: &#39;battle&#39;,
 8605: &#39;hurry&#39;,
 9274: &#39;rebecca&#39;,
 7098: &#39;cunningham&#39;,
 505: &#39;turns&#39;,
 1056: &#39;gun&#39;,
 7267: &#39;gus&#39;,
 5565: &#39;gut&#39;,
 232: &#39;guy&#39;,
 5749: &#39;rapist&#39;,
 5519: &#39;shares&#39;,
 5345: &#39;shared&#39;,
 1869: &#34;hadn&#39;t&#34;,
 5291: &#39;teaches&#39;,
 1750: &#39;teacher&#39;,
 5679: &#39;sending&#39;,
 6893: &#39;franklin&#39;,
 8432: &#39;plotted&#39;,
 3563: &#39;regardless&#39;,
 1727: &#39;extra&#39;,
 8174: &#39;woefully&#39;,
 8175: &#39;chip&#39;,
 1503: &#39;lacks&#39;,
 3772: &#39;discussion&#39;,
 3199: &#39;kurt&#39;,
 7924: &#39;chops&#39;,
 1224: &#39;brain&#39;,
 131: &#39;still&#39;,
 2440: &#39;drop&#39;,
 5235: &#39;challenged&#39;,
 1243: &#39;yeah&#39;,
 5459: &#39;challenges&#39;,
 291: &#39;year&#39;,
 8294: &#39;gibson&#39;,
 4592: &#39;transition&#39;,
 4917: &#39;suffice&#39;,
 8606: &#39;romania&#39;,
 8954: &#39;flipping&#39;,
 5520: &#39;tomorrow&#39;,
 6759: &#39;seymour&#39;,
 4081: &#39;brains&#39;,
 7099: &#39;professionals&#39;,
 9888: &#39;transferred&#39;,
 3517: &#39;importantly&#39;,
 8433: &#39;premiered&#39;,
 9663: &#39;teamed&#39;,
 5566: &#39;burst&#39;,
 6267: &#39;colours&#39;,
 3001: &#39;madness&#39;,
 8607: &#39;foreboding&#39;,
 5750: &#39;inexplicable&#39;,
 6471: &#39;exploit&#39;,
 3389: &#39;charismatic&#39;,
 8434: &#39;dictator&#39;,
 3479: &#39;elvis&#39;,
 6358: &#39;offbeat&#39;,
 2061: &#39;develop&#39;,
 1644: &#39;food&#39;,
 341: &#39;death&#39;,
 6359: &#39;earnest&#39;,
 3200: &#39;fortune&#39;,
 1314: &#39;fully&#39;,
 6894: &#39;verbal&#39;,
 3773: &#39;exposed&#39;,
 9889: &#39;exposes&#39;,
 4804: &#39;francis&#39;,
 218: &#34;isn&#39;t&#34;,
 7925: &#39;pitched&#39;,
 2281: &#39;freddy&#39;,
 6799: &#39;fools&#39;,
 338: &#39;poor&#39;,
 3073: &#39;pool&#39;,
 7184: &#39;corey&#39;,
 9469: &#39;overseas&#39;,
 670: &#39;robert&#39;,
 4353: &#39;thoughtful&#39;,
 1736: &#39;religious&#39;,
 1197: &#39;decide&#39;,
 1995: &#39;ass&#39;,
 1986: &#39;streets&#39;,
 9470: &#39;bass&#39;,
 5850: &#39;excess&#39;,
 4593: &#39;advertising&#39;,
 9664: &#39;cathy&#39;,
 3818: &#39;heroic&#39;,
 6441: &#39;budgets&#39;,
 7970: &#39;reject&#39;,
 9471: &#39;surpasses&#39;,
 7100: &#39;criticize&#39;,
 6800: &#39;anytime&#39;,
 9103: &#39;roommates&#39;,
 3819: &#39;absence&#39;,
 774: &#34;haven&#39;t&#34;,
 4850: &#39;ninja&#39;,
 8295: &#39;bless&#39;,
 2447: &#39;fairy&#39;,
 1185: &#39;heavy&#39;,
 9104: &#39;jolly&#39;,
 1635: &#39;lord&#39;,
 8609: &#39;earns&#39;,
 5680: &#39;hapless&#39;,
 298: &#39;american&#39;,
 5567: &#39;visions&#39;,
 2605: &#39;trapped&#39;,
 1841: &#39;toward&#39;,
 4851: &#39;randomly&#39;,
 9472: &#39;organs&#39;,
 4898: &#39;caliber&#39;,
 5681: &#39;physics&#39;,
 7185: &#39;stalked&#39;,
 5682: &#39;phenomenon&#39;,
 5851: &#39;stalker&#39;,
 9105: &#39;heavens&#39;,
 9890: &#39;competing&#39;,
 9156: &#39;imitating&#39;,
 5628: &#39;fluff&#39;,
 3401: &#39;hype&#39;,
 8435: &#39;locale&#39;,
 3213: &#39;portrait&#39;,
 5751: &#39;locals&#39;,
 6197: &#39;abruptly&#39;,
 2756: &#39;league&#39;,
 586: &#34;wouldn&#39;t&#34;,
 1896: &#39;empty&#39;,
 7926: &#39;juice&#39;,
 1014: &#39;match&#39;,
 2107: &#39;grant&#39;,
 8077: &#39;sensual&#39;,
 1758: &#39;grand&#39;,
 7269: &#39;composition&#39;,
 8176: &#39;classmates&#39;,
 540: &#39;obviously&#39;,
 3935: &#39;synopsis&#39;,
 6801: &#39;reviewed&#39;,
 2215: &#39;reviewer&#39;,
 800: &#39;showing&#39;,
 5405: &#39;sketch&#39;,
 4047: &#39;lips&#39;,
 949: &#39;towards&#39;,
 3542: &#39;silence&#39;,
 5406: &#39;alison&#39;,
 9106: &#39;placing&#39;,
 7843: &#39;ideals&#39;,
 729: &#39;similar&#39;,
 5175: &#39;ordered&#39;,
 3564: &#39;fears&#39;,
 2550: &#39;department&#39;,
 5852: &#39;smiles&#39;,
 1960: &#39;unfunny&#39;,
 8234: &#39;riders&#39;,
 979: &#39;telling&#39;,
 9891: &#39;yourselves&#39;,
 9107: &#39;watered&#39;,
 1783: &#39;jump&#39;,
 8786: &#39;notwithstanding&#39;,
 1362: &#39;vampire&#39;,
 2784: &#39;lugosi&#39;,
 2595: &#39;clark&#39;,
 1921: &#39;manage&#39;,
 6544: &#39;clara&#39;,
 370: &#39;camera&#39;,
 8296: &#39;boards&#39;,
 8068: &#39;meek&#39;,
 6360: &#39;servants&#39;,
 909: &#39;meet&#39;,
 3661: &#39;pulling&#39;,
 6442: &#39;sought&#39;,
 4420: &#39;orson&#39;,
 9473: &#39;rohmer&#39;,
 9892: &#39;sentiments&#39;,
 6268: &#39;ronald&#39;,
 6443: &#39;scoop&#39;,
 7482: &#39;favourites&#39;,
 9665: &#34;its&#39;&#34;,
 3436: &#39;university&#39;,
 6444: &#39;slide&#39;,
 318: &#39;special&#39;,
 6445: &#39;butch&#39;,
 6633: &#39;obsessive&#39;,
 8069: &#39;darkly&#39;,
 6361: &#39;jill&#39;,
 211: &#39;times&#39;,
 8177: &#39;timed&#39;,
 5460: &#39;bitch&#39;,
 4561: &#39;wrapped&#39;,
 7701: &#39;hines&#39;,
 8436: &#39;bastard&#39;,
 3353: &#39;battles&#39;,
 3025: &#39;mansion&#39;,
 2448: &#39;repeated&#39;,
 8437: &#39;manga&#39;,
 9666: &#39;unfinished&#39;,
 2249: &#39;sheriff&#39;,
 9164: &#39;hector&#39;,
 1199: &#39;won&#39;,
 3201: &#39;cameos&#39;,
 9275: &#39;inherited&#39;,
 672: &#39;episodes&#39;,
 3662: &#39;ken&#39;,
 4562: &#39;kicking&#39;,
 1317: &#39;key&#39;,
 4317: &#39;limits&#39;,
 7702: &#39;cena&#39;,
 8297: &#39;troopers&#39;,
 5407: &#39;controlled&#39;,
 2558: &#39;surface&#39;,
 8932: &#39;examined&#39;,
 5752: &#39;http&#39;,
 7927: &#39;riff&#39;,
 9474: &#39;montages&#39;,
 3437: &#39;increasingly&#39;,
 3609: &#39;distant&#39;,
 9835: &#39;gamut&#39;,
 8070: &#39;disappearance&#39;,
 5629: &#39;demonstrates&#39;,
 8933: &#39;cradle&#39;,
 6710: &#39;demonstrated&#39;,
 6198: &#39;limitations&#39;,
 7619: &#39;unhinged&#39;,
 6446: &#39;nightclub&#39;,
 1149: &#39;pointless&#39;,
 5461: &#39;additional&#39;,
 3235: &#39;gain&#39;,
 4082: &#39;highest&#39;,
 9893: &#39;kisses&#39;,
 3936: &#39;beats&#39;,
 4421: &#39;education&#39;,
 8930: &#39;disasters&#39;,
 7186: &#39;foil&#39;,
 3202: &#39;consists&#39;,
 806: &#39;sorry&#39;,
 6991: &#39;void&#39;,
 2570: &#39;suspenseful&#39;,
 6992: &#39;herbert&#39;,
 5684: &#39;unrelated&#39;,
 6802: &#39;enhance&#39;,
 7373: &#39;iturbi&#39;,
 7101: &#39;kidnap&#39;,
 7928: &#39;blandings&#39;,
 5799: &#39;meg&#39;,
 3774: &#39;mel&#39;,
 349: &#39;men&#39;,
 3717: &#39;mitchell&#39;,
 7270: &#39;robertson&#39;,
 4456: &#39;berlin&#39;,
 7733: &#39;shahid&#39;,
 673: &#39;room&#39;,
 5370: &#39;roof&#39;,
 102: &#39;movies&#39;,
 5630: &#39;exceptions&#39;,
 3663: &#39;root&#39;,
 7803: &#39;titular&#39;,
 2236: &#39;gordon&#39;,
 3839: &#39;vicious&#39;,
 840: &#39;third&#39;,
 9108: &#39;fable&#39;,
 8178: &#39;budding&#39;,
 965: &#39;personal&#39;,
 1051: &#39;crew&#39;,
 6301: &#39;anil&#39;,
 2221: &#39;combination&#39;,
 31: &#39;one&#39;,
 2738: &#39;forgot&#39;,
 4422: &#39;aids&#39;,
 1290: &#39;comedies&#39;,
 7703: &#39;mandy&#39;,
 1077: &#39;uses&#39;,
 9667: &#39;floors&#39;,
 9668: &#39;downside&#39;,
 8179: &#39;gandolfini&#39;,
 778: &#39;begins&#39;,
 4386: &#39;mario&#39;,
 2907: &#39;maria&#39;,
 9109: &#39;zealand&#39;,
 4049: &#39;mildred&#39;,
 7704: &#39;testing&#39;,
 6993: &#39;narrated&#39;,
 5523: &#39;guaranteed&#39;,
 4359: &#39;represented&#39;,
 5800: &#39;quinn&#39;,
 6269: &#39;mathieu&#39;,
 1643: &#39;asks&#39;,
 5978: &#39;entered&#39;,
 1334: &#39;lovely&#39;,
 1979: &#39;locations&#39;,
 6994: &#39;lionel&#39;,
 1558: &#39;ugly&#39;,
 2488: &#39;cant&#39;,
 4354: &#39;realizing&#39;,
 9476: &#39;ella&#39;,
 5872: &#39;programs&#39;,
 3718: &#39;failing&#39;,
 8298: &#39;reese&#39;,
 6447: &#39;yours&#39;,
 4943: &#39;assigned&#39;,
 8438: &#39;fighters&#39;,
 8299: &#39;goodman&#39;,
 3289: &#39;stunts&#39;,
 2516: &#39;nude&#39;,
 2643: &#39;dean&#39;,
 855: &#39;deal&#39;,
 5080: &#39;deaf&#39;,
 3214: &#39;dear&#39;,
 2282: &#39;shakespeare&#39;,
 5127: &#39;confrontation&#39;,
 2655: &#39;afternoon&#39;,
 5347: &#39;automatically&#39;,
 180: &#39;down&#39;,
 2559: &#39;narration&#39;,
 3794: &#39;editor&#39;,
 3565: &#39;creation&#39;,
 1354: &#39;batman&#39;,
 5128: &#39;landing&#39;,
 6895: &#39;feminine&#39;,
 5236: &#39;awhile&#39;,
 1448: &#39;happening&#39;,
 3905: &#39;pseudo&#39;,
 4639: &#39;restored&#39;,
 336: &#39;father&#39;,
 9895: &#39;turgid&#39;,
 3543: &#39;talked&#39;,
 6995: &#39;targets&#39;,
 1781: &#39;suspect&#39;,
 953: &#39;box&#39;,
 430: &#39;boy&#39;,
 9477: &#39;maguire&#39;,
 5631: &#39;bow&#39;,
 8610: &#39;bon&#39;,
 7804: &#39;boo&#39;,
 2046: &#39;bob&#39;,
 1667: &#39;teenage&#39;,
 8300: &#39;transplant&#39;,
 3465: &#39;drags&#39;,
 2801: &#39;dennis&#39;,
 4490: &#39;snl&#39;,
 6448: &#39;blooded&#39;,
 568: &#39;police&#39;,
 6896: &#39;policy&#39;,
 9669: &#39;tucker&#39;,
 6803: &#39;lunch&#39;,
 8787: &#39;elephants&#39;,
 7483: &#39;ajay&#39;,
 3334: &#39;stanwyck&#39;,
 9110: &#39;carnival&#39;,
 4852: &#39;frequent&#39;,
 86: &#39;first&#39;,
 8934: &#39;fleeing&#39;,
 1386: &#39;speaking&#39;,
 1842: &#39;kevin&#39;,
 4640: &#39;complexity&#39;,
 2414: &#39;shocked&#39;,
 8301: &#39;shocker&#39;,
 6305: &#39;200&#39;,
 6545: &#39;arguing&#39;,
 5568: &#39;angst&#39;,
 4355: &#39;harvey&#39;,
 1766: &#39;russian&#39;,
 2528: &#39;treasure&#39;,
 4995: &#39;travesty&#39;,
 4805: &#39;enthusiasm&#39;,
 79: &#39;get&#39;,
 9111: &#39;gee&#39;,
 8611: &#39;gen&#39;,
 1528: &#39;gem&#39;,
 1316: &#39;london&#39;,
 2224: &#39;seat&#39;,
 9896: &#39;declares&#39;,
 9276: &#39;seal&#39;,
 594: &#39;wonder&#39;,
 2349: &#39;satisfying&#39;,
 6049: &#39;label&#39;,
 7484: &#39;boundaries&#39;,
 638: &#39;across&#39;,
 6996: &#39;august&#39;,
 1069: &#39;considering&#39;,
 2250: &#39;capable&#39;,
 432: &#39;sort&#39;,
 3290: &#39;wake&#39;,
 4208: &#39;hardcore&#39;,
 2428: &#39;promising&#39;,
 7285: &#39;rupert&#39;,
 7805: &#34;o&#39;brien&#34;,
 3844: &#39;extended&#39;,
 9366: &#39;concentrates&#39;,
 7485: &#39;northam&#39;,
 9277: &#39;consisted&#39;,
 6897: &#39;flavor&#39;,
 5753: &#39;clueless&#39;,
 4601: &#39;adams&#39;,
 4387: &#39;passionate&#39;,
 257: &#39;each&#39;,
 5979: &#39;demonic&#39;,
 7136: &#39;distracted&#39;,
 6711: &#39;spice&#39;,
 1856: &#39;vhs&#39;,
 8302: &#39;examine&#39;,
 6449: &#34;she&#39;d&#34;,
 1400: &#39;hey&#39;,
 442: &#34;she&#39;s&#34;,
 1206: &#39;u&#39;,
 7705: &#39;motel&#39;,
 7187: &#39;plodding&#39;,
 1138: &#39;former&#39;,
 9670: &#39;paperhouse&#39;,
 7583: &#39;strung&#39;,
 1456: &#39;zero&#39;,
 3994: &#39;newspaper&#39;,
 991: &#39;masterpiece&#39;,
 4899: &#39;mentions&#39;,
 2415: &#39;africa&#39;,
 5237: &#39;tacky&#39;,
 3953: &#39;engaged&#39;,
 4209: &#39;mill&#39;,
 534: &#39;hour&#39;,
 2283: &#39;recall&#39;,
 1870: &#39;sucks&#39;,
 2416: &#39;remain&#39;,
 9278: &#39;stubborn&#39;,
 2108: &#39;ford&#39;,
 8071: &#39;colman&#39;,
 5041: &#39;biography&#39;,
 6071: &#39;homicide&#39;,
 738: &#39;needs&#39;,
 1421: &#39;acts&#39;,
 9788: &#39;sacred&#39;,
 5685: &#39;kitty&#39;,
 8439: &#39;sophistication&#39;,
 4143: &#39;brady&#39;,
 2785: &#39;dragon&#39;,
 5348: &#39;heartfelt&#39;,
 6450: &#39;appeals&#39;,
 1717: &#39;comedic&#39;,
 9671: &#39;compound&#39;,
 797: &#39;viewers&#39;,
 736: &#39;mystery&#39;,
 5686: &#39;repeating&#39;,
 9478: &#39;rhys&#39;,
 1728: &#39;engaging&#39;,
 9999: &#39;edged&#39;,
 4050: &#39;perry&#39;,
 3664: &#34;they&#39;ll&#34;,
 2802: &#39;extraordinary&#39;,
 6712: &#39;backed&#39;,
 350: &#39;top&#39;,
 6997: &#39;razor&#39;,
 9898: &#39;mercilessly&#39;,
 5853: &#39;ton&#39;,
 827: &#39;tom&#39;,
 8440: &#39;lifts&#39;,
 3518: &#39;godfather&#39;,
 9672: &#39;eggs&#39;,
 1382: &#39;charm&#39;,
 7272: &#39;services&#39;,
 7584: &#39;rebels&#39;,
 8303: &#39;chock&#39;,
 6451: &#39;ebert&#39;,
 863: &#39;premise&#39;,
 2189: &#39;foreign&#39;,
 213: &#39;point&#39;,
 3269: &#39;expensive&#39;,
 7930: &#39;screened&#39;,
 8022: &#39;variation&#39;,
 5854: &#39;politician&#39;,
 5633: &#39;widescreen&#39;,
 1117: &#39;century&#39;,
 7931: &#39;tashan&#39;,
 8912: &#39;1965&#39;,
 7170: &#39;1967&#39;,
 3296: &#39;knock&#39;,
 6393: &#39;foolish&#39;,
 7585: &#39;candle&#39;,
 151: &#39;though&#39;,
 8803: &#39;manipulate&#39;,
 4595: &#39;abusive&#39;,
 9673: &#39;underused&#39;,
 2693: &#39;murphy&#39;,
 9480: &#39;stripped&#39;,
 8304: &#39;scarlet&#39;,
 4318: &#39;cure&#39;,
 8788: &#39;stripper&#39;,
 1254: &#39;utterly&#39;,
 6270: &#39;implied&#39;,
 2265: &#39;portraying&#39;,
 5292: &#39;literary&#39;,
 5754: &#39;pleasing&#39;,
 436: &#39;entire&#39;,
 6998: &#39;rivers&#39;,
 1922: &#39;fat&#39;,
 9112: &#39;archer&#39;,
 8935: &#39;healing&#39;,
 3954: &#39;escaped&#39;,
 2722: &#39;closing&#39;,
 9279: &#39;didnt&#39;,
 2386: &#39;continuity&#39;,
 7188: &#39;varied&#39;,
 1777: &#39;holds&#39;,
 4984: &#39;suspend&#39;,
 7486: &#39;profile&#39;,
 106: &#39;watch&#39;,
 9369: &#39;incompetence&#39;,
 3187: &#39;chasing&#39;,
 7706: &#39;subsequently&#39;,
 8789: &#39;grendel&#39;,
 5081: &#39;grayson&#39;,
 4144: &#39;blatant&#39;,
 4764: &#39;lively&#39;,
 861: &#39;sexual&#39;,
 5042: &#39;yard&#39;,
 8441: &#39;yarn&#39;,
 4231: &#39;reaches&#39;,
 3820: &#39;reached&#39;,
 8442: &#39;spelling&#39;,
 7189: &#39;sweden&#39;,
 28: &#39;have&#39;,
 4766: &#39;prisoner&#39;,
 3497: &#39;disease&#39;,
 4083: &#39;occasion&#39;,
 3420: &#39;hamlet&#39;,
 1857: &#39;knowledge&#39;,
 3203: &#39;perfection&#39;,
 6271: &#39;teams&#39;,
 4901: &#39;showdown&#39;,
 6362: &#39;bruno&#39;,
 9674: &#39;incarnation&#39;,
 3871: &#39;antics&#39;,
 7487: &#39;russ&#39;,
 975: &#39;joke&#39;,
 3215: &#39;equal&#39;,
 7707: &#39;fassbinder&#39;,
 45: &#34;it&#39;s&#34;,
 9899: &#34;it&#39;d&#34;,
 9113: &#39;locales&#39;,
 7932: &#39;meredith&#39;,
 5129: &#39;frustrating&#39;,
 2592: &#39;powell&#39;,
 9900: &#39;exceedingly&#39;,
 5687: &#39;stores&#39;,
 5178: &#39;griffith&#39;,
 6272: &#39;resolved&#39;,
 7933: &#39;doyle&#39;,
 40: &#39;like&#39;,
 5755: &#39;vibrant&#39;,
 6999: &#39;admitted&#39;,
 2284: &#39;chick&#39;,
 1153: &#39;hair&#39;,
 5492: &#39;recommendation&#39;,
 7273: &#39;hysterically&#39;,
 9280: &#39;lieutenant&#39;,
 8443: &#39;uptight&#39;,
 4319: &#39;introduces&#39;,
 3312: &#39;rushed&#39;,
 9481: &#39;rushes&#39;,
 7423: &#34;&#39;80s&#34;,
 6804: &#39;coke&#39;,
 7808: &#39;flip&#39;,
 9114: &#39;thorn&#39;,
 5601: &#39;circus&#39;,
 1810: &#39;dressed&#39;,
 1589: &#39;detail&#39;,
 5350: &#39;dresses&#39;,
 5569: &#34;daughter&#39;s&#34;,
 9901: &#34;ted&#39;s&#34;,
 6452: &#39;harriet&#39;,
 1504: &#39;direct&#39;,
 4423: &#39;nail&#39;,
 824: &#39;doubt&#39;,
 6546: &#39;selected&#39;,
 3054: &#39;revolves&#39;,
 8180: &#39;revolver&#39;,
 8181: &#39;liberty&#39;,
 889: &#39;leaves&#39;,
 321: &#39;excellent&#39;,
 7809: &#39;salvage&#39;,
 3519: &#39;estate&#39;,
 5688: &#39;attract&#39;,
 8471: &#39;ceremony&#39;,
 5855: &#39;keen&#39;,
 8445: &#39;drummer&#39;,
 2786: &#39;description&#39;,
 9902: &#39;insecure&#39;,
 4680: &#39;parallel&#39;,
 8446: &#39;amid&#39;,
 6805: &#39;upside&#39;,
 2880: &#39;succeeds&#39;,
 7190: &#39;detroit&#39;,
 4700: &#39;newly&#39;,
 5756: &#39;independence&#39;,
 8182: &#39;associate&#39;,
 504: &#39;days&#39;,
 ...}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#This step is visual step where encoding in the dataset is convrted back to readable or alphabetic form </span>
<span class="c1">#Here each integer in the text is matched with the index, and replaced by the corresponding word</span>

<span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">idx2word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s2">&quot;?&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert &lt;UNK&gt; is an amazing actor and now the same being director &lt;UNK&gt; father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for &lt;UNK&gt; and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also &lt;UNK&gt; to the two little boy&#39;s that played the &lt;UNK&gt; of norman and paul they were just brilliant children are often left out of the &lt;UNK&gt; list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="MODEL-BUILDING:">MODEL BUILDING:<a class="anchor-link" href="#MODEL-BUILDING:">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="NORMAL-NN-WITH-SEQ-LEN-20">NORMAL NN WITH SEQ LEN 20<a class="anchor-link" href="#NORMAL-NN-WITH-SEQ-LEN-20">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#padding train and test set with max sequence length of 20 </span>
<span class="n">SEQ_LEN</span><span class="o">=</span><span class="mi">20</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span>  <span class="n">pad_sequences</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">)</span>

<span class="c1">#Note Padding is post padding </span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see shape of both test and train set</span>
<span class="c1">#here it should be 20 in shape[1]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(25000, 20)
(25000, 20)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;numpy.ndarray&#39;&gt;
&lt;class &#39;numpy.ndarray&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see test values</span>
<span class="n">X_test</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[29]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[   1,  591,  202, ..., 5760,  394,  354],
       [   1,   14,   22, ...,  114,    9,   55],
       [   1,  111,  748, ...,  498, 5076,  748],
       ...,
       [   1,   13, 1408, ...,   45,  184,   78],
       [   1,   11,  119, ...,   86,  107,    8],
       [   1,    6,   52, ...,   47,    6, 3482]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see test values</span>
<span class="n">X_train</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[30]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[   1,   14,   22, ...,  256,    5,   25],
       [   1,  194, 1153, ...,  118, 1634,   14],
       [   1,   14,   47, ...,   71,  149,   14],
       ...,
       [   1,   11,    6, ...,    4,  912,   84],
       [   1, 1446, 7079, ...,   54,  349,   11],
       [   1,   17,    6, ...,  270,    2,    5]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; big hair big boobs bad music and a giant safety pin these are the words to best describe this
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; this has to be one of the worst films of the 1990s when my friends i were watching this
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="MODEL-NN">MODEL NN<a class="anchor-link" href="#MODEL-NN">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Model buliding</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>  <span class="c1">#Sequential model</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">))</span> <span class="c1">#Init embedding layer with no pretrained wts</span>
<span class="c1">#embedding layer takes input of vocabulary size i.e 10000, embedding dimension i.e 50 and input sequence i.e number of columns of dataset i.e 20</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span> <span class="c1">#Use flatten layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span><span class="c1">#use dropout for regularization</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> <span class="c1">#Hidden layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>  <span class="c1">#use dropout for regularization</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span> <span class="c1">#Output layer</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From C:\Users\sarth\Anaconda3\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what our model have, number of layer , output shape ,etc</span>
<span class="c1">#model summary</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 20, 50)            500000    
_________________________________________________________________
flatten_1 (Flatten)          (None, 1000)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 1000)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                10010     
_________________________________________________________________
dropout_2 (Dropout)          (None, 10)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 11        
=================================================================
Total params: 510,021
Trainable params: 510,021
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From C:\Users\sarth\Anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see shape of input to our model</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[37]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(25000, 20)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Fitting model to xtrain and ytrain with defined epochs and batch size</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
  <span class="n">X_train</span><span class="p">,</span>
  <span class="n">y_train</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
  <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From C:\Users\sarth\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 7s 281us/step - loss: 0.6678 - accuracy: 0.5866 - val_loss: 0.6025 - val_accuracy: 0.6713
Epoch 2/10
25000/25000 [==============================] - 7s 280us/step - loss: 0.5222 - accuracy: 0.7432 - val_loss: 0.5621 - val_accuracy: 0.6970
Epoch 3/10
25000/25000 [==============================] - 7s 273us/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.6042 - val_accuracy: 0.6898
Epoch 4/10
25000/25000 [==============================] - 7s 288us/step - loss: 0.2912 - accuracy: 0.8842 - val_loss: 0.6765 - val_accuracy: 0.6783
Epoch 5/10
25000/25000 [==============================] - 7s 262us/step - loss: 0.2089 - accuracy: 0.9213 - val_loss: 0.7787 - val_accuracy: 0.6711
Epoch 6/10
25000/25000 [==============================] - 7s 270us/step - loss: 0.1584 - accuracy: 0.9412 - val_loss: 0.8733 - val_accuracy: 0.6695
Epoch 7/10
25000/25000 [==============================] - 6s 250us/step - loss: 0.1282 - accuracy: 0.9523 - val_loss: 0.9589 - val_accuracy: 0.6641
Epoch 8/10
25000/25000 [==============================] - 9s 351us/step - loss: 0.1035 - accuracy: 0.9617 - val_loss: 1.0516 - val_accuracy: 0.6654
Epoch 9/10
25000/25000 [==============================] - 7s 265us/step - loss: 0.0902 - accuracy: 0.9670 - val_loss: 1.1338 - val_accuracy: 0.6593
Epoch 10/10
25000/25000 [==============================] - 7s 283us/step - loss: 0.0813 - accuracy: 0.9705 - val_loss: 1.2030 - val_accuracy: 0.6603
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate test set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 1s 45us/step
Test accuracy:  0.6602799892425537
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate train set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 1s 41us/step
Test accuracy:  0.9976400136947632
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NOTE:">NOTE:<a class="anchor-link" href="#NOTE:">&#182;</a></h4><p>After seeing model performance on dataset with sequence length of 20(which is very less as you cannot get all details in review). The model under performed, the accuarcy is very low and the model was going into overfit zone.
Now lets increase sequence length based on the gaph in visualize steps and some calculation</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="NN-WITH-SEQ-LEN-300">NN WITH SEQ LEN 300<a class="anchor-link" href="#NN-WITH-SEQ-LEN-300">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To create list which contain all the sequence length of each review</span>
<span class="n">k</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x_train</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Print k</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[218, 189, 141, 550, 147, 43, 123, 562, 233, 130, 450, 99, 117, 238, 109, 129, 163, 752, 212, 177, 129, 140, 256, 888, 93, 142, 220, 193, 171, 221, 174, 647, 233, 162, 597, 234, 51, 336, 139, 231, 704, 142, 861, 132, 122, 570, 55, 214, 103, 186, 113, 169, 469, 138, 302, 766, 351, 146, 59, 206, 107, 152, 186, 431, 147, 684, 383, 324, 252, 263, 787, 211, 314, 118, 390, 132, 710, 306, 167, 115, 95, 158, 156, 82, 502, 314, 190, 174, 60, 145, 214, 659, 408, 515, 461, 202, 238, 170, 107, 171, 158, 145, 790, 258, 287, 67, 123, 975, 775, 236, 195, 274, 214, 91, 1038, 815, 183, 206, 50, 118, 147, 141, 60, 56, 439, 439, 213, 144, 533, 303, 203, 563, 129, 153, 55, 92, 174, 187, 183, 165, 78, 198, 156, 223, 127, 61, 362, 84, 57, 176, 159, 57, 159, 165, 213, 194, 149, 130, 203, 19, 98, 466, 525, 130, 322, 153, 408, 215, 472, 143, 136, 354, 260, 319, 125, 209, 282, 810, 142, 240, 148, 198, 193, 123, 128, 103, 479, 345, 263, 165, 205, 333, 184, 92, 177, 335, 120, 121, 259, 180, 160, 114, 59, 343, 513, 133, 206, 152, 206, 572, 153, 139, 151, 129, 129, 196, 433, 199, 140, 311, 151, 200, 584, 127, 513, 781, 932, 526, 161, 646, 135, 52, 267, 174, 185, 219, 81, 219, 131, 153, 270, 644, 155, 546, 284, 85, 293, 155, 358, 45, 231, 124, 178, 118, 260, 393, 127, 157, 107, 322, 188, 126, 155, 294, 249, 177, 138, 215, 263, 132, 150, 217, 188, 385, 199, 127, 325, 161, 140, 215, 240, 230, 327, 129, 113, 225, 87, 496, 234, 311, 215, 111, 102, 110, 165, 839, 296, 130, 104, 274, 229, 235, 653, 468, 578, 139, 315, 65, 178, 836, 164, 239, 212, 297, 258, 157, 78, 544, 152, 120, 208, 163, 226, 304, 195, 454, 121, 175, 617, 320, 121, 245, 655, 114, 131, 104, 238, 138, 164, 52, 215, 87, 471, 142, 289, 106, 141, 239, 412, 154, 175, 828, 41, 144, 525, 176, 551, 251, 621, 159, 75, 207, 80, 94, 78, 449, 622, 157, 85, 260, 1011, 444, 326, 586, 118, 270, 360, 95, 640, 315, 138, 573, 434, 313, 128, 1007, 130, 257, 209, 159, 602, 109, 250, 117, 149, 199, 55, 578, 158, 323, 486, 177, 73, 127, 138, 130, 110, 283, 244, 375, 137, 156, 153, 112, 94, 137, 195, 137, 112, 25, 106, 105, 272, 857, 116, 58, 114, 71, 57, 292, 56, 157, 283, 87, 327, 481, 918, 129, 181, 214, 601, 215, 117, 112, 401, 165, 154, 587, 417, 345, 233, 496, 403, 317, 189, 340, 195, 370, 194, 150, 559, 48, 129, 110, 45, 173, 674, 416, 233, 146, 73, 146, 190, 130, 127, 217, 785, 227, 119, 149, 150, 175, 588, 130, 414, 172, 523, 119, 130, 122, 219, 264, 202, 218, 367, 230, 429, 985, 144, 128, 60, 78, 125, 131, 186, 283, 121, 226, 82, 57, 468, 336, 218, 110, 535, 603, 147, 117, 156, 72, 72, 69, 529, 148, 56, 263, 202, 348, 172, 104, 212, 146, 191, 251, 179, 722, 156, 141, 235, 97, 69, 222, 228, 233, 46, 130, 599, 146, 71, 144, 132, 89, 115, 267, 100, 148, 197, 627, 161, 263, 447, 97, 132, 357, 52, 329, 149, 253, 330, 549, 166, 190, 165, 202, 351, 633, 942, 123, 121, 184, 270, 139, 248, 382, 292, 215, 439, 177, 42, 173, 173, 233, 480, 377, 48, 177, 192, 84, 176, 150, 467, 210, 687, 631, 279, 136, 67, 167, 170, 359, 451, 135, 197, 1009, 87, 241, 492, 336, 88, 170, 425, 459, 331, 199, 158, 69, 121, 116, 120, 297, 173, 293, 103, 477, 723, 133, 413, 109, 101, 227, 141, 939, 199, 162, 377, 172, 532, 68, 41, 130, 83, 136, 787, 117, 165, 111, 124, 552, 172, 130, 96, 153, 181, 49, 119, 88, 100, 297, 363, 632, 218, 168, 100, 212, 120, 84, 135, 268, 127, 746, 127, 236, 335, 193, 843, 251, 165, 210, 239, 311, 214, 29, 334, 168, 127, 169, 110, 164, 147, 205, 133, 188, 125, 183, 326, 150, 290, 214, 328, 51, 343, 212, 454, 96, 471, 82, 523, 114, 147, 200, 387, 174, 150, 103, 187, 183, 115, 144, 131, 241, 57, 46, 23, 419, 227, 110, 91, 66, 137, 104, 164, 417, 127, 78, 181, 179, 181, 261, 243, 205, 155, 166, 180, 77, 440, 284, 328, 258, 61, 193, 39, 156, 124, 108, 322, 376, 162, 359, 139, 302, 646, 44, 253, 244, 438, 432, 226, 236, 336, 166, 444, 195, 74, 127, 213, 195, 148, 174, 148, 149, 136, 77, 53, 151, 215, 129, 196, 135, 146, 235, 166, 359, 132, 167, 141, 188, 365, 138, 118, 110, 309, 261, 127, 76, 900, 211, 273, 233, 149, 212, 302, 268, 295, 212, 143, 467, 256, 230, 129, 145, 119, 83, 322, 208, 132, 149, 278, 136, 198, 164, 349, 200, 278, 439, 130, 161, 223, 561, 397, 302, 282, 187, 192, 107, 361, 126, 201, 79, 415, 133, 300, 124, 355, 978, 323, 114, 85, 143, 221, 190, 215, 244, 626, 64, 127, 180, 128, 206, 221, 261, 122, 201, 221, 139, 315, 356, 254, 131, 128, 234, 129, 66, 134, 121, 470, 373, 129, 127, 92, 127, 223, 179, 651, 452, 935, 146, 170, 438, 94, 159, 312, 302, 128, 121, 280, 622, 166, 126, 157, 353, 45, 132, 324, 65, 304, 149, 243, 117, 719, 164, 116, 61, 368, 407, 73, 571, 170, 303, 159, 42, 400, 295, 183, 75, 215, 255, 229, 445, 1000, 494, 128, 580, 130, 59, 189, 526, 116, 114, 544, 118, 111, 420, 250, 258, 188, 139, 89, 135, 58, 173, 84, 150, 170, 159, 152, 170, 74, 213, 41, 250, 124, 533, 84, 186, 126, 183, 125, 153, 282, 146, 149, 215, 122, 68, 139, 128, 113, 252, 168, 434, 298, 181, 216, 152, 99, 182, 135, 169, 103, 109, 218, 62, 1022, 546, 313, 261, 248, 57, 100, 544, 290, 197, 132, 170, 151, 707, 263, 142, 164, 141, 371, 298, 324, 142, 237, 244, 40, 230, 158, 142, 379, 124, 178, 108, 149, 741, 125, 410, 128, 243, 179, 138, 610, 542, 90, 187, 172, 186, 106, 27, 237, 98, 140, 125, 245, 147, 137, 84, 264, 147, 257, 220, 82, 159, 239, 149, 157, 160, 183, 185, 253, 230, 167, 105, 218, 85, 367, 209, 66, 180, 253, 214, 219, 320, 200, 216, 112, 184, 173, 499, 196, 340, 308, 144, 240, 72, 657, 753, 164, 925, 169, 694, 395, 144, 152, 142, 596, 431, 160, 985, 143, 138, 171, 215, 110, 140, 486, 267, 344, 129, 162, 88, 116, 150, 232, 104, 39, 932, 209, 207, 344, 153, 220, 183, 310, 328, 196, 284, 232, 203, 135, 122, 271, 132, 133, 242, 593, 319, 331, 152, 160, 284, 191, 409, 198, 171, 159, 297, 164, 124, 184, 139, 356, 296, 184, 633, 656, 156, 170, 223, 98, 273, 37, 60, 166, 679, 123, 89, 168, 189, 247, 110, 633, 642, 133, 182, 134, 125, 133, 84, 111, 179, 185, 149, 324, 517, 174, 186, 716, 959, 129, 130, 147, 122, 180, 167, 142, 240, 151, 117, 196, 137, 171, 199, 135, 153, 197, 209, 253, 132, 133, 137, 232, 138, 212, 171, 790, 51, 97, 71, 118, 49, 1009, 149, 255, 229, 123, 204, 469, 201, 110, 228, 133, 467, 318, 211, 107, 132, 179, 304, 239, 114, 186, 187, 261, 137, 263, 132, 154, 159, 254, 147, 502, 202, 117, 150, 117, 204, 144, 135, 215, 478, 919, 141, 129, 125, 341, 189, 496, 107, 278, 54, 55, 270, 129, 145, 254, 278, 216, 168, 340, 193, 360, 421, 339, 138, 132, 143, 356, 137, 270, 199, 540, 240, 131, 183, 250, 131, 32, 190, 161, 71, 324, 383, 622, 364, 238, 196, 98, 76, 119, 128, 169, 148, 154, 143, 60, 178, 305, 208, 93, 197, 180, 101, 227, 204, 278, 278, 191, 429, 153, 192, 811, 208, 137, 529, 147, 67, 141, 230, 49, 137, 117, 235, 134, 128, 205, 92, 504, 135, 52, 189, 262, 96, 345, 244, 194, 702, 256, 857, 186, 200, 66, 263, 155, 52, 872, 116, 315, 536, 119, 40, 745, 222, 139, 278, 271, 730, 118, 131, 158, 121, 426, 144, 112, 266, 311, 831, 425, 83, 269, 256, 191, 166, 798, 255, 186, 167, 141, 174, 142, 73, 105, 175, 144, 130, 988, 101, 163, 107, 144, 298, 214, 118, 130, 124, 135, 558, 292, 173, 119, 282, 534, 205, 42, 99, 50, 146, 67, 206, 145, 255, 223, 425, 198, 727, 254, 204, 155, 174, 117, 160, 321, 146, 105, 123, 183, 189, 145, 209, 120, 193, 158, 163, 131, 109, 267, 209, 116, 543, 466, 134, 57, 171, 358, 172, 124, 58, 950, 323, 205, 174, 368, 290, 156, 184, 465, 58, 373, 97, 366, 140, 177, 127, 57, 295, 608, 488, 599, 338, 140, 211, 384, 281, 130, 172, 89, 129, 736, 142, 158, 357, 211, 382, 113, 121, 248, 145, 639, 96, 83, 324, 183, 559, 335, 634, 341, 198, 291, 323, 306, 99, 193, 193, 177, 81, 252, 277, 424, 155, 315, 445, 113, 68, 431, 173, 188, 125, 177, 261, 144, 439, 277, 52, 128, 254, 69, 275, 198, 277, 317, 321, 100, 173, 110, 242, 453, 679, 576, 206, 475, 272, 334, 207, 82, 289, 126, 122, 122, 59, 63, 125, 414, 131, 261, 184, 210, 127, 167, 134, 414, 141, 175, 263, 118, 154, 96, 206, 166, 151, 119, 133, 184, 430, 409, 153, 211, 228, 402, 61, 346, 185, 186, 149, 197, 141, 142, 233, 124, 201, 252, 152, 128, 297, 129, 357, 142, 252, 125, 155, 165, 306, 125, 314, 61, 189, 164, 92, 225, 240, 288, 146, 373, 543, 153, 117, 418, 190, 151, 723, 43, 52, 236, 163, 318, 170, 65, 405, 233, 144, 148, 190, 170, 201, 631, 127, 80, 74, 369, 127, 140, 133, 542, 133, 184, 136, 699, 231, 265, 214, 347, 302, 209, 59, 108, 143, 760, 147, 909, 224, 114, 134, 254, 112, 104, 319, 621, 182, 232, 166, 122, 138, 400, 365, 186, 153, 114, 151, 450, 702, 155, 230, 214, 182, 100, 469, 202, 335, 131, 358, 124, 156, 319, 689, 171, 291, 48, 261, 54, 314, 234, 156, 316, 962, 430, 211, 253, 256, 135, 365, 325, 115, 125, 171, 228, 127, 182, 105, 235, 329, 113, 174, 150, 162, 123, 218, 333, 140, 402, 81, 293, 205, 190, 148, 292, 112, 664, 411, 161, 347, 424, 160, 181, 210, 114, 359, 113, 220, 300, 248, 636, 178, 259, 178, 1015, 378, 152, 924, 475, 997, 279, 145, 148, 125, 136, 65, 107, 124, 139, 184, 135, 410, 256, 148, 122, 83, 56, 462, 126, 61, 101, 121, 271, 1010, 178, 110, 41, 159, 447, 185, 183, 90, 150, 524, 172, 184, 149, 121, 215, 82, 245, 139, 55, 184, 115, 134, 335, 627, 203, 267, 228, 173, 196, 130, 271, 179, 49, 67, 138, 112, 61, 88, 152, 64, 124, 360, 127, 240, 158, 346, 133, 872, 73, 212, 206, 141, 191, 325, 207, 155, 175, 423, 269, 128, 645, 310, 161, 110, 114, 331, 525, 125, 50, 139, 243, 168, 260, 119, 65, 795, 158, 124, 235, 116, 281, 116, 177, 838, 96, 68, 103, 189, 242, 135, 201, 137, 384, 198, 278, 89, 123, 227, 854, 129, 488, 115, 63, 80, 50, 128, 179, 285, 214, 173, 325, 147, 228, 495, 125, 223, 216, 541, 708, 42, 165, 730, 132, 128, 347, 233, 247, 446, 304, 337, 438, 130, 511, 175, 101, 198, 114, 160, 128, 91, 148, 563, 43, 159, 115, 56, 391, 149, 340, 363, 152, 187, 204, 133, 624, 136, 116, 375, 169, 156, 477, 134, 165, 138, 129, 201, 790, 165, 182, 114, 178, 124, 141, 417, 379, 55, 109, 229, 53, 166, 135, 200, 183, 169, 202, 630, 137, 80, 136, 151, 596, 624, 196, 475, 356, 308, 203, 91, 151, 127, 124, 89, 125, 487, 221, 410, 183, 299, 354, 238, 167, 161, 150, 339, 415, 152, 330, 207, 123, 212, 124, 136, 134, 350, 125, 370, 150, 438, 121, 156, 283, 132, 140, 229, 125, 113, 191, 245, 135, 751, 54, 240, 230, 148, 174, 389, 390, 1011, 146, 535, 245, 65, 160, 141, 197, 245, 166, 146, 128, 84, 110, 118, 157, 318, 50, 263, 258, 73, 120, 371, 197, 146, 226, 207, 76, 169, 426, 312, 652, 121, 138, 156, 397, 116, 57, 645, 203, 16, 353, 70, 125, 164, 258, 396, 185, 110, 148, 127, 163, 117, 439, 138, 386, 114, 37, 175, 1034, 238, 125, 52, 406, 640, 131, 526, 180, 75, 190, 182, 267, 126, 191, 697, 162, 371, 155, 276, 257, 152, 351, 80, 139, 133, 143, 75, 112, 226, 112, 186, 145, 209, 315, 120, 758, 93, 220, 128, 137, 129, 328, 648, 443, 159, 125, 39, 160, 456, 402, 48, 112, 91, 142, 125, 758, 835, 228, 188, 185, 70, 667, 128, 300, 157, 392, 229, 442, 64, 123, 49, 47, 680, 139, 92, 166, 221, 234, 724, 119, 263, 462, 159, 120, 105, 188, 115, 184, 419, 155, 292, 1002, 447, 113, 130, 240, 147, 216, 136, 150, 119, 305, 250, 64, 547, 142, 186, 269, 45, 592, 50, 167, 141, 345, 158, 162, 541, 314, 349, 148, 143, 317, 152, 89, 383, 468, 238, 131, 160, 325, 91, 122, 111, 317, 85, 213, 193, 141, 46, 161, 147, 300, 322, 149, 90, 235, 591, 334, 126, 239, 136, 153, 173, 182, 113, 150, 161, 229, 180, 395, 125, 436, 569, 302, 168, 129, 495, 406, 297, 279, 205, 197, 122, 244, 112, 466, 139, 128, 136, 184, 122, 200, 78, 122, 268, 151, 124, 162, 479, 155, 400, 201, 131, 148, 155, 343, 135, 337, 137, 95, 436, 247, 158, 179, 259, 120, 693, 144, 196, 105, 406, 804, 142, 611, 414, 269, 172, 133, 142, 645, 475, 262, 132, 167, 128, 167, 108, 504, 70, 150, 216, 129, 90, 48, 493, 459, 635, 233, 486, 301, 256, 205, 178, 120, 240, 317, 120, 157, 141, 140, 27, 538, 47, 73, 203, 124, 100, 167, 173, 83, 117, 128, 39, 997, 167, 141, 193, 127, 353, 122, 150, 735, 501, 396, 160, 160, 124, 104, 119, 50, 179, 314, 77, 195, 348, 119, 373, 172, 140, 155, 532, 247, 246, 454, 255, 483, 125, 362, 142, 117, 49, 106, 120, 169, 526, 514, 241, 124, 67, 510, 312, 105, 273, 131, 145, 822, 249, 596, 166, 151, 436, 161, 1629, 192, 139, 125, 179, 114, 265, 166, 219, 353, 130, 159, 124, 210, 321, 407, 59, 102, 260, 313, 262, 166, 124, 279, 113, 123, 76, 350, 163, 51, 152, 261, 90, 205, 518, 98, 146, 194, 106, 502, 567, 138, 188, 123, 290, 485, 507, 150, 139, 152, 354, 65, 62, 300, 139, 718, 153, 848, 130, 131, 259, 178, 631, 149, 141, 130, 319, 241, 84, 190, 242, 1036, 133, 86, 202, 173, 497, 104, 229, 483, 102, 249, 327, 436, 56, 236, 328, 454, 49, 232, 382, 475, 180, 125, 323, 350, 106, 175, 272, 227, 146, 117, 134, 123, 182, 395, 413, 103, 245, 259, 188, 207, 117, 382, 112, 244, 148, 174, 77, 222, 107, 605, 74, 295, 158, 498, 469, 117, 51, 274, 149, 61, 118, 457, 265, 209, 45, 229, 349, 595, 445, 158, 284, 111, 146, 158, 468, 54, 538, 237, 164, 237, 197, 593, 115, 111, 122, 250, 163, 224, 275, 659, 336, 201, 197, 601, 104, 185, 435, 538, 128, 167, 234, 220, 335, 398, 46, 491, 809, 163, 108, 746, 126, 175, 116, 433, 220, 823, 153, 135, 110, 52, 644, 231, 485, 53, 338, 334, 176, 173, 144, 165, 61, 226, 481, 122, 159, 164, 470, 829, 143, 105, 416, 315, 197, 408, 362, 254, 331, 68, 107, 54, 534, 282, 162, 71, 688, 133, 71, 122, 116, 178, 659, 223, 140, 303, 423, 191, 989, 333, 136, 832, 1021, 385, 139, 164, 277, 232, 999, 170, 201, 173, 147, 158, 167, 55, 116, 44, 708, 195, 214, 123, 123, 328, 402, 51, 110, 243, 223, 204, 211, 150, 240, 146, 211, 134, 370, 475, 43, 188, 149, 292, 350, 539, 156, 249, 189, 162, 155, 102, 51, 130, 168, 588, 295, 146, 265, 231, 67, 695, 193, 155, 302, 137, 422, 309, 58, 184, 133, 133, 148, 126, 436, 103, 154, 95, 127, 111, 782, 279, 362, 119, 140, 171, 820, 151, 64, 253, 161, 171, 370, 199, 120, 96, 307, 169, 145, 342, 210, 344, 193, 294, 52, 660, 56, 271, 760, 85, 129, 124, 467, 110, 495, 502, 223, 256, 47, 121, 149, 375, 118, 850, 247, 109, 132, 130, 176, 300, 200, 121, 147, 319, 727, 176, 177, 202, 187, 128, 220, 126, 161, 49, 176, 144, 1000, 218, 108, 706, 186, 151, 210, 191, 118, 142, 114, 202, 84, 132, 121, 133, 120, 694, 124, 72, 257, 297, 162, 121, 186, 133, 633, 136, 186, 34, 125, 107, 143, 143, 325, 949, 207, 41, 194, 607, 641, 497, 91, 201, 553, 174, 306, 123, 514, 238, 171, 168, 751, 518, 286, 137, 421, 457, 118, 542, 116, 69, 348, 412, 241, 352, 139, 53, 487, 356, 85, 575, 615, 157, 86, 247, 625, 696, 236, 253, 361, 123, 201, 293, 239, 167, 53, 64, 364, 103, 431, 475, 47, 352, 106, 158, 149, 162, 773, 115, 137, 101, 148, 222, 175, 227, 164, 193, 121, 147, 501, 300, 208, 276, 277, 131, 134, 371, 40, 391, 403, 74, 146, 912, 135, 266, 163, 149, 100, 522, 89, 190, 140, 428, 99, 365, 98, 525, 96, 127, 117, 160, 351, 118, 126, 247, 284, 598, 211, 130, 241, 135, 368, 323, 220, 79, 153, 177, 301, 103, 115, 139, 263, 314, 121, 140, 388, 194, 484, 162, 217, 324, 168, 154, 748, 515, 186, 287, 287, 255, 512, 331, 80, 203, 138, 192, 578, 468, 361, 117, 275, 156, 285, 138, 122, 203, 135, 153, 160, 329, 161, 229, 117, 65, 430, 143, 606, 143, 118, 232, 221, 335, 155, 206, 121, 136, 295, 221, 674, 506, 120, 166, 111, 182, 161, 116, 355, 168, 143, 292, 320, 543, 610, 160, 390, 242, 236, 56, 957, 264, 69, 180, 154, 173, 563, 173, 750, 658, 137, 303, 101, 127, 164, 135, 783, 61, 195, 287, 679, 172, 110, 154, 111, 473, 245, 484, 263, 258, 280, 186, 108, 137, 250, 73, 137, 119, 91, 344, 283, 760, 259, 415, 520, 317, 164, 317, 499, 218, 292, 154, 165, 443, 202, 129, 347, 64, 150, 138, 80, 403, 149, 116, 223, 158, 137, 161, 155, 285, 180, 124, 424, 199, 266, 275, 143, 174, 193, 660, 69, 171, 321, 232, 125, 119, 473, 158, 244, 49, 125, 47, 333, 186, 141, 203, 198, 456, 119, 280, 50, 496, 248, 309, 106, 126, 871, 226, 80, 511, 420, 592, 262, 126, 166, 217, 377, 415, 143, 63, 530, 186, 109, 192, 499, 443, 429, 262, 150, 128, 128, 205, 80, 838, 307, 184, 1030, 565, 220, 54, 127, 208, 110, 569, 112, 251, 140, 155, 187, 165, 266, 255, 135, 168, 220, 187, 785, 128, 513, 171, 136, 622, 63, 73, 267, 125, 587, 67, 138, 197, 174, 686, 141, 260, 240, 167, 133, 424, 148, 270, 366, 72, 319, 195, 119, 151, 517, 268, 120, 111, 126, 178, 48, 146, 185, 210, 254, 62, 241, 30, 532, 214, 81, 222, 94, 50, 163, 305, 343, 691, 267, 208, 125, 142, 70, 180, 255, 229, 349, 294, 125, 158, 100, 266, 171, 596, 163, 169, 467, 406, 89, 310, 125, 387, 208, 117, 488, 1004, 63, 194, 154, 435, 233, 92, 187, 127, 203, 306, 202, 567, 150, 142, 127, 199, 174, 108, 246, 640, 522, 379, 799, 157, 354, 440, 351, 403, 357, 62, 434, 167, 100, 462, 589, 707, 117, 321, 355, 203, 123, 63, 492, 181, 121, 308, 213, 618, 271, 158, 1034, 113, 163, 413, 71, 178, 241, 142, 252, 408, 192, 271, 188, 265, 164, 404, 152, 229, 1112, 136, 116, 279, 339, 166, 317, 259, 436, 188, 81, 504, 224, 126, 1050, 339, 126, 126, 263, 119, 457, 320, 171, 169, 117, 73, 77, 715, 243, 329, 158, 48, 470, 46, 137, 128, 128, 201, 274, 50, 120, 198, 551, 323, 66, 424, 105, 65, 217, 113, 147, 187, 257, 148, 237, 112, 152, 185, 71, 128, 126, 83, 171, 203, 132, 120, 324, 464, 287, 173, 206, 136, 522, 175, 77, 153, 132, 123, 128, 227, 118, 129, 211, 552, 378, 309, 58, 702, 183, 284, 207, 128, 313, 151, 168, 297, 397, 111, 741, 130, 204, 136, 404, 962, 465, 544, 152, 443, 496, 314, 165, 200, 297, 127, 251, 155, 272, 208, 409, 344, 129, 71, 85, 140, 519, 263, 123, 235, 190, 126, 255, 409, 52, 144, 131, 122, 357, 96, 199, 280, 229, 163, 263, 319, 378, 476, 279, 210, 251, 134, 124, 216, 148, 116, 181, 178, 109, 427, 65, 130, 313, 139, 173, 152, 210, 201, 398, 137, 65, 303, 107, 126, 317, 521, 849, 343, 164, 320, 361, 168, 390, 48, 702, 119, 117, 132, 388, 660, 256, 57, 204, 216, 116, 168, 114, 251, 495, 142, 326, 96, 374, 199, 163, 184, 63, 731, 269, 499, 142, 53, 86, 238, 212, 315, 254, 162, 116, 100, 101, 119, 126, 257, 137, 410, 134, 397, 239, 757, 237, 183, 352, 437, 159, 300, 177, 294, 179, 218, 231, 149, 336, 135, 318, 114, 125, 163, 223, 397, 553, 332, 55, 270, 343, 175, 343, 138, 361, 131, 215, 265, 171, 494, 182, 497, 59, 71, 850, 512, 178, 740, 598, 62, 195, 168, 137, 270, 219, 183, 348, 203, 57, 178, 222, 257, 170, 152, 128, 142, 87, 118, 51, 355, 134, 316, 208, 220, 58, 181, 159, 63, 89, 172, 235, 462, 605, 128, 171, 171, 132, 184, 116, 67, 623, 374, 683, 155, 165, 426, 117, 612, 156, 144, 390, 227, 134, 484, 189, 139, 131, 44, 191, 180, 540, 138, 247, 237, 104, 130, 327, 233, 125, 149, 133, 158, 190, 160, 144, 246, 497, 249, 123, 173, 45, 342, 158, 168, 140, 133, 31, 287, 146, 613, 318, 154, 390, 146, 551, 349, 153, 168, 225, 452, 191, 219, 35, 60, 412, 125, 237, 140, 131, 116, 94, 124, 280, 125, 285, 201, 594, 142, 98, 130, 101, 256, 105, 146, 110, 244, 144, 132, 169, 341, 444, 127, 470, 338, 294, 69, 248, 246, 142, 133, 126, 88, 137, 143, 171, 438, 252, 136, 69, 45, 155, 955, 234, 132, 68, 767, 287, 119, 178, 184, 86, 113, 642, 139, 47, 314, 307, 196, 184, 386, 110, 299, 152, 164, 126, 174, 126, 136, 206, 56, 156, 231, 105, 242, 108, 882, 109, 180, 214, 323, 148, 123, 190, 176, 494, 326, 132, 78, 194, 294, 262, 219, 159, 138, 133, 209, 166, 57, 365, 110, 193, 112, 344, 45, 118, 351, 270, 69, 44, 102, 47, 310, 130, 128, 69, 351, 119, 607, 597, 112, 148, 173, 118, 424, 141, 142, 254, 287, 298, 399, 387, 310, 52, 246, 367, 242, 256, 987, 135, 256, 146, 285, 109, 270, 161, 231, 210, 89, 236, 229, 460, 162, 498, 233, 71, 142, 435, 184, 442, 190, 387, 85, 389, 52, 102, 174, 355, 133, 125, 365, 609, 308, 864, 654, 108, 301, 103, 223, 169, 355, 493, 97, 51, 186, 103, 153, 142, 89, 883, 155, 121, 491, 763, 133, 65, 192, 169, 171, 126, 215, 215, 138, 184, 650, 180, 194, 309, 148, 276, 1851, 502, 57, 464, 45, 234, 172, 139, 318, 205, 158, 167, 236, 352, 277, 916, 105, 179, 141, 183, 261, 281, 140, 413, 157, 200, 360, 471, 306, 590, 104, 485, 163, 136, 59, 99, 219, 148, 686, 311, 161, 151, 73, 122, 317, 235, 127, 168, 207, 987, 187, 285, 372, 243, 197, 271, 138, 154, 407, 190, 149, 128, 130, 300, 152, 136, 119, 194, 137, 701, 119, 193, 173, 130, 230, 136, 114, 162, 116, 240, 145, 382, 290, 129, 128, 122, 216, 232, 300, 137, 172, 508, 151, 124, 383, 364, 171, 504, 135, 210, 172, 726, 161, 130, 138, 141, 440, 306, 113, 123, 164, 161, 154, 253, 161, 47, 118, 124, 209, 275, 134, 67, 80, 123, 153, 208, 171, 270, 196, 107, 134, 130, 129, 149, 101, 150, 404, 146, 148, 599, 130, 194, 548, 247, 366, 764, 119, 123, 225, 217, 78, 354, 122, 397, 250, 128, 132, 312, 192, 467, 108, 115, 144, 156, 310, 241, 92, 216, 407, 131, 154, 119, 144, 205, 475, 205, 104, 715, 230, 104, 317, 41, 210, 565, 154, 62, 146, 383, 301, 349, 134, 239, 230, 223, 154, 172, 198, 141, 385, 279, 250, 200, 117, 385, 145, 396, 895, 172, 495, 148, 216, 262, 68, 481, 191, 217, 197, 177, 693, 70, 272, 134, 57, 307, 198, 142, 679, 99, 155, 171, 318, 167, 201, 173, 186, 256, 129, 345, 353, 141, 118, 591, 537, 166, 201, 117, 213, 177, 57, 496, 75, 135, 94, 108, 130, 227, 160, 121, 146, 329, 87, 180, 119, 219, 255, 349, 292, 584, 115, 64, 183, 103, 275, 371, 117, 124, 122, 102, 539, 111, 370, 299, 270, 356, 155, 141, 203, 167, 103, 189, 62, 358, 83, 84, 124, 230, 141, 205, 147, 49, 69, 318, 146, 134, 136, 118, 183, 604, 152, 424, 236, 174, 191, 214, 64, 405, 137, 686, 268, 817, 148, 65, 306, 211, 183, 55, 112, 285, 153, 293, 77, 347, 557, 62, 223, 876, 412, 139, 138, 203, 123, 123, 330, 926, 170, 530, 62, 83, 237, 660, 280, 124, 174, 158, 180, 117, 148, 733, 381, 412, 138, 101, 205, 228, 311, 156, 137, 83, 190, 521, 68, 327, 93, 341, 119, 118, 110, 275, 165, 386, 123, 492, 138, 550, 243, 291, 372, 133, 140, 94, 183, 410, 280, 352, 150, 333, 128, 71, 106, 228, 238, 115, 404, 63, 182, 296, 317, 129, 152, 89, 104, 111, 542, 136, 209, 114, 158, 440, 487, 118, 191, 187, 262, 284, 219, 116, 152, 312, 91, 145, 126, 804, 269, 174, 147, 158, 166, 250, 116, 260, 192, 157, 159, 204, 217, 96, 138, 128, 196, 184, 338, 554, 765, 75, 122, 321, 318, 581, 400, 112, 142, 135, 295, 166, 378, 236, 356, 178, 322, 40, 134, 146, 785, 655, 254, 374, 337, 137, 583, 411, 591, 145, 370, 171, 848, 177, 122, 143, 319, 159, 156, 132, 147, 268, 320, 145, 161, 120, 323, 84, 85, 146, 648, 554, 311, 162, 535, 398, 360, 104, 197, 112, 446, 244, 91, 443, 189, 128, 252, 274, 431, 140, 187, 285, 437, 118, 128, 40, 213, 274, 1014, 153, 275, 135, 114, 114, 142, 229, 136, 374, 328, 118, 285, 153, 87, 124, 176, 130, 243, 148, 189, 108, 222, 99, 247, 136, 108, 217, 416, 143, 432, 132, 868, 123, 128, 103, 69, 551, 279, 107, 363, 127, 124, 168, 679, 78, 241, 220, 69, 536, 218, 311, 206, 317, 133, 87, 132, 125, 453, 393, 79, 154, 96, 486, 43, 237, 115, 593, 119, 134, 193, 321, 298, 118, 428, 167, 354, 424, 108, 159, 185, 173, 102, 454, 497, 87, 35, 340, 856, 135, 133, 135, 177, 397, 206, 178, 105, 643, 206, 145, 160, 225, 201, 729, 125, 216, 160, 195, 695, 127, 99, 219, 150, 190, 305, 337, 179, 245, 162, 96, 134, 309, 820, 536, 210, 162, 96, 130, 261, 124, 310, 178, 121, 67, 184, 252, 130, 235, 137, 127, 126, 164, 55, 115, 46, 352, 136, 267, 124, 62, 198, 106, 198, 227, 201, 150, 802, 258, 368, 146, 118, 29, 527, 160, 45, 338, 290, 446, 482, 172, 117, 740, 231, 362, 185, 253, 143, 146, 129, 279, 61, 460, 129, 315, 240, 122, 169, 287, 173, 112, 313, 237, 209, 159, 20, 125, 116, 124, 197, 238, 84, 74, 149, 189, 283, 288, 127, 375, 113, 148, 208, 185, 46, 131, 193, 184, 478, 125, 140, 127, 180, 114, 161, 149, 127, 141, 233, 211, 240, 135, 233, 374, 183, 136, 185, 538, 80, 271, 113, 192, 84, 171, 700, 267, 126, 297, 196, 247, 239, 53, 207, 184, 868, 116, 129, 181, 463, 218, 324, 435, 546, 169, 142, 148, 118, 146, 364, 181, 131, 164, 285, 315, 214, 382, 758, 154, 119, 417, 201, 220, 147, 240, 69, 238, 229, 133, 211, 158, 562, 121, 121, 168, 459, 171, 227, 171, 137, 207, 163, 557, 168, 380, 148, 231, 286, 54, 402, 204, 120, 123, 260, 204, 203, 132, 303, 243, 321, 73, 189, 324, 244, 443, 256, 183, 132, 184, 221, 328, 141, 193, 129, 258, 122, 101, 251, 132, 439, 200, 146, 373, 175, 131, 311, 223, 431, 215, 377, 360, 640, 266, 340, 140, 199, 134, 146, 155, 349, 164, 152, 212, 202, 129, 307, 198, 196, 153, 106, 122, 142, 120, 95, 973, 169, 301, 161, 110, 629, 399, 264, 790, 506, 147, 131, 252, 122, 287, 147, 209, 152, 325, 186, 332, 167, 165, 284, 182, 273, 334, 244, 320, 448, 721, 142, 266, 623, 191, 209, 138, 177, 115, 79, 322, 269, 213, 56, 183, 285, 151, 358, 206, 51, 394, 37, 134, 141, 144, 106, 321, 216, 519, 144, 221, 532, 131, 643, 356, 137, 137, 204, 209, 146, 96, 194, 121, 155, 155, 150, 129, 461, 244, 199, 199, 92, 131, 329, 129, 121, 150, 166, 252, 198, 405, 382, 102, 133, 138, 727, 109, 134, 152, 456, 517, 175, 191, 387, 490, 143, 833, 208, 182, 324, 127, 131, 96, 171, 146, 1020, 135, 261, 179, 824, 135, 140, 163, 321, 852, 130, 171, 124, 171, 131, 629, 737, 88, 449, 130, 227, 152, 90, 68, 77, 90, 791, 214, 56, 153, 193, 273, 105, 49, 47, 511, 405, 143, 80, 380, 178, 141, 107, 177, 319, 342, 128, 250, 334, 321, 271, 134, 481, 174, 151, 113, 388, 702, 176, 310, 158, 155, 132, 42, 641, 96, 116, 169, 197, 151, 164, 230, 230, 145, 146, 355, 406, 149, 211, 111, 392, 176, 143, 110, 264, 313, 207, 149, 216, 445, 131, 385, 589, 97, 121, 316, 145, 138, 201, 137, 455, 126, 418, 409, 313, 192, 502, 133, 218, 929, 138, 94, 307, 142, 186, 188, 392, 329, 135, 59, 327, 117, 127, 154, 363, 242, 182, 376, 142, 176, 264, 230, 602, 126, 539, 158, 198, 381, 71, 191, 264, 458, 145, 798, 354, 228, 189, 100, 125, 136, 259, 152, 40, 187, 199, 196, 242, 110, 337, 473, 93, 344, 152, 386, 161, 72, 141, 69, 176, 68, 239, 128, 385, 122, 64, 177, 149, 90, 172, 406, 257, 121, 271, 401, 129, 212, 202, 131, 132, 100, 492, 220, 193, 49, 219, 136, 54, 55, 233, 147, 176, 143, 57, 344, 285, 202, 148, 129, 77, 593, 115, 177, 72, 157, 441, 145, 143, 139, 296, 190, 178, 233, 165, 224, 153, 550, 92, 142, 195, 136, 116, 130, 236, 150, 446, 158, 135, 115, 398, 192, 126, 345, 487, 147, 242, 166, 50, 506, 122, 273, 191, 120, 178, 306, 105, 133, 207, 368, 134, 548, 572, 167, 107, 181, 81, 163, 245, 492, 166, 127, 153, 155, 61, 168, 156, 142, 294, 149, 134, 248, 92, 143, 141, 223, 260, 56, 169, 179, 177, 450, 169, 52, 179, 148, 400, 82, 142, 127, 165, 51, 300, 45, 183, 145, 262, 134, 268, 722, 418, 138, 160, 121, 95, 166, 448, 176, 115, 188, 416, 212, 163, 93, 707, 1010, 131, 512, 150, 172, 296, 123, 239, 311, 676, 309, 436, 514, 125, 359, 116, 155, 363, 378, 129, 130, 169, 278, 426, 126, 615, 118, 243, 163, 258, 45, 111, 163, 140, 824, 148, 438, 48, 424, 424, 817, 131, 59, 150, 92, 127, 77, 270, 76, 330, 262, 198, 80, 529, 176, 119, 770, 51, 376, 161, 133, 481, 327, 259, 198, 75, 443, 128, 185, 395, 186, 888, 683, 183, 532, 47, 124, 144, 177, 120, 143, 286, 490, 136, 199, 150, 65, 170, 585, 160, 530, 68, 157, 107, 132, 242, 256, 158, 62, 136, 401, 229, 464, 488, 76, 222, 147, 116, 143, 184, 81, 217, 68, 713, 135, 349, 947, 144, 134, 155, 132, 253, 272, 37, 210, 165, 129, 137, 107, 176, 182, 118, 479, 50, 293, 183, 107, 160, 83, 168, 138, 193, 126, 199, 315, 123, 263, 136, 202, 53, 99, 253, 130, 156, 290, 122, 960, 243, 77, 115, 565, 178, 563, 122, 165, 293, 133, 200, 50, 260, 297, 26, 195, 205, 217, 114, 387, 246, 74, 325, 148, 83, 508, 374, 192, 135, 40, 161, 159, 136, 216, 212, 307, 127, 319, 106, 310, 108, 173, 230, 263, 163, 570, 288, 202, 401, 121, 93, 214, 184, 134, 413, 272, 62, 139, 310, 390, 218, 221, 135, 168, 131, 138, 131, 163, 273, 150, 112, 282, 452, 56, 206, 138, 63, 133, 125, 184, 294, 811, 349, 199, 365, 568, 65, 137, 162, 152, 305, 96, 150, 139, 134, 321, 443, 122, 149, 87, 136, 134, 95, 181, 794, 607, 188, 522, 127, 681, 104, 155, 565, 215, 100, 55, 611, 191, 132, 117, 200, 152, 162, 95, 598, 338, 90, 57, 327, 200, 580, 290, 441, 212, 313, 238, 125, 578, 119, 319, 228, 135, 752, 181, 156, 63, 191, 236, 116, 304, 144, 144, 323, 164, 279, 235, 197, 245, 118, 193, 383, 157, 111, 378, 295, 134, 94, 134, 149, 139, 158, 45, 212, 100, 279, 268, 319, 122, 265, 220, 217, 329, 187, 334, 168, 92, 132, 189, 382, 613, 233, 63, 150, 393, 120, 135, 47, 264, 169, 409, 197, 397, 415, 129, 213, 158, 484, 138, 145, 491, 61, 205, 154, 196, 441, 116, 341, 147, 421, 613, 270, 134, 154, 70, 117, 335, 146, 72, 203, 141, 124, 263, 277, 332, 169, 140, 252, 86, 346, 214, 60, 309, 218, 165, 171, 69, 131, 313, 257, 147, 73, 560, 97, 479, 147, 202, 921, 72, 129, 247, 113, 287, 196, 260, 585, 175, 217, 219, 380, 135, 116, 155, 77, 146, 316, 135, 484, 137, 122, 120, 75, 90, 253, 1003, 224, 233, 51, 586, 388, 140, 130, 118, 266, 351, 576, 62, 228, 70, 298, 263, 103, 188, 96, 340, 261, 268, 246, 133, 57, 168, 165, 215, 488, 245, 255, 293, 173, 437, 194, 559, 56, 124, 153, 173, 107, 236, 285, 879, 348, 370, 153, 172, 205, 106, 192, 189, 191, 418, 347, 88, 321, 450, 130, 75, 112, 171, 478, 125, 154, 119, 128, 315, 173, 150, 180, 79, 180, 145, 137, 183, 638, 139, 82, 167, 216, 72, 220, 64, 135, 172, 374, 181, 395, 121, 698, 163, 128, 132, 259, 197, 189, 46, 71, 117, 82, 536, 171, 157, 313, 187, 273, 72, 166, 552, 429, 347, 84, 283, 273, 66, 138, 257, 170, 150, 129, 196, 128, 388, 481, 298, 345, 112, 58, 103, 554, 124, 133, 346, 594, 176, 127, 223, 322, 190, 296, 146, 381, 115, 205, 71, 161, 300, 142, 137, 165, 118, 124, 160, 173, 185, 53, 142, 125, 116, 403, 54, 87, 323, 125, 135, 59, 115, 321, 206, 232, 317, 333, 1111, 135, 114, 126, 264, 153, 246, 140, 132, 380, 171, 132, 167, 219, 252, 724, 176, 197, 159, 130, 567, 153, 42, 115, 124, 351, 134, 141, 214, 191, 344, 105, 147, 981, 225, 130, 264, 178, 148, 188, 234, 466, 281, 62, 38, 111, 147, 150, 229, 121, 232, 341, 487, 224, 327, 264, 232, 793, 159, 864, 62, 174, 312, 53, 331, 272, 113, 167, 55, 408, 428, 241, 110, 500, 138, 195, 158, 160, 205, 201, 36, 466, 202, 917, 86, 73, 150, 168, 133, 288, 140, 79, 208, 131, 144, 169, 99, 128, 45, 119, 97, 244, 132, 64, 427, 560, 153, 694, 255, 89, 332, 308, 79, 199, 795, 268, 144, 229, 174, 154, 44, 74, 211, 330, 584, 342, 68, 135, 62, 124, 254, 235, 305, 130, 76, 161, 154, 570, 434, 99, 201, 123, 222, 252, 202, 43, 331, 369, 160, 49, 132, 279, 159, 165, 56, 152, 488, 374, 80, 126, 133, 499, 242, 229, 219, 222, 906, 120, 426, 402, 408, 99, 159, 120, 130, 540, 524, 262, 113, 153, 172, 205, 137, 198, 912, 236, 129, 49, 125, 358, 57, 580, 83, 122, 102, 270, 568, 129, 183, 116, 139, 124, 806, 123, 318, 394, 100, 561, 270, 285, 141, 37, 117, 126, 141, 259, 187, 529, 256, 144, 129, 992, 107, 167, 379, 146, 128, 50, 54, 227, 281, 195, 96, 122, 158, 210, 128, 36, 120, 167, 72, 140, 145, 109, 494, 293, 743, 116, 123, 74, 135, 86, 303, 231, 360, 449, 47, 132, 284, 207, 159, 131, 253, 404, 308, 366, 116, 57, 508, 182, 208, 705, 250, 346, 301, 246, 349, 124, 168, 575, 115, 139, 326, 114, 257, 161, 1016, 120, 237, 133, 127, 68, 661, 475, 184, 360, 148, 132, 171, 250, 223, 86, 265, 123, 351, 153, 145, 224, 157, 166, 133, 130, 52, 55, 147, 136, 439, 135, 604, 262, 297, 117, 585, 113, 183, 220, 251, 201, 215, 405, 185, 221, 376, 224, 175, 151, 135, 127, 86, 169, 114, 110, 216, 364, 62, 26, 161, 133, 134, 839, 201, 328, 57, 189, 83, 112, 227, 151, 139, 127, 203, 215, 295, 266, 145, 334, 123, 136, 243, 155, 566, 409, 118, 405, 161, 260, 105, 154, 1010, 268, 359, 166, 219, 42, 262, 406, 177, 373, 203, 325, 123, 227, 121, 479, 146, 201, 160, 631, 199, 878, 115, 210, 395, 124, 141, 262, 151, 164, 186, 104, 89, 142, 129, 580, 184, 143, 248, 228, 168, 434, 133, 110, 145, 376, 148, 137, 91, 182, 161, 78, 124, 180, 150, 118, 319, 259, 233, 322, 332, 55, 384, 99, 621, 403, 136, 253, 110, 132, 204, 150, 162, 125, 487, 192, 44, 138, 155, 112, 323, 404, 235, 423, 175, 209, 44, 152, 220, 116, 76, 71, 430, 521, 84, 145, 318, 273, 115, 166, 358, 238, 149, 175, 277, 381, 151, 135, 277, 562, 189, 149, 756, 224, 260, 241, 789, 216, 139, 831, 223, 223, 158, 159, 151, 296, 161, 426, 267, 142, 145, 254, 170, 142, 141, 99, 185, 139, 159, 97, 186, 308, 110, 404, 149, 452, 256, 276, 171, 52, 368, 117, 115, 187, 161, 74, 197, 151, 250, 215, 259, 167, 914, 323, 265, 185, 178, 50, 118, 286, 75, 203, 156, 106, 201, 140, 181, 276, 120, 384, 462, 678, 111, 45, 126, 151, 482, 274, 128, 180, 348, 683, 110, 664, 548, 117, 149, 800, 203, 562, 297, 176, 59, 226, 165, 80, 36, 124, 137, 112, 119, 160, 377, 227, 185, 256, 95, 149, 150, 82, 97, 963, 568, 130, 203, 439, 880, 144, 180, 140, 92, 71, 122, 305, 280, 150, 253, 381, 242, 201, 545, 277, 214, 377, 250, 125, 225, 143, 119, 117, 57, 133, 257, 197, 53, 74, 426, 132, 132, 44, 90, 242, 133, 174, 169, 126, 182, 52, 175, 119, 163, 528, 130, 158, 118, 219, 244, 126, 281, 162, 83, 989, 216, 176, 163, 193, 536, 103, 958, 442, 176, 144, 180, 239, 191, 58, 868, 119, 149, 181, 243, 130, 62, 133, 244, 230, 534, 171, 152, 166, 592, 204, 145, 140, 198, 126, 494, 223, 236, 127, 153, 531, 112, 126, 295, 207, 145, 526, 133, 148, 179, 89, 165, 152, 104, 255, 417, 130, 219, 232, 432, 45, 182, 134, 236, 103, 421, 256, 152, 102, 196, 102, 339, 104, 164, 127, 110, 142, 352, 125, 146, 147, 179, 139, 281, 296, 409, 123, 279, 216, 34, 168, 229, 462, 274, 154, 500, 127, 144, 186, 238, 130, 78, 201, 79, 157, 164, 135, 313, 38, 423, 138, 255, 251, 215, 117, 141, 186, 172, 194, 207, 37, 232, 142, 135, 154, 519, 134, 240, 117, 141, 158, 133, 355, 187, 97, 11, 213, 407, 98, 845, 341, 268, 74, 147, 71, 940, 237, 83, 157, 139, 600, 125, 155, 156, 328, 129, 57, 454, 146, 114, 210, 236, 144, 979, 126, 361, 179, 147, 131, 197, 241, 45, 438, 473, 225, 248, 111, 145, 101, 155, 84, 274, 130, 160, 137, 130, 601, 53, 334, 181, 135, 290, 153, 291, 121, 308, 199, 155, 195, 204, 143, 156, 64, 264, 398, 274, 190, 189, 184, 75, 185, 114, 484, 239, 191, 123, 110, 484, 137, 146, 381, 125, 284, 312, 144, 154, 202, 274, 148, 197, 340, 174, 168, 599, 50, 224, 327, 425, 154, 255, 170, 124, 281, 217, 160, 244, 92, 117, 202, 127, 104, 137, 129, 154, 288, 384, 165, 276, 794, 158, 620, 165, 160, 130, 344, 119, 137, 377, 144, 601, 152, 738, 267, 699, 409, 121, 45, 199, 207, 364, 133, 297, 342, 112, 201, 970, 115, 588, 530, 354, 135, 46, 258, 49, 169, 622, 299, 146, 138, 222, 245, 453, 690, 551, 237, 55, 124, 130, 272, 138, 131, 378, 133, 128, 216, 188, 421, 219, 79, 145, 105, 251, 220, 625, 317, 463, 133, 149, 118, 101, 134, 178, 192, 143, 182, 168, 568, 85, 198, 672, 158, 101, 422, 131, 63, 364, 170, 146, 471, 238, 88, 185, 352, 207, 800, 57, 202, 213, 98, 126, 268, 60, 192, 131, 334, 109, 141, 162, 192, 41, 45, 416, 180, 132, 130, 193, 139, 325, 429, 82, 226, 129, 108, 143, 93, 178, 253, 396, 345, 181, 295, 146, 237, 212, 444, 466, 46, 102, 163, 557, 213, 49, 220, 302, 358, 396, 177, 217, 109, 140, 246, 44, 144, 664, 130, 100, 75, 68, 150, 126, 183, 134, 121, 364, 151, 35, 170, 237, 138, 136, 355, 198, 214, 149, 153, 28, 83, 308, 147, 175, 273, 262, 118, 260, 197, 576, 127, 279, 124, 124, 123, 56, 123, 290, 192, 470, 76, 62, 240, 133, 68, 157, 130, 66, 283, 73, 451, 150, 106, 143, 104, 220, 170, 120, 168, 333, 125, 528, 165, 108, 56, 528, 175, 130, 134, 102, 390, 212, 205, 63, 37, 365, 257, 54, 109, 205, 155, 179, 118, 423, 124, 457, 158, 795, 246, 179, 323, 83, 560, 39, 456, 101, 214, 646, 316, 458, 119, 222, 51, 187, 51, 122, 299, 295, 363, 205, 189, 255, 133, 126, 107, 110, 383, 152, 412, 286, 303, 261, 502, 236, 111, 285, 220, 181, 158, 159, 225, 350, 188, 328, 136, 826, 111, 1014, 270, 208, 209, 105, 610, 73, 122, 473, 183, 171, 302, 758, 190, 98, 118, 356, 325, 843, 119, 190, 125, 179, 137, 154, 230, 352, 330, 147, 283, 74, 191, 579, 106, 149, 103, 168, 136, 254, 172, 313, 333, 157, 125, 262, 142, 166, 141, 162, 51, 287, 153, 231, 200, 296, 232, 174, 418, 133, 331, 228, 155, 119, 176, 162, 569, 259, 273, 134, 154, 135, 44, 275, 73, 183, 194, 461, 159, 107, 139, 236, 131, 78, 223, 197, 168, 480, 240, 150, 595, 158, 310, 773, 158, 342, 382, 301, 45, 27, 132, 194, 133, 216, 76, 177, 538, 143, 210, 418, 415, 266, 725, 142, 116, 526, 514, 61, 323, 102, 147, 150, 168, 271, 119, 135, 166, 135, 251, 144, 285, 57, 197, 138, 190, 958, 307, 167, 610, 220, 124, 373, 190, 198, 128, 220, 129, 184, 652, 422, 262, 65, 116, 289, 269, 658, 261, 174, 250, 92, 106, 202, 190, 250, 626, 11, 246, 424, 141, 247, 214, 326, 124, 256, 228, 178, 124, 335, 108, 157, 39, 150, 198, 731, 159, 131, 137, 93, 526, 241, 236, 46, 283, 214, 333, 173, 272, 188, 560, 238, 129, 566, 445, 411, 693, 37, 163, 129, 125, 246, 40, 220, 116, 130, 95, 713, 149, 503, 219, 112, 274, 65, 58, 151, 317, 105, 112, 69, 162, 139, 272, 172, 222, 64, 457, 88, 193, 208, 192, 299, 125, 111, 274, 180, 431, 156, 237, 47, 593, 142, 346, 190, 85, 47, 343, 151, 499, 130, 132, 309, 274, 707, 161, 136, 213, 149, 241, 716, 148, 236, 194, 94, 87, 140, 453, 346, 184, 147, 293, 133, 320, 314, 223, 175, 517, 632, 565, 354, 361, 68, 461, 145, 121, 262, 101, 155, 231, 439, 597, 945, 627, 85, 151, 253, 197, 307, 170, 294, 224, 202, 119, 129, 206, 71, 42, 116, 285, 581, 159, 944, 536, 137, 193, 58, 717, 137, 138, 380, 139, 124, 131, 213, 284, 928, 93, 327, 210, 212, 206, 184, 155, 408, 139, 185, 180, 81, 283, 253, 561, 94, 207, 50, 363, 211, 116, 125, 112, 481, 181, 153, 226, 107, 46, 135, 92, 46, 125, 124, 198, 286, 172, 194, 209, 168, 240, 120, 152, 147, 173, 218, 140, 155, 224, 83, 214, 413, 523, 293, 185, 203, 191, 74, 193, 133, 286, 268, 157, 84, 185, 141, 205, 143, 342, 134, 94, 120, 158, 342, 584, 211, 278, 120, 200, 26, 113, 98, 339, 254, 450, 616, 143, 138, 222, 103, 168, 243, 186, 125, 144, 139, 318, 133, 116, 91, 102, 310, 148, 118, 111, 206, 164, 146, 94, 112, 359, 181, 41, 180, 338, 232, 386, 241, 124, 174, 74, 274, 131, 319, 158, 131, 317, 678, 146, 66, 114, 156, 166, 156, 397, 155, 144, 134, 1300, 190, 131, 612, 119, 418, 486, 799, 245, 190, 152, 273, 214, 159, 771, 136, 159, 46, 182, 116, 583, 121, 125, 236, 134, 266, 363, 326, 58, 147, 214, 23, 220, 156, 570, 584, 371, 45, 172, 250, 136, 133, 337, 226, 133, 155, 162, 132, 114, 136, 310, 1394, 53, 131, 241, 115, 201, 149, 411, 709, 127, 192, 144, 92, 864, 340, 428, 109, 120, 144, 262, 159, 231, 203, 168, 198, 130, 115, 201, 242, 203, 619, 274, 110, 139, 285, 130, 166, 29, 141, 363, 455, 145, 221, 127, 130, 132, 131, 277, 162, 118, 89, 149, 307, 454, 146, 188, 120, 200, 100, 124, 139, 176, 127, 134, 177, 261, 793, 137, 198, 130, 260, 125, 151, 206, 268, 52, 47, 109, 202, 996, 93, 380, 256, 153, 636, 138, 114, 126, 124, 78, 258, 162, 256, 1006, 150, 157, 148, 376, 319, 283, 104, 156, 217, 73, 511, 722, 126, 177, 71, 195, 263, 73, 286, 38, 141, 114, 264, 250, 385, 229, 127, 42, 575, 133, 1009, 230, 399, 230, 153, 187, 175, 153, 381, 225, 291, 232, 383, 317, 121, 231, 128, 192, 142, 271, 136, 145, 310, 195, 173, 185, 101, 177, 57, 329, 158, 40, 130, 617, 44, 78, 559, 184, 749, 88, 926, 299, 134, 253, 109, 206, 924, 104, 229, 384, 44, 132, 512, 177, 586, 224, 109, 399, 351, 847, 68, 257, 208, 481, 182, 167, 54, 76, 111, 398, 149, 246, 450, 140, 136, 394, 593, 179, 219, 228, 188, 98, 178, 153, 165, 408, 87, 42, 129, 299, 143, 428, 111, 320, 1033, 347, 407, 196, 128, 314, 134, 56, 152, 41, 196, 213, 84, 154, 288, 161, 351, 64, 207, 167, 245, 588, 442, 148, 495, 188, 197, 168, 149, 277, 211, 134, 252, 348, 280, 119, 129, 199, 278, 538, 375, 349, 138, 598, 122, 209, 146, 319, 185, 343, 600, 265, 284, 79, 43, 407, 131, 641, 135, 159, 203, 248, 122, 205, 100, 167, 147, 142, 208, 360, 120, 141, 304, 239, 731, 143, 1013, 143, 193, 118, 122, 129, 166, 182, 202, 407, 241, 529, 166, 261, 269, 130, 346, 71, 105, 224, 183, 152, 163, 166, 50, 137, 306, 452, 425, 104, 576, 249, 355, 127, 647, 155, 261, 168, 320, 657, 384, 499, 151, 62, 139, 58, 200, 109, 150, 669, 127, 63, 201, 327, 69, 139, 137, 198, 69, 59, 184, 214, 252, 177, 282, 128, 70, 344, 109, 327, 147, 92, 157, 694, 114, 273, 227, 51, 602, 124, 122, 125, 119, 151, 155, 128, 150, 184, 174, 356, 105, 172, 208, 50, 179, 122, 189, 191, 71, 115, 160, 682, 207, 57, 212, 179, 367, 193, 142, 276, 194, 268, 1015, 57, 135, 193, 230, 189, 359, 146, 228, 378, 268, 236, 194, 49, 124, 132, 119, 248, 160, 794, 122, 300, 250, 307, 150, 198, 279, 176, 126, 95, 191, 429, 145, 63, 120, 155, 154, 561, 214, 161, 331, 132, 304, 258, 183, 413, 315, 441, 251, 71, 127, 252, 222, 143, 175, 111, 145, 523, 553, 148, 626, 85, 862, 285, 267, 129, 131, 415, 382, 275, 132, 788, 68, 179, 701, 163, 449, 76, 134, 81, 482, 477, 147, 147, 132, 95, 204, 144, 97, 159, 147, 131, 114, 635, 127, 104, 360, 119, 243, 59, 143, 577, 137, 131, 51, 160, 462, 343, 240, 746, 446, 220, 166, 674, 116, 100, 183, 278, 183, 114, 288, 60, 236, 204, 133, 304, 155, 444, 132, 89, 177, 209, 477, 266, 121, 108, 309, 125, 161, 852, 548, 143, 161, 138, 241, 290, 109, 177, 152, 309, 494, 198, 197, 159, 122, 52, 92, 201, 120, 163, 122, 156, 231, 267, 234, 428, 331, 283, 111, 118, 306, 125, 167, 149, 283, 950, 140, 340, 231, 145, 234, 146, 134, 99, 162, 112, 112, 40, 506, 142, 110, 180, 64, 204, 515, 145, 149, 340, 134, 138, 256, 77, 387, 108, 107, 94, 324, 289, 134, 268, 125, 455, 440, 420, 78, 440, 945, 126, 215, 123, 177, 127, 70, 71, 285, 213, 141, 43, 137, 791, 278, 319, 212, 180, 125, 118, 148, 135, 179, 129, 467, 162, 183, 93, 161, 335, 144, 400, 107, 481, 146, 152, 318, 228, 156, 397, 148, 170, 450, 169, 55, 120, 253, 63, 119, 223, 1001, 62, 133, 133, 488, 129, 132, 352, 320, 130, 180, 218, 105, 275, 105, 275, 153, 109, 230, 134, 397, 229, 493, 134, 133, 131, 239, 227, 77, 195, 173, 314, 304, 417, 57, 132, 433, 54, 121, 300, 168, 292, 123, 233, 105, 814, 203, 150, 107, 373, 130, 146, 426, 190, 178, 187, 131, 104, 69, 234, 205, 375, 349, 447, 134, 87, 297, 166, 184, 502, 141, 183, 124, 154, 764, 120, 54, 160, 39, 594, 178, 200, 137, 241, 54, 351, 217, 376, 89, 257, 404, 165, 138, 346, 47, 183, 279, 281, 227, 120, 247, 329, 364, 122, 148, 466, 746, 92, 129, 271, 260, 81, 474, 237, 88, 148, 551, 319, 221, 308, 73, 153, 227, 265, 90, 146, 117, 98, 440, 435, 145, 147, 530, 372, 209, 147, 255, 248, 716, 286, 130, 141, 86, 135, 681, 117, 141, 59, 787, 351, 167, 357, 215, 120, 244, 378, 43, 220, 105, 50, 123, 142, 163, 244, 164, 281, 274, 126, 119, 143, 119, 707, 71, 170, 164, 296, 352, 158, 188, 118, 130, 196, 257, 46, 406, 183, 71, 83, 191, 125, 303, 129, 156, 322, 190, 148, 170, 37, 329, 141, 207, 124, 372, 69, 939, 161, 128, 300, 340, 300, 176, 232, 198, 815, 172, 486, 262, 149, 430, 178, 89, 138, 309, 425, 127, 138, 401, 122, 1023, 137, 243, 192, 113, 85, 203, 107, 528, 190, 386, 140, 309, 145, 253, 257, 270, 194, 123, 92, 99, 140, 123, 265, 131, 303, 180, 157, 166, 156, 157, 121, 92, 155, 120, 223, 265, 214, 571, 255, 320, 296, 118, 232, 501, 129, 179, 117, 184, 251, 235, 235, 116, 140, 405, 366, 200, 149, 91, 119, 137, 82, 138, 282, 136, 549, 147, 218, 152, 183, 172, 152, 136, 331, 71, 227, 196, 78, 183, 446, 116, 145, 132, 110, 213, 142, 55, 154, 156, 98, 410, 70, 46, 446, 472, 334, 125, 380, 245, 719, 169, 277, 217, 124, 136, 249, 389, 104, 282, 270, 145, 109, 218, 125, 168, 269, 130, 134, 233, 191, 140, 201, 454, 116, 60, 170, 367, 207, 808, 97, 123, 281, 100, 660, 595, 187, 170, 126, 299, 162, 88, 249, 116, 155, 369, 712, 121, 204, 563, 106, 597, 150, 529, 127, 127, 134, 301, 91, 348, 147, 623, 150, 370, 116, 73, 45, 408, 573, 169, 47, 177, 77, 332, 142, 138, 123, 128, 205, 50, 80, 282, 88, 304, 433, 212, 162, 152, 204, 49, 79, 427, 551, 259, 361, 175, 329, 151, 512, 274, 139, 186, 250, 169, 112, 132, 223, 145, 239, 174, 571, 104, 758, 92, 208, 198, 140, 479, 156, 309, 60, 141, 143, 119, 399, 115, 336, 380, 154, 256, 987, 44, 132, 191, 309, 272, 271, 158, 71, 84, 158, 128, 152, 379, 43, 87, 202, 190, 137, 81, 221, 186, 179, 257, 139, 336, 297, 173, 344, 521, 64, 368, 242, 143, 310, 192, 200, 227, 203, 127, 136, 331, 159, 200, 438, 103, 142, 140, 139, 273, 404, 490, 119, 192, 353, 355, 160, 169, 178, 546, 170, 75, 175, 125, 94, 46, 113, 385, 123, 154, 63, 252, 132, 45, 328, 87, 200, 499, 161, 37, 87, 335, 401, 138, 164, 253, 117, 159, 219, 126, 347, 128, 363, 268, 241, 586, 164, 117, 562, 133, 565, 277, 470, 293, 153, 228, 209, 222, 162, 45, 253, 147, 84, 90, 112, 280, 172, 104, 669, 70, 162, 129, 133, 29, 165, 82, 147, 109, 191, 154, 297, 613, 184, 253, 141, 102, 214, 118, 118, 200, 152, 132, 140, 131, 148, 144, 71, 276, 135, 207, 208, 510, 123, 160, 195, 317, 142, 126, 135, 155, 341, 297, 262, 132, 117, 110, 191, 123, 141, 865, 145, 138, 301, 146, 154, 129, 205, 149, 303, 163, 244, 496, 375, 138, 253, 189, 264, 381, 214, 114, 304, 99, 172, 213, 588, 399, 360, 127, 249, 579, 764, 275, 123, 413, 159, 315, 164, 577, 147, 163, 138, 279, 119, 77, 257, 156, 133, 162, 51, 241, 123, 140, 109, 200, 122, 153, 74, 154, 225, 153, 90, 115, 99, 166, 70, 247, 125, 160, 433, 138, 657, 640, 602, 188, 317, 140, 617, 150, 248, 120, 140, 147, 132, 137, 306, 133, 480, 68, 84, 757, 140, 427, 117, 176, 655, 417, 325, 369, 262, 407, 151, 171, 250, 175, 45, 321, 138, 387, 475, 283, 122, 255, 366, 459, 334, 125, 120, 75, 130, 400, 540, 123, 49, 258, 120, 132, 132, 145, 90, 173, 228, 146, 109, 84, 60, 226, 124, 90, 159, 120, 969, 505, 119, 231, 232, 91, 168, 185, 283, 360, 290, 80, 203, 1015, 167, 119, 128, 440, 219, 351, 129, 130, 169, 182, 122, 128, 64, 135, 137, 337, 183, 150, 130, 626, 311, 124, 74, 160, 350, 94, 231, 138, 143, 100, 140, 773, 126, 255, 161, 114, 86, 264, 203, 263, 168, 307, 263, 147, 162, 1733, 452, 69, 286, 175, 156, 169, 612, 248, 211, 164, 420, 313, 198, 213, 80, 77, 150, 208, 136, 366, 67, 171, 79, 360, 1034, 160, 330, 309, 153, 90, 97, 164, 281, 520, 255, 662, 228, 480, 479, 166, 105, 183, 33, 53, 333, 900, 72, 297, 1000, 195, 416, 169, 152, 120, 92, 246, 157, 132, 333, 150, 251, 102, 159, 163, 121, 210, 208, 473, 95, 357, 147, 187, 138, 625, 145, 70, 145, 172, 174, 174, 163, 102, 929, 270, 210, 129, 235, 130, 151, 234, 96, 582, 177, 192, 176, 132, 160, 184, 314, 201, 107, 198, 507, 157, 203, 390, 139, 245, 350, 416, 79, 145, 241, 591, 62, 607, 167, 158, 375, 257, 194, 91, 127, 358, 259, 680, 366, 180, 154, 994, 179, 729, 96, 137, 457, 259, 476, 177, 237, 258, 54, 839, 182, 212, 282, 164, 182, 221, 201, 63, 173, 290, 68, 154, 225, 190, 104, 140, 318, 249, 221, 134, 848, 204, 246, 195, 488, 121, 419, 45, 201, 290, 289, 145, 951, 153, 199, 200, 109, 163, 190, 84, 175, 397, 101, 307, 249, 129, 219, 474, 180, 114, 125, 155, 365, 110, 163, 140, 181, 126, 127, 177, 330, 293, 133, 130, 397, 228, 175, 69, 138, 653, 229, 341, 166, 210, 127, 82, 179, 157, 321, 134, 116, 145, 520, 612, 90, 147, 41, 121, 308, 144, 119, 211, 210, 438, 175, 250, 187, 245, 241, 237, 161, 146, 589, 132, 540, 65, 221, 98, 76, 79, 331, 613, 205, 104, 175, 760, 231, 197, 93, 244, 114, 254, 230, 88, 132, 66, 105, 230, 157, 76, 198, 159, 118, 187, 130, 371, 161, 343, 276, 788, 199, 116, 165, 233, 608, 85, 323, 472, 116, 232, 207, 421, 620, 284, 124, 552, 101, 130, 154, 456, 139, 1020, 121, 758, 265, 973, 96, 122, 146, 88, 1002, 47, 352, 506, 167, 209, 151, 40, 266, 241, 146, 141, 248, 927, 140, 154, 48, 104, 229, 93, 42, 151, 102, 126, 150, 230, 392, 138, 175, 395, 125, 334, 1016, 158, 143, 45, 205, 154, 294, 295, 147, 323, 454, 441, 335, 169, 588, 179, 168, 529, 374, 51, 180, 79, 202, 269, 268, 145, 171, 239, 113, 130, 257, 143, 165, 620, 239, 164, 491, 81, 489, 199, 204, 132, 134, 187, 132, 115, 112, 558, 610, 451, 343, 150, 433, 324, 108, 468, 143, 304, 120, 275, 271, 250, 307, 80, 546, 90, 127, 119, 161, 121, 134, 58, 1092, 109, 229, 152, 304, 250, 69, 279, 331, 280, 371, 112, 152, 471, 155, 75, 225, 129, 287, 111, 428, 254, 196, 95, 358, 98, 137, 124, 127, 182, 700, 49, 129, 520, 586, 170, 173, 164, 179, 338, 183, 202, 174, 647, 304, 62, 123, 162, 135, 147, 180, 89, 336, 120, 59, 125, 138, 418, 208, 340, 233, 911, 69, 228, 225, 272, 378, 128, 309, 248, 382, 346, 1036, 117, 56, 176, 148, 99, 194, 255, 134, 136, 153, 155, 44, 47, 156, 218, 130, 59, 407, 153, 146, 217, 84, 271, 181, 320, 146, 113, 293, 181, 65, 113, 163, 458, 300, 223, 592, 392, 74, 157, 85, 414, 121, 169, 365, 235, 232, 360, 198, 136, 150, 351, 66, 240, 366, 364, 37, 155, 162, 469, 163, 129, 122, 194, 202, 815, 368, 199, 53, 133, 167, 964, 245, 363, 122, 170, 203, 239, 214, 124, 426, 107, 536, 127, 329, 218, 179, 209, 125, 140, 178, 58, 117, 143, 110, 141, 433, 185, 112, 205, 132, 159, 496, 139, 217, 166, 498, 356, 275, 625, 56, 211, 287, 178, 985, 48, 58, 158, 294, 668, 186, 121, 125, 251, 628, 352, 210, 226, 345, 133, 106, 390, 134, 110, 168, 201, 355, 213, 157, 311, 367, 163, 161, 153, 162, 337, 249, 165, 78, 80, 127, 437, 160, 355, 159, 137, 339, 95, 745, 136, 212, 195, 263, 154, 155, 546, 139, 75, 76, 62, 186, 292, 148, 171, 242, 150, 142, 64, 130, 170, 128, 125, 411, 102, 470, 36, 233, 379, 262, 56, 115, 61, 119, 160, 147, 86, 156, 260, 131, 108, 184, 117, 119, 185, 181, 127, 132, 167, 210, 141, 684, 449, 394, 371, 254, 216, 119, 70, 380, 357, 125, 392, 125, 43, 700, 150, 209, 97, 195, 118, 134, 359, 121, 200, 866, 67, 50, 119, 252, 203, 134, 80, 96, 501, 277, 609, 121, 254, 230, 149, 173, 283, 270, 336, 74, 203, 113, 169, 113, 43, 157, 54, 287, 218, 322, 129, 200, 299, 128, 174, 168, 181, 130, 129, 104, 171, 126, 423, 155, 73, 347, 40, 102, 247, 412, 132, 223, 159, 197, 71, 140, 131, 747, 58, 297, 257, 539, 217, 596, 184, 62, 141, 279, 187, 248, 179, 271, 128, 306, 334, 99, 180, 169, 117, 326, 117, 145, 174, 76, 210, 240, 168, 119, 261, 160, 184, 515, 103, 119, 225, 137, 116, 404, 292, 132, 363, 156, 355, 255, 38, 232, 271, 247, 64, 89, 116, 146, 138, 85, 155, 533, 141, 127, 149, 118, 38, 196, 215, 72, 186, 129, 653, 106, 134, 335, 214, 256, 128, 155, 337, 99, 206, 195, 343, 837, 127, 121, 143, 165, 236, 183, 205, 766, 377, 276, 191, 215, 272, 205, 125, 489, 191, 158, 694, 452, 145, 165, 345, 484, 182, 129, 136, 212, 365, 247, 185, 199, 301, 156, 125, 172, 870, 299, 393, 108, 99, 220, 130, 114, 174, 236, 330, 159, 453, 113, 79, 209, 258, 128, 306, 89, 175, 536, 122, 222, 133, 398, 171, 108, 131, 297, 220, 108, 148, 296, 349, 113, 277, 248, 63, 468, 321, 333, 247, 167, 320, 582, 471, 706, 109, 107, 303, 160, 224, 270, 132, 120, 221, 424, 275, 135, 122, 144, 122, 130, 283, 138, 26, 217, 127, 134, 142, 187, 833, 153, 170, 124, 197, 123, 64, 258, 113, 57, 100, 134, 817, 356, 143, 150, 174, 158, 199, 53, 899, 140, 161, 114, 704, 154, 57, 178, 193, 410, 1000, 755, 458, 115, 156, 365, 466, 85, 898, 35, 426, 251, 164, 63, 116, 670, 411, 252, 985, 131, 285, 117, 250, 356, 204, 125, 546, 146, 141, 263, 252, 122, 1011, 129, 278, 105, 52, 150, 105, 84, 347, 418, 129, 118, 120, 192, 180, 199, 169, 276, 307, 326, 151, 183, 146, 199, 268, 234, 139, 521, 167, 109, 141, 83, 278, 819, 302, 202, 313, 163, 209, 161, 163, 457, 1546, 106, 129, 243, 186, 101, 297, 128, 195, 131, 112, 554, 229, 256, 144, 144, 220, 457, 123, 160, 167, 242, 217, 139, 70, 299, 418, 122, 154, 185, 464, 126, 114, 84, 399, 137, 217, 86, 33, 127, 129, 293, 113, 116, 233, 604, 342, 199, 131, 643, 274, 1022, 86, 189, 43, 80, 265, 141, 146, 179, 294, 300, 278, 857, 208, 80, 310, 103, 215, 248, 195, 67, 84, 299, 331, 313, 215, 261, 351, 186, 137, 232, 164, 69, 129, 168, 189, 174, 376, 65, 104, 477, 117, 364, 58, 863, 863, 274, 145, 322, 301, 151, 61, 125, 123, 244, 103, 100, 142, 191, 261, 139, 271, 142, 225, 173, 123, 212, 227, 565, 483, 444, 391, 343, 257, 134, 250, 131, 143, 326, 122, 205, 274, 358, 47, 201, 68, 827, 135, 115, 132, 218, 156, 129, 243, 67, 183, 64, 186, 199, 127, 260, 136, 215, 264, 196, 111, 296, 138, 112, 155, 159, 79, 143, 320, 182, 133, 221, 470, 268, 100, 43, 137, 48, 168, 291, 164, 125, 69, 123, 196, 159, 453, 177, 132, 149, 346, 231, 117, 312, 229, 149, 171, 79, 267, 213, 193, 353, 225, 608, 135, 138, 81, 142, 338, 70, 256, 136, 137, 92, 136, 142, 529, 160, 88, 166, 172, 149, 628, 341, 236, 650, 197, 529, 496, 158, 222, 128, 176, 222, 65, 157, 130, 418, 1162, 126, 55, 82, 174, 198, 634, 293, 171, 576, 140, 283, 125, 178, 323, 192, 145, 147, 151, 298, 173, 149, 139, 148, 181, 132, 66, 153, 54, 631, 60, 205, 190, 529, 58, 268, 192, 107, 409, 144, 157, 251, 159, 125, 221, 105, 664, 113, 291, 76, 156, 122, 237, 209, 133, 157, 172, 63, 549, 130, 171, 89, 172, 375, 124, 81, 124, 121, 218, 391, 275, 712, 90, 161, 197, 489, 160, 119, 276, 173, 162, 579, 452, 155, 277, 120, 686, 183, 173, 307, 529, 199, 36, 116, 993, 220, 106, 195, 134, 148, 128, 313, 114, 220, 49, 530, 339, 918, 151, 144, 67, 135, 151, 145, 121, 189, 291, 83, 474, 364, 288, 299, 132, 45, 162, 210, 89, 382, 257, 122, 50, 124, 138, 184, 460, 131, 252, 66, 426, 380, 89, 225, 645, 76, 130, 163, 205, 332, 229, 263, 433, 132, 82, 123, 136, 138, 296, 117, 495, 101, 80, 250, 565, 213, 150, 122, 100, 324, 146, 141, 143, 54, 440, 138, 138, 110, 169, 44, 125, 243, 334, 78, 227, 69, 223, 162, 341, 253, 309, 343, 362, 170, 239, 152, 131, 175, 140, 97, 190, 576, 201, 521, 114, 167, 116, 297, 133, 264, 957, 151, 152, 77, 301, 177, 247, 134, 211, 340, 215, 174, 141, 158, 73, 194, 260, 346, 217, 147, 377, 110, 197, 105, 112, 196, 183, 175, 81, 509, 304, 583, 201, 211, 118, 363, 124, 570, 185, 241, 209, 19, 249, 356, 320, 209, 158, 512, 58, 812, 116, 117, 200, 387, 148, 465, 140, 365, 174, 120, 235, 536, 35, 139, 73, 129, 154, 401, 52, 647, 392, 324, 135, 211, 69, 222, 52, 146, 155, 193, 502, 391, 263, 268, 157, 47, 301, 181, 188, 714, 158, 130, 263, 220, 94, 31, 189, 139, 176, 135, 213, 96, 154, 154, 74, 264, 247, 139, 532, 370, 53, 118, 80, 185, 136, 129, 126, 138, 119, 242, 153, 234, 172, 188, 302, 417, 235, 302, 165, 115, 131, 169, 275, 35, 207, 328, 123, 33, 247, 157, 246, 75, 256, 156, 280, 61, 161, 217, 200, 286, 190, 151, 175, 167, 240, 173, 745, 255, 173, 119, 211, 508, 552, 168, 112, 219, 102, 186, 1222, 146, 104, 156, 198, 336, 144, 337, 446, 110, 121, 145, 197, 182, 479, 878, 257, 252, 118, 207, 502, 158, 146, 125, 218, 132, 71, 70, 144, 167, 171, 362, 254, 71, 157, 155, 94, 403, 137, 166, 163, 144, 66, 244, 157, 396, 440, 58, 292, 221, 163, 82, 80, 124, 443, 165, 133, 167, 349, 140, 164, 120, 96, 136, 559, 183, 266, 233, 181, 255, 114, 157, 269, 90, 292, 162, 129, 82, 264, 243, 157, 148, 382, 195, 109, 137, 121, 171, 145, 115, 217, 139, 134, 54, 80, 216, 129, 87, 267, 435, 172, 181, 331, 68, 364, 153, 107, 332, 413, 122, 1000, 149, 122, 550, 71, 82, 152, 225, 136, 162, 250, 153, 150, 107, 151, 249, 123, 192, 142, 333, 123, 267, 236, 412, 148, 138, 218, 273, 246, 302, 348, 138, 246, 358, 267, 103, 169, 45, 382, 325, 226, 128, 247, 112, 224, 253, 168, 168, 210, 29, 180, 117, 127, 226, 411, 208, 154, 259, 143, 357, 219, 88, 104, 60, 172, 110, 120, 116, 124, 343, 276, 225, 156, 764, 138, 575, 253, 173, 184, 157, 215, 143, 326, 113, 193, 137, 261, 314, 294, 141, 90, 227, 185, 173, 244, 72, 45, 148, 737, 308, 149, 166, 691, 63, 151, 217, 55, 173, 331, 470, 244, 189, 163, 150, 128, 183, 240, 112, 283, 407, 145, 464, 131, 85, 187, 501, 178, 104, 136, 61, 458, 73, 238, 131, 115, 85, 98, 350, 193, 223, 120, 198, 104, 53, 124, 133, 157, 127, 343, 127, 466, 42, 86, 210, 617, 292, 253, 110, 201, 110, 350, 306, 119, 56, 149, 283, 132, 120, 334, 347, 63, 140, 146, 136, 373, 136, 308, 653, 192, 552, 56, 149, 139, 142, 151, 474, 122, 540, 310, 53, 139, 153, 59, 144, 209, 397, 124, 150, 133, 171, 502, 464, 54, 79, 141, 47, 258, 127, 131, 763, 163, 148, 29, 423, 142, 166, 50, 400, 118, 188, 97, 169, 179, 292, 279, 226, 324, 226, 87, 184, 164, 140, 123, 147, 259, 175, 88, 161, 132, 108, 99, 173, 225, 55, 146, 683, 75, 255, 59, 440, 157, 84, 160, 178, 147, 211, 205, 49, 154, 136, 294, 342, 128, 245, 153, 124, 484, 110, 447, 136, 150, 586, 239, 141, 114, 1023, 128, 108, 216, 223, 512, 123, 57, 66, 148, 269, 150, 214, 190, 110, 320, 217, 172, 619, 91, 394, 209, 186, 92, 143, 371, 177, 752, 135, 535, 248, 138, 196, 296, 386, 156, 160, 161, 135, 138, 313, 158, 233, 471, 153, 295, 182, 240, 592, 167, 62, 71, 228, 138, 61, 72, 231, 166, 446, 397, 453, 300, 300, 193, 610, 233, 348, 163, 182, 198, 121, 355, 199, 481, 136, 40, 136, 72, 518, 185, 158, 271, 130, 117, 180, 142, 60, 142, 195, 157, 124, 193, 195, 192, 63, 389, 325, 288, 254, 148, 539, 214, 137, 241, 172, 355, 216, 490, 242, 197, 63, 336, 365, 129, 134, 164, 120, 332, 85, 272, 249, 120, 98, 141, 217, 200, 141, 598, 191, 45, 117, 73, 635, 808, 168, 198, 669, 142, 352, 205, 262, 207, 977, 783, 58, 327, 167, 197, 237, 258, 116, 198, 133, 195, 357, 246, 54, 221, 251, 289, 171, 188, 369, 527, 179, 97, 156, 589, 186, 313, 286, 229, 321, 115, 179, 77, 320, 777, 119, 388, 189, 130, 316, 437, 185, 161, 76, 130, 411, 183, 797, 139, 129, 454, 149, 366, 129, 61, 386, 83, 141, 122, 119, 125, 229, 449, 46, 115, 281, 553, 221, 468, 153, 123, 61, 119, 156, 199, 150, 511, 426, 409, 160, 115, 170, 620, 159, 305, 89, 149, 74, 134, 214, 173, 391, 35, 123, 1006, 83, 203, 393, 58, 100, 107, 283, 126, 494, 112, 188, 438, 232, 120, 113, 135, 190, 79, 237, 170, 217, 53, 145, 314, 196, 628, 165, 241, 135, 32, 265, 115, 205, 123, 159, 120, 44, 98, 376, 61, 331, 170, 127, 677, 139, 579, 59, 163, 226, 302, 221, 157, 741, 838, 182, 39, 156, 553, 500, 618, 267, 62, 255, 398, 275, 160, 126, 294, 86, 124, 119, 303, 282, 258, 79, 93, 117, 260, 75, 263, 294, 268, 438, 216, 279, 144, 184, 126, 323, 165, 107, 124, 214, 136, 229, 207, 652, 68, 239, 198, 150, 233, 153, 207, 137, 134, 87, 139, 98, 136, 80, 105, 413, 208, 370, 174, 652, 252, 292, 121, 434, 567, 427, 196, 118, 996, 134, 68, 193, 294, 131, 88, 218, 121, 171, 735, 97, 372, 233, 55, 173, 138, 150, 575, 388, 64, 184, 156, 117, 116, 130, 485, 161, 257, 531, 162, 192, 117, 121, 97, 268, 136, 161, 116, 143, 275, 368, 336, 61, 122, 146, 121, 339, 152, 130, 173, 124, 215, 182, 39, 187, 232, 191, 577, 682, 463, 142, 81, 160, 123, 342, 207, 97, 420, 73, 221, 145, 472, 379, 229, 568, 221, 201, 119, 753, 243, 155, 467, 112, 89, 271, 436, 109, 174, 587, 308, 396, 104, 137, 197, 171, 130, 210, 139, 305, 262, 155, 140, 499, 168, 274, 623, 1008, 358, 142, 242, 275, 269, 157, 134, 131, 239, 250, 80, 809, 270, 163, 141, 263, 262, 130, 151, 145, 241, 256, 122, 93, 391, 142, 137, 293, 251, 162, 120, 378, 169, 52, 217, 493, 245, 93, 295, 298, 152, 148, 476, 626, 168, 190, 81, 348, 389, 78, 106, 157, 255, 163, 408, 404, 128, 146, 137, 154, 321, 212, 117, 358, 195, 139, 255, 181, 179, 122, 160, 134, 414, 199, 500, 193, 128, 91, 462, 97, 343, 51, 94, 186, 132, 43, 287, 104, 559, 58, 79, 687, 81, 141, 163, 229, 104, 105, 51, 64, 398, 188, 204, 83, 191, 135, 520, 86, 592, 113, 146, 104, 147, 202, 222, 61, 286, 235, 202, 650, 107, 92, 148, 146, 287, 148, 335, 80, 1009, 127, 229, 388, 563, 95, 149, 139, 154, 116, 166, 354, 510, 28, 287, 115, 199, 490, 62, 191, 180, 127, 527, 115, 261, 126, 194, 200, 114, 217, 139, 320, 234, 80, 141, 38, 92, 411, 259, 408, 107, 469, 517, 140, 209, 131, 206, 184, 100, 88, 127, 140, 63, 199, 169, 230, 638, 65, 191, 195, 138, 197, 300, 222, 1003, 122, 120, 788, 143, 119, 429, 280, 107, 121, 205, 420, 405, 128, 294, 166, 272, 94, 131, 283, 692, 374, 73, 166, 383, 166, 138, 52, 55, 166, 358, 163, 145, 83, 135, 110, 166, 143, 269, 136, 129, 813, 289, 135, 75, 61, 300, 181, 148, 144, 175, 242, 183, 176, 545, 107, 65, 275, 376, 166, 146, 165, 186, 139, 115, 208, 266, 725, 153, 298, 216, 244, 123, 197, 764, 955, 181, 96, 196, 167, 93, 415, 133, 102, 285, 129, 211, 71, 226, 192, 143, 424, 371, 70, 218, 176, 79, 118, 238, 336, 154, 620, 128, 145, 249, 250, 74, 140, 120, 252, 135, 190, 210, 459, 50, 120, 692, 130, 455, 232, 166, 193, 222, 140, 448, 799, 444, 309, 164, 132, 279, 128, 211, 368, 246, 114, 842, 188, 290, 230, 142, 203, 141, 435, 843, 267, 205, 334, 62, 56, 337, 93, 361, 159, 537, 103, 129, 147, 811, 199, 216, 146, 531, 142, 240, 154, 77, 257, 262, 244, 713, 211, 113, 209, 155, 110, 92, 235, 250, 163, 322, 170, 162, 273, 330, 131, 174, 108, 304, 53, 123, 88, 234, 269, 184, 125, 122, 135, 119, 136, 121, 167, 31, 138, 140, 491, 171, 133, 145, 162, 180, 129, 187, 258, 134, 113, 67, 249, 170, 116, 194, 172, 916, 262, 260, 180, 196, 112, 269, 404, 252, 152, 159, 409, 111, 471, 155, 147, 955, 186, 349, 219, 138, 172, 179, 174, 242, 117, 171, 356, 233, 166, 365, 388, 83, 144, 132, 200, 173, 325, 216, 345, 159, 120, 386, 195, 125, 118, 90, 155, 76, 109, 163, 103, 125, 289, 758, 229, 246, 423, 130, 210, 48, 271, 219, 235, 137, 113, 60, 56, 230, 61, 561, 133, 329, 155, 166, 565, 150, 163, 489, 150, 322, 455, 95, 171, 135, 120, 198, 312, 326, 68, 211, 551, 71, 128, 126, 132, 69, 253, 181, 150, 40, 176, 135, 227, 122, 183, 79, 253, 506, 172, 58, 88, 481, 271, 121, 127, 400, 59, 231, 677, 181, 417, 137, 139, 109, 116, 642, 129, 743, 158, 104, 159, 115, 230, 576, 289, 271, 199, 113, 211, 516, 114, 177, 110, 123, 257, 906, 153, 123, 365, 144, 132, 264, 120, 192, 185, 204, 133, 94, 169, 90, 223, 85, 389, 228, 404, 56, 185, 202, 528, 625, 189, 151, 77, 259, 151, 256, 648, 121, 132, 429, 499, 121, 136, 251, 80, 127, 150, 85, 167, 267, 338, 162, 115, 176, 110, 239, 424, 760, 325, 165, 272, 155, 149, 224, 284, 312, 129, 301, 919, 264, 308, 203, 525, 129, 302, 223, 193, 125, 120, 138, 311, 325, 152, 128, 351, 76, 147, 188, 209, 689, 348, 168, 133, 312, 168, 172, 147, 119, 48, 130, 149, 284, 88, 314, 205, 235, 214, 122, 551, 119, 113, 208, 208, 45, 283, 193, 55, 208, 121, 56, 226, 486, 313, 137, 127, 128, 162, 272, 360, 134, 468, 235, 143, 272, 274, 207, 194, 203, 143, 153, 52, 78, 538, 523, 235, 380, 116, 232, 319, 65, 134, 252, 91, 269, 232, 330, 138, 96, 130, 156, 246, 502, 126, 108, 102, 107, 368, 135, 255, 130, 156, 191, 216, 102, 122, 158, 944, 109, 595, 119, 275, 121, 129, 472, 630, 180, 100, 78, 401, 302, 151, 211, 139, 846, 551, 70, 194, 120, 162, 155, 125, 278, 150, 823, 94, 153, 630, 124, 195, 624, 268, 105, 388, 321, 368, 107, 727, 412, 876, 286, 136, 315, 132, 292, 1015, 127, 205, 257, 221, 284, 88, 227, 498, 700, 582, 188, 213, 78, 126, 84, 191, 88, 817, 203, 509, 225, 140, 127, 183, 134, 243, 146, 73, 519, 222, 128, 216, 202, 143, 133, 180, 65, 285, 161, 175, 205, 274, 113, 148, 268, 252, 174, 166, 119, 143, 198, 272, 155, 381, 171, 230, 379, 167, 76, 559, 173, 359, 43, 46, 429, 191, 119, 223, 186, 308, 400, 36, 56, 319, 114, 229, 159, 645, 144, 211, 43, 36, 165, 122, 244, 41, 108, 82, 307, 423, 48, 198, 202, 676, 191, 154, 693, 983, 54, 367, 118, 560, 137, 163, 139, 133, 474, 412, 288, 146, 206, 377, 120, 165, 239, 306, 52, 84, 193, 479, 442, 176, 279, 141, 198, 68, 223, 179, 401, 337, 98, 191, 292, 909, 189, 244, 131, 151, 348, 224, 268, 200, 253, 123, 302, 241, 168, 379, 177, 128, 193, 137, 339, 725, 125, 272, 69, 136, 140, 183, 669, 135, 423, 236, 383, 393, 109, 174, 147, 104, 202, 139, 310, 72, 48, 133, 404, 292, 83, 195, 181, 141, 131, 635, 550, 92, 121, 119, 383, 163, 42, 128, 250, 123, 241, 176, 130, 130, 147, 124, 156, 406, 138, 165, 142, 138, 459, 45, 262, 220, 120, 166, 219, 149, 511, 285, 131, 534, 178, 92, 107, 140, 269, 113, 211, 982, 50, 373, 470, 162, 185, 170, 328, 166, 223, 144, 298, 567, 160, 176, 213, 182, 126, 202, 442, 281, 469, 453, 75, 105, 201, 248, 139, 348, 679, 140, 159, 316, 95, 151, 181, 971, 307, 394, 149, 113, 63, 631, 100, 205, 503, 306, 95, 141, 119, 222, 171, 116, 277, 1005, 12, 553, 164, 118, 149, 672, 184, 53, 124, 328, 170, 234, 268, 143, 67, 154, 476, 984, 361, 49, 56, 828, 168, 163, 413, 146, 132, 217, 129, 236, 214, 104, 355, 194, 267, 207, 152, 168, 52, 374, 112, 362, 828, 435, 188, 122, 1030, 486, 143, 528, 158, 203, 270, 205, 144, 560, 166, 69, 155, 66, 110, 114, 251, 335, 238, 444, 143, 552, 864, 154, 108, 146, 60, 234, 165, 471, 70, 383, 48, 484, 50, 94, 255, 144, 511, 159, 138, 230, 131, 196, 130, 82, 154, 67, 119, 371, 139, 484, 424, 343, 415, 189, 358, 254, 481, 126, 171, 229, 165, 370, 88, 193, 155, 246, 221, 208, 143, 113, 219, 165, 157, 160, 185, 149, 200, 739, 221, 144, 79, 68, 124, 136, 82, 345, 108, 128, 166, 192, 59, 93, 357, 173, 380, 739, 207, 69, 132, 314, 153, 135, 131, 78, 272, 179, 127, 155, 133, 201, 350, 119, 167, 310, 298, 376, 395, 149, 42, 146, 156, 151, 606, 187, 138, 60, 145, 221, 69, 100, 201, 591, 182, 104, 108, 129, 120, 40, 142, 260, 131, 183, 310, 127, 286, 88, 86, 160, 265, 139, 141, 222, 146, 190, 807, 212, 64, 106, 89, 228, 109, 47, 609, 215, 300, 124, 202, 64, 162, 87, 413, 155, 122, 351, 343, 61, 262, 343, 307, 294, 218, 274, 194, 216, 224, 116, 103, 135, 694, 203, 75, 424, 195, 165, 233, 475, 165, 177, 184, 378, 266, 139, 349, 281, 982, 1008, 84, 103, 424, 159, 155, 127, 136, 407, 97, 283, 130, 182, 151, 177, 149, 214, 368, 260, 171, 419, 600, 233, 233, 315, 174, 420, 175, 187, 140, 233, 125, 142, 322, 42, 372, 57, 277, 81, 133, 108, 207, 132, 432, 575, 158, 187, 225, 295, 425, 15, 391, 279, 169, 254, 313, 469, 141, 50, 174, 148, 117, 104, 639, 344, 315, 127, 998, 206, 122, 394, 77, 145, 202, 380, 251, 468, 89, 114, 186, 122, 257, 154, 584, 126, 136, 150, 472, 141, 436, 833, 149, 112, 192, 318, 124, 278, 213, 134, 189, 372, 389, 228, 210, 173, 122, 164, 497, 84, 64, 178, 194, 111, 212, 84, 174, 380, 149, 158, 246, 150, 142, 422, 181, 638, 200, 345, 144, 58, 172, 141, 968, 131, 123, 245, 241, 239, 130, 575, 294, 142, 454, 196, 143, 295, 162, 138, 231, 155, 146, 182, 128, 361, 332, 86, 112, 86, 193, 149, 132, 231, 189, 156, 235, 218, 417, 97, 125, 69, 143, 151, 209, 128, 163, 158, 126, 54, 379, 146, 387, 649, 134, 128, 120, 476, 106, 74, 83, 153, 137, 368, 123, 146, 169, 134, 134, 451, 129, 179, 282, 128, 337, 706, 70, 159, 156, 196, 64, 190, 134, 176, 245, 233, 155, 133, 189, 307, 361, 986, 220, 396, 119, 330, 152, 145, 145, 193, 1036, 192, 86, 129, 259, 495, 207, 187, 47, 757, 993, 136, 89, 212, 670, 412, 35, 122, 168, 147, 254, 343, 385, 223, 106, 227, 622, 199, 369, 523, 276, 262, 268, 171, 176, 713, 403, 1006, 153, 190, 118, 314, 557, 132, 286, 263, 466, 215, 869, 395, 124, 179, 125, 147, 214, 159, 113, 314, 218, 53, 97, 952, 127, 128, 187, 615, 156, 107, 197, 232, 125, 190, 124, 326, 353, 262, 359, 182, 315, 178, 176, 279, 249, 248, 321, 83, 178, 944, 96, 203, 245, 95, 141, 86, 124, 202, 135, 55, 263, 221, 216, 169, 435, 132, 170, 174, 181, 203, 374, 232, 238, 220, 695, 270, 400, 277, 116, 283, 120, 208, 318, 136, 127, 625, 407, 151, 105, 225, 163, 428, 401, 280, 187, 373, 243, 348, 123, 184, 204, 385, 59, 193, 558, 158, 127, 414, 298, 305, 279, 314, 131, 160, 255, 397, 331, 124, 79, 168, 134, 113, 112, 143, 94, 165, 179, 174, 210, 239, 130, 308, 174, 247, 331, 115, 172, 97, 263, 187, 295, 183, 168, 144, 40, 101, 236, 235, 159, 172, 144, 674, 159, 193, 156, 161, 646, 133, 286, 241, 170, 221, 337, 562, 141, 157, 106, 413, 138, 163, 546, 281, 175, 182, 185, 731, 487, 99, 235, 68, 156, 66, 322, 351, 210, 53, 207, 137, 151, 518, 470, 310, 186, 215, 118, 574, 135, 278, 150, 140, 115, 161, 267, 169, 140, 371, 120, 151, 89, 111, 92, 274, 121, 225, 361, 436, 115, 1854, 191, 105, 139, 149, 101, 138, 222, 139, 89, 174, 266, 170, 342, 227, 231, 65, 426, 247, 155, 405, 91, 280, 230, 131, 1015, 346, 126, 175, 275, 227, 339, 112, 185, 62, 370, 113, 71, 488, 159, 138, 126, 185, 260, 237, 273, 114, 170, 187, 113, 247, 244, 307, 298, 789, 144, 123, 256, 120, 369, 298, 310, 86, 125, 443, 313, 138, 61, 624, 589, 164, 159, 200, 72, 207, 89, 117, 131, 129, 83, 215, 121, 126, 622, 371, 147, 89, 158, 604, 145, 626, 244, 333, 138, 197, 143, 237, 159, 223, 172, 247, 195, 120, 153, 191, 64, 121, 202, 594, 686, 367, 369, 178, 908, 95, 431, 118, 321, 184, 249, 517, 80, 208, 47, 190, 272, 249, 507, 371, 123, 125, 238, 636, 248, 107, 366, 483, 978, 83, 221, 382, 111, 150, 114, 399, 196, 205, 302, 109, 213, 131, 71, 141, 52, 375, 193, 153, 242, 200, 236, 197, 1018, 45, 141, 56, 133, 142, 640, 183, 166, 173, 175, 232, 124, 188, 133, 162, 338, 237, 182, 214, 440, 371, 382, 154, 196, 125, 279, 121, 150, 165, 176, 260, 165, 31, 194, 285, 444, 165, 103, 264, 157, 209, 183, 306, 127, 495, 690, 83, 125, 139, 61, 94, 134, 50, 389, 294, 67, 382, 80, 581, 159, 143, 204, 280, 201, 239, 160, 266, 119, 57, 276, 344, 149, 265, 248, 54, 123, 159, 154, 123, 152, 219, 171, 244, 214, 292, 359, 164, 50, 167, 158, 230, 133, 251, 103, 743, 387, 501, 240, 326, 103, 198, 426, 542, 57, 168, 629, 391, 205, 494, 132, 313, 184, 122, 195, 181, 58, 35, 122, 112, 199, 300, 206, 136, 454, 128, 228, 178, 138, 210, 57, 163, 377, 165, 256, 252, 144, 115, 128, 356, 200, 204, 236, 275, 202, 233, 132, 123, 166, 772, 237, 70, 171, 342, 269, 293, 58, 268, 287, 153, 222, 455, 124, 116, 141, 106, 169, 139, 161, 208, 286, 291, 262, 143, 500, 267, 134, 224, 223, 135, 163, 161, 141, 236, 51, 292, 430, 176, 417, 585, 193, 649, 161, 195, 268, 162, 114, 532, 328, 140, 109, 195, 304, 187, 621, 124, 139, 140, 164, 168, 128, 202, 128, 174, 354, 170, 780, 97, 159, 207, 154, 289, 598, 143, 13, 133, 508, 292, 441, 259, 161, 211, 362, 342, 296, 163, 141, 124, 203, 82, 132, 745, 140, 77, 453, 194, 221, 210, 461, 158, 290, 265, 148, 150, 130, 376, 826, 137, 139, 487, 122, 519, 143, 89, 314, 141, 466, 242, 302, 305, 170, 310, 76, 161, 226, 573, 593, 1003, 185, 120, 190, 496, 118, 661, 215, 292, 527, 699, 217, 195, 495, 83, 149, 129, 168, 251, 381, 137, 190, 154, 402, 110, 102, 297, 256, 877, 240, 158, 334, 189, 411, 182, 444, 371, 360, 91, 319, 146, 272, 89, 676, 191, 60, 405, 64, 148, 45, 122, 168, 207, 241, 125, 114, 127, 104, 243, 129, 153, 169, 100, 735, 433, 286, 144, 511, 121, 317, 132, 145, 478, 710, 329, 156, 85, 204, 78, 166, 126, 136, 95, 319, 303, 242, 133, 239, 171, 178, 140, 351, 109, 311, 96, 184, 411, 509, 610, 748, 182, 255, 199, 187, 137, 641, 129, 255, 133, 135, 328, 228, 137, 361, 135, 56, 186, 102, 182, 409, 536, 604, 107, 156, 757, 158, 377, 225, 147, 272, 304, 260, 302, 105, 192, 114, 445, 260, 240, 164, 238, 280, 271, 185, 618, 731, 118, 158, 257, 300, 165, 118, 169, 115, 1306, 423, 94, 189, 121, 146, 37, 873, 175, 139, 206, 182, 155, 115, 852, 196, 175, 131, 310, 95, 61, 507, 398, 203, 407, 342, 274, 113, 108, 233, 165, 417, 189, 168, 165, 61, 396, 79, 308, 115, 294, 144, 293, 515, 124, 246, 410, 156, 190, 118, 547, 142, 114, 239, 611, 147, 725, 195, 566, 102, 138, 398, 777, 303, 174, 663, 49, 519, 234, 208, 164, 145, 315, 287, 206, 148, 143, 175, 44, 110, 223, 672, 215, 127, 18, 132, 59, 69, 120, 130, 166, 200, 157, 93, 428, 129, 73, 96, 166, 248, 361, 52, 119, 106, 329, 429, 150, 424, 231, 527, 84, 112, 205, 192, 41, 78, 73, 130, 143, 215, 670, 175, 218, 84, 69, 147, 207, 129, 92, 248, 168, 776, 581, 238, 846, 306, 788, 167, 162, 351, 499, 174, 126, 303, 163, 908, 333, 187, 329, 140, 792, 102, 170, 354, 68, 179, 60, 703, 235, 180, 52, 287, 177, 140, 136, 131, 351, 139, 190, 386, 168, 112, 135, 403, 97, 208, 146, 275, 388, 1015, 102, 96, 121, 343, 480, 151, 47, 297, 140, 144, 117, 958, 162, 389, 78, 190, 150, 210, 123, 166, 296, 173, 334, 267, 587, 43, 144, 151, 338, 358, 311, 154, 430, 662, 144, 116, 205, 721, 168, 123, 122, 167, 171, 146, 471, 262, 174, 446, 124, 133, 191, 258, 318, 170, 200, 208, 131, 113, 468, 252, 204, 186, 240, 53, 413, 424, 177, 213, 38, 157, 122, 192, 153, 108, 804, 53, 152, 57, 80, 180, 144, 157, 156, 208, 184, 154, 131, 191, 551, 242, 704, 78, 123, 195, 196, 196, 439, 241, 153, 168, 101, 291, 212, 123, 679, 80, 706, 163, 67, 257, 179, 238, 105, 155, 278, 544, 269, 102, 102, 173, 78, 45, 150, 165, 170, 149, 415, 811, 263, 182, 225, 259, 826, 111, 218, 156, 269, 308, 150, 175, 145, 131, 467, 115, 242, 291, 181, 816, 399, 142, 461, 853, 315, 264, 208, 183, 174, 483, 94, 145, 319, 224, 135, 101, 217, 267, 189, 336, 93, 204, 286, 219, 429, 106, 175, 622, 151, 336, 123, 129, 905, 222, 229, 254, 129, 202, 261, 594, 110, 448, 116, 162, 128, 323, 177, 144, 507, 489, 217, 130, 588, 177, 253, 167, 122, 123, 452, 259, 376, 517, 632, 85, 47, 303, 235, 357, 216, 348, 224, 115, 186, 311, 66, 104, 89, 120, 578, 778, 123, 468, 224, 307, 128, 113, 114, 185, 260, 38, 391, 102, 480, 76, 436, 225, 431, 452, 239, 53, 83, 249, 223, 199, 135, 382, 142, 279, 116, 129, 343, 210, 400, 117, 122, 55, 156, 253, 182, 46, 67, 144, 132, 362, 200, 159, 53, 124, 107, 153, 141, 301, 110, 155, 239, 187, 345, 184, 170, 86, 422, 207, 151, 133, 365, 125, 191, 127, 271, 444, 49, 73, 167, 121, 533, 408, 126, 141, 142, 342, 170, 152, 203, 355, 547, 104, 249, 111, 160, 183, 385, 338, 244, 108, 127, 149, 153, 144, 71, 249, 198, 127, 282, 516, 250, 209, 78, 582, 1291, 38, 240, 148, 192, 728, 237, 173, 112, 133, 241, 432, 177, 202, 484, 167, 291, 53, 211, 227, 196, 652, 239, 509, 95, 191, 144, 123, 219, 197, 313, 360, 125, 241, 141, 276, 266, 179, 329, 171, 82, 861, 280, 168, 380, 427, 180, 167, 169, 322, 132, 518, 83, 122, 136, 189, 542, 104, 138, 181, 171, 51, 407, 327, 123, 221, 40, 178, 116, 122, 139, 312, 350, 124, 120, 249, 126, 121, 189, 483, 40, 450, 152, 137, 172, 175, 316, 597, 553, 159, 134, 274, 248, 214, 364, 332, 46, 252, 138, 274, 145, 494, 344, 130, 189, 128, 136, 57, 166, 161, 267, 123, 316, 406, 176, 127, 329, 142, 98, 86, 146, 178, 283, 60, 135, 200, 191, 116, 54, 131, 58, 180, 166, 137, 156, 163, 121, 153, 186, 469, 110, 341, 161, 426, 210, 384, 159, 128, 134, 106, 55, 257, 146, 1024, 127, 127, 118, 101, 152, 160, 135, 172, 128, 483, 118, 555, 80, 137, 196, 310, 193, 500, 334, 150, 121, 767, 240, 253, 208, 77, 728, 163, 631, 248, 79, 64, 630, 306, 228, 200, 74, 626, 459, 585, 384, 73, 149, 63, 342, 144, 327, 204, 136, 460, 140, 171, 124, 101, 186, 141, 118, 200, 199, 174, 240, 377, 216, 136, 42, 274, 130, 238, 267, 66, 176, 154, 72, 282, 250, 162, 139, 409, 145, 666, 290, 164, 787, 167, 308, 140, 114, 149, 111, 231, 554, 270, 153, 273, 649, 322, 189, 197, 269, 170, 192, 333, 105, 42, 230, 676, 332, 435, 612, 276, 130, 842, 109, 65, 667, 124, 592, 518, 50, 198, 222, 144, 65, 576, 168, 162, 141, 129, 116, 148, 341, 50, 138, 199, 108, 329, 489, 424, 677, 137, 597, 209, 670, 805, 374, 518, 110, 227, 107, 306, 161, 213, 319, 358, 159, 151, 135, 155, 163, 134, 181, 238, 222, 123, 350, 130, 271, 70, 200, 148, 164, 208, 146, 156, 103, 257, 125, 138, 35, 143, 182, 264, 184, 214, 43, 130, 163, 141, 191, 143, 230, 195, 133, 143, 162, 194, 143, 409, 245, 84, 354, 139, 117, 74, 1034, 310, 88, 171, 122, 149, 160, 354, 368, 336, 553, 203, 569, 59, 133, 256, 157, 413, 161, 333, 171, 289, 122, 155, 199, 275, 72, 123, 139, 109, 482, 205, 413, 241, 153, 165, 140, 246, 416, 176, 281, 82, 125, 99, 273, 40, 159, 100, 182, 167, 228, 309, 44, 283, 124, 460, 153, 194, 414, 129, 178, 157, 190, 334, 124, 208, 50, 670, 172, 61, 234, 64, 173, 229, 101, 189, 314, 240, 135, 212, 360, 238, 899, 129, 121, 52, 475, 342, 102, 104, 155, 116, 255, 400, 131, 52, 359, 139, 122, 152, 226, 168, 234, 291, 580, 56, 86, 160, 48, 154, 150, 165, 300, 151, 65, 97, 131, 180, 1039, 150, 448, 248, 166, 351, 360, 181, 231, 565, 118, 210, 217, 96, 164, 157, 213, 502, 106, 160, 64, 122, 216, 161, 154, 376, 154, 237, 134, 281, 184, 145, 737, 111, 141, 406, 132, 148, 229, 69, 52, 159, 115, 144, 580, 214, 140, 320, 127, 88, 375, 122, 242, 230, 202, 106, 90, 96, 386, 134, 410, 186, 340, 126, 104, 123, 175, 536, 506, 272, 487, 106, 127, 172, 254, 218, 210, 172, 365, 288, 157, 144, 76, 138, 56, 604, 173, 271, 176, 101, 282, 129, 122, 153, 173, 147, 86, 965, 119, 143, 198, 156, 164, 58, 753, 371, 133, 698, 133, 244, 289, 117, 127, 212, 194, 131, 57, 275, 256, 374, 299, 130, 73, 301, 50, 225, 191, 210, 284, 81, 104, 197, 255, 128, 122, 275, 276, 117, 145, 681, 47, 509, 301, 204, 206, 163, 443, 164, 136, 282, 178, 347, 163, 200, 218, 232, 285, 319, 113, 304, 259, 183, 191, 396, 903, 121, 234, 296, 321, 108, 161, 243, 106, 70, 611, 239, 117, 129, 195, 134, 754, 220, 399, 234, 628, 137, 102, 533, 126, 182, 173, 159, 185, 242, 310, 390, 280, 159, 228, 159, 598, 178, 168, 266, 327, 642, 148, 250, 183, 294, 434, 182, 145, 247, 325, 255, 222, 625, 144, 196, 229, 247, 127, 319, 123, 204, 135, 130, 233, 49, 346, 52, 433, 55, 199, 92, 92, 173, 495, 372, 158, 122, 117, 75, 203, 167, 628, 81, 225, 192, 233, 246, 741, 207, 1003, 238, 227, 162, 161, 167, 190, 165, 293, 250, 115, 218, 147, 320, 119, 59, 82, 108, 358, 122, 107, 753, 370, 420, 133, 99, 674, 169, 204, 247, 117, 46, 183, 193, 193, 59, 303, 134, 122, 144, 214, 161, 92, 70, 73, 154, 337, 141, 257, 155, 248, 377, 123, 148, 184, 113, 31, 143, 81, 104, 123, 138, 112, 88, 362, 232, 152, 51, 491, 239, 487, 156, 80, 632, 153, 137, 194, 56, 145, 180, 196, 139, 120, 80, 104, 369, 292, 158, 84, 91, 121, 49, 174, 740, 887, 115, 118, 92, 315, 296, 753, 329, 151, 176, 287, 138, 653, 88, 123, 146, 697, 98, 351, 468, 359, 1530, 161, 191, 171, 133, 183, 120, 229, 349, 264, 135, 236, 165, 335, 191, 346, 123, 308, 426, 351, 364, 298, 205, 163, 68, 256, 200, 328, 284, 1018, 186, 263, 43, 304, 502, 773, 228, 155, 675, 206, 111, 504, 135, 121, 38, 151, 535, 987, 230, 900, 301, 106, 663, 170, 114, 123, 669, 225, 98, 262, 126, 504, 143, 199, 280, 541, 106, 125, 190, 29, 192, 303, 104, 121, 176, 160, 129, 266, 121, 114, 209, 42, 154, 116, 117, 183, 357, 62, 79, 218, 148, 139, 203, 126, 198, 594, 194, 107, 134, 146, 200, 126, 555, 126, 255, 158, 137, 203, 167, 98, 142, 150, 175, 104, 78, 241, 304, 298, 154, 191, 130, 762, 210, 132, 136, 447, 209, 67, 197, 223, 176, 145, 327, 726, 158, 348, 557, 132, 294, 154, 382, 114, 195, 266, 212, 173, 121, 140, 268, 246, 114, 222, 81, 139, 726, 154, 191, 179, 157, 138, 847, 128, 137, 128, 244, 342, 569, 169, 194, 222, 110, 114, 253, 473, 126, 130, 169, 143, 119, 110, 78, 59, 152, 97, 266, 325, 46, 161, 59, 223, 81, 116, 305, 485, 300, 307, 449, 245, 154, 449, 155, 111, 354, 278, 262, 158, 378, 104, 187, 138, 122, 196, 151, 123, 410, 254, 373, 191, 128, 421, 53, 131, 107, 290, 183, 170, 442, 321, 147, 176, 177, 255, 316, 59, 207, 135, 126, 92, 140, 924, 200, 212, 137, 114, 210, 254, 156, 308, 123, 236, 47, 287, 396, 291, 66, 274, 158, 133, 289, 136, 77, 153, 191, 246, 142, 53, 49, 114, 400, 155, 154, 404, 140, 208, 177, 155, 126, 634, 672, 146, 289, 114, 117, 183, 63, 80, 565, 337, 171, 173, 83, 297, 77, 219, 119, 243, 696, 202, 140, 251, 120, 166, 62, 168, 127, 160, 93, 446, 174, 228, 236, 138, 494, 175, 137, 974, 122, 237, 212, 154, 377, 439, 215, 113, 112, 171, 933, 193, 208, 128, 171, 433, 281, 100, 155, 165, 188, 123, 223, 179, 271, 97, 206, 430, 202, 176, 136, 472, 70, 105, 387, 309, 333, 635, 192, 50, 427, 115, 147, 301, 75, 287, 184, 158, 59, 159, 276, 274, 291, 260, 110, 127, 240, 212, 122, 159, 143, 62, 115, 243, 126, 435, 113, 168, 282, 192, 300, 466, 144, 145, 602, 121, 334, 121, 53, 189, 314, 113, 254, 126, 21, 364, 776, 46, 217, 150, 116, 181, 633, 365, 139, 184, 460, 349, 350, 777, 134, 153, 148, 64, 117, 74, 132, 155, 324, 293, 236, 141, 473, 733, 175, 117, 136, 363, 86, 246, 52, 158, 140, 278, 123, 598, 89, 240, 424, 174, 289, 515, 90, 291, 112, 122, 182, 236, 132, 150, 680, 245, 492, 469, 618, 138, 110, 174, 149, 129, 178, 69, 208, 254, 50, 96, 249, 89, 119, 111, 223, 378, 248, 447, 155, 313, 191, 499, 187, 481, 165, 171, 96, 102, 203, 201, 295, 373, 514, 113, 808, 61, 164, 199, 197, 278, 256, 157, 289, 735, 114, 363, 115, 181, 217, 328, 541, 356, 50, 230, 372, 365, 127, 173, 270, 81, 123, 133, 100, 218, 390, 125, 231, 141, 296, 166, 179, 291, 330, 316, 131, 171, 278, 713, 244, 162, 151, 505, 177, 123, 458, 170, 172, 590, 131, 146, 252, 333, 153, 142, 159, 237, 346, 237, 225, 128, 332, 230, 118, 79, 53, 270, 458, 104, 109, 152, 189, 150, 254, 142, 64, 211, 198, 126, 517, 42, 131, 223, 299, 355, 378, 231, 174, 111, 99, 164, 144, 176, 157, 259, 180, 138, 137, 667, 710, 177, 512, 125, 250, 305, 205, 431, 141, 59, 168, 143, 196, 146, 171, 123, 61, 523, 278, 570, 58, 778, 291, 177, 130, 109, 43, 382, 242, 65, 142, 84, 61, 518, 320, 134, 256, 59, 94, 74, 131, 89, 221, 120, 69, 149, 132, 198, 204, 111, 162, 216, 187, 241, 250, 181, 177, 149, 73, 142, 197, 188, 138, 135, 982, 137, 133, 114, 147, 283, 151, 88, 295, 93, 95, 701, 121, 237, 337, 90, 172, 276, 119, 196, 249, 140, 170, 582, 252, 352, 157, 77, 163, 137, 101, 137, 174, 242, 140, 237, 163, 170, 615, 463, 308, 184, 134, 241, 489, 129, 772, 40, 124, 683, 253, 125, 289, 154, 359, 45, 449, 171, 131, 388, 127, 307, 146, 107, 121, 283, 131, 269, 466, 122, 555, 165, 141, 155, 204, 539, 210, 435, 693, 225, 124, 116, 204, 136, 120, 172, 183, 272, 158, 130, 473, 60, 112, 531, 162, 399, 265, 126, 512, 159, 129, 181, 179, 143, 165, 90, 206, 134, 389, 187, 226, 116, 97, 1005, 329, 595, 102, 72, 205, 204, 101, 327, 180, 167, 149, 208, 128, 59, 108, 90, 190, 164, 130, 556, 381, 32, 121, 860, 140, 152, 79, 211, 185, 90, 309, 154, 826, 192, 155, 294, 445, 141, 837, 164, 141, 143, 98, 115, 228, 168, 182, 157, 338, 186, 396, 107, 819, 258, 115, 167, 344, 268, 213, 159, 377, 452, 103, 79, 134, 169, 153, 555, 337, 130, 131, 754, 439, 97, 196, 361, 146, 133, 383, 172, 72, 199, 279, 301, 60, 387, 138, 227, 106, 126, 128, 115, 69, 138, 137, 293, 406, 208, 65, 130, 124, 133, 265, 232, 679, 138, 306, 700, 252, 180, 186, 540, 149, 295, 128, 187, 253, 167, 133, 146, 598, 117, 122, 85, 148, 51, 287, 197, 164, 151, 191, 170, 339, 158, 198, 181, 561, 122, 151, 139, 197, 435, 493, 43, 160, 191, 161, 203, 119, 136, 232, 292, 717, 164, 88, 88, 548, 117, 215, 106, 244, 108, 164, 351, 399, 106, 525, 63, 107, 214, 179, 46, 303, 249, 149, 1027, 182, 239, 232, 199, 162, 176, 220, 149, 115, 109, 181, 196, 581, 135, 125, 237, 68, 157, 212, 99, 166, 318, 186, 227, 192, 168, 159, 212, 130, 357, 355, 157, 132, 115, 119, 114, 60, 191, 279, 132, 174, 120, 371, 317, 198, 159, 92, 140, 414, 303, 42, 213, 114, 150, 98, 185, 521, 392, 274, 60, 618, 169, 94, 164, 403, 200, 215, 186, 309, 187, 342, 74, 126, 165, 531, 116, 170, 156, 271, 287, 137, 237, 141, 78, 199, 699, 1165, 126, 373, 324, 145, 544, 148, 56, 155, 230, 265, 59, 213, 170, 91, 311, 184, 147, 445, 280, 58, 102, 365, 131, 244, 112, 128, 417, 872, 153, 180, 145, 77, 189, 309, 218, 148, 94, 286, 211, 355, 602, 112, 124, 141, 337, 155, 175, 93, 414, 99, 137, 173, 233, 179, 245, 209, 48, 232, 72, 199, 187, 135, 164, 170, 462, 598, 228, 142, 300, 134, 459, 364, 805, 130, 149, 71, 135, 162, 131, 240, 175, 250, 127, 158, 506, 236, 169, 209, 143, 136, 131, 684, 154, 406, 313, 272, 605, 174, 439, 252, 107, 230, 939, 132, 274, 146, 829, 191, 62, 128, 423, 94, 167, 176, 706, 324, 134, 92, 241, 55, 314, 339, 355, 155, 342, 268, 141, 139, 116, 78, 171, 249, 450, 124, 62, 311, 585, 323, 66, 386, 170, 953, 204, 232, 118, 92, 855, 231, 133, 426, 236, 381, 114, 622, 418, 124, 175, 120, 328, 177, 122, 332, 384, 448, 454, 169, 543, 113, 391, 89, 242, 338, 124, 272, 180, 191, 131, 123, 150, 296, 430, 200, 177, 480, 217, 59, 492, 143, 198, 242, 334, 257, 35, 97, 242, 91, 155, 258, 1016, 194, 117, 365, 90, 194, 321, 824, 753, 194, 103, 156, 219, 202, 187, 218, 148, 92, 154, 199, 505, 335, 125, 311, 1022, 144, 268, 518, 354, 138, 283, 200, 143, 370, 327, 262, 342, 311, 177, 101, 70, 254, 189, 124, 246, 126, 290, 152, 173, 295, 537, 221, 247, 347, 119, 156, 128, 171, 126, 219, 405, 595, 158, 149, 314, 112, 153, 158, 238, 154, 132, 137, 62, 112, 157, 243, 143, 160, 285, 132, 671, 63, 197, 203, 484, 162, 132, 844, 128, 176, 963, 108, 129, 201, 306, 443, 170, 135, 371, 133, 338, 106, 150, 58, 267, 122, 725, 423, 168, 161, 151, 296, 162, 434, 1012, 209, 109, 108, 128, 445, 125, 385, 196, 96, 123, 153, 174, 79, 156, 166, 58, 242, 66, 283, 140, 390, 142, 168, 142, 276, 221, 285, 128, 172, 1020, 88, 388, 321, 363, 135, 113, 208, 136, 199, 460, 779, 376, 215, 49, 121, 137, 64, 169, 473, 115, 276, 162, 207, 196, 156, 97, 375, 75, 137, 274, 176, 146, 155, 185, 59, 203, 276, 137, 259, 147, 322, 198, 65, 261, 143, 127, 95, 129, 272, 274, 120, 252, 240, 132, 661, 302, 213, 152, 201, 791, 194, 144, 308, 362, 450, 461, 167, 194, 332, 263, 51, 136, 612, 72, 445, 181, 206, 178, 271, 132, 44, 131, 221, 186, 139, 437, 689, 144, 204, 190, 216, 159, 172, 155, 174, 230, 193, 150, 130, 137, 161, 335, 168, 390, 130, 279, 56, 89, 133, 159, 119, 192, 115, 249, 265, 139, 127, 125, 137, 319, 272, 132, 216, 467, 57, 343, 265, 107, 438, 287, 125, 185, 110, 54, 139, 65, 98, 165, 124, 122, 107, 226, 167, 277, 186, 343, 340, 242, 417, 137, 147, 159, 243, 395, 126, 334, 240, 131, 169, 266, 149, 196, 165, 234, 224, 122, 197, 255, 559, 119, 148, 411, 230, 374, 55, 219, 66, 674, 506, 205, 42, 158, 175, 73, 206, 183, 174, 44, 976, 455, 167, 290, 128, 127, 151, 81, 285, 197, 63, 103, 161, 265, 188, 136, 139, 130, 207, 70, 54, 204, 131, 102, 115, 116, 176, 169, 178, 145, 144, 386, 247, 208, 133, 193, 125, 158, 241, 193, 242, 241, 416, 134, 150, 359, 154, 154, 168, 76, 86, 141, 152, 55, 197, 113, 180, 608, 1337, 169, 66, 146, 165, 67, 715, 129, 90, 117, 264, 838, 37, 337, 105, 190, 190, 1090, 185, 256, 367, 126, 177, 177, 130, 92, 408, 48, 56, 975, 142, 872, 248, 320, 158, 648, 227, 141, 71, 120, 68, 683, 182, 565, 210, 298, 56, 224, 142, 124, 170, 125, 226, 205, 117, 86, 296, 148, 580, 273, 117, 178, 130, 166, 234, 190, 353, 281, 634, 393, 113, 319, 323, 137, 138, 91, 587, 576, 525, 1216, 60, 57, 177, 89, 165, 206, 299, 227, 190, 135, 181, 338, 84, 121, 76, 574, 148, 376, 191, 371, 260, 267, 107, 281, 154, 269, 43, 139, 870, 737, 90, 173, 138, 178, 131, 876, 415, 48, 169, 297, 175, 63, 235, 138, 199, 221, 74, 138, 616, 214, 151, 116, 236, 431, 132, 681, 192, 235, 193, 414, 142, 188, 789, 224, 127, 84, 170, 174, 69, 205, 188, 149, 445, 160, 127, 108, 40, 457, 204, 178, 68, 190, 118, 224, 417, 116, 371, 151, 236, 287, 141, 262, 84, 308, 204, 340, 410, 106, 975, 34, 266, 132, 900, 284, 499, 210, 58, 65, 122, 124, 236, 139, 168, 261, 179, 258, 486, 205, 118, 119, 130, 132, 133, 121, 150, 88, 138, 122, 152, 218, 834, 127, 104, 121, 57, 139, 47, 223, 331, 289, 234, 159, 79, 175, 74, 345, 159, 290, 347, 316, 171, 84, 337, 307, 605, 147, 238, 194, 113, 59, 147, 300, 443, 136, 490, 197, 123, 315, 215, 192, 227, 128, 208, 141, 241, 296, 212, 161, 103, 357, 624, 111, 132, 118, 321, 250, 74, 146, 299, 120, 144, 187, 136, 135, 137, 817, 131, 314, 377, 181, 198, 219, 185, 176, 78, 126, 122, 168, 137, 162, 142, 227, 125, 241, 139, 177, 58, 237, 147, 239, 506, 477, 135, 60, 116, 147, 273, 148, 462, 317, 291, 171, 168, 126, 127, 134, 394, 107, 866, 192, 194, 300, 279, 514, 168, 498, 136, 134, 698, 170, 115, 102, 227, 132, 124, 656, 170, 239, 291, 223, 45, 119, 129, 132, 158, 330, 297, 48, 134, 139, 115, 140, 235, 153, 108, 157, 224, 249, 882, 383, 112, 221, 290, 142, 110, 121, 462, 99, 128, 329, 400, 552, 359, 129, 124, 164, 315, 322, 368, 120, 163, 96, 151, 145, 192, 148, 303, 287, 214, 293, 120, 461, 107, 135, 187, 176, 316, 148, 56, 368, 140, 99, 190, 249, 143, 75, 160, 246, 83, 218, 151, 78, 163, 237, 144, 122, 112, 184, 261, 225, 124, 76, 111, 150, 122, 85, 124, 172, 259, 163, 135, 138, 239, 204, 272, 149, 118, 200, 110, 488, 464, 122, 390, 139, 88, 737, 204, 77, 126, 127, 274, 74, 166, 61, 616, 546, 236, 83, 386, 106, 862, 286, 297, 205, 63, 92, 302, 115, 181, 275, 206, 184, 164, 138, 147, 232, 177, 454, 119, 609, 127, 83, 334, 201, 133, 181, 519, 138, 249, 149, 111, 429, 142, 95, 203, 188, 207, 190, 477, 119, 650, 381, 154, 893, 135, 142, 265, 58, 103, 47, 184, 134, 104, 298, 537, 130, 205, 146, 128, 557, 128, 175, 136, 158, 103, 184, 146, 79, 184, 308, 34, 128, 261, 139, 325, 166, 140, 105, 125, 108, 562, 143, 92, 65, 128, 211, 204, 16, 432, 169, 369, 110, 66, 134, 147, 179, 168, 143, 48, 452, 265, 197, 59, 130, 443, 521, 180, 514, 297, 130, 100, 145, 407, 186, 141, 127, 341, 157, 210, 281, 224, 142, 259, 371, 109, 116, 1018, 225, 206, 136, 76, 527, 191, 81, 989, 125, 135, 988, 132, 478, 210, 640, 361, 431, 194, 50, 269, 221, 207, 130, 259, 125, 208, 164, 686, 86, 63, 157, 308, 116, 369, 120, 123, 144, 38, 226, 529, 536, 293, 312, 125, 198, 281, 34, 151, 181, 106, 118, 283, 228, 274, 619, 150, 280, 106, 345, 369, 210, 134, 39, 157, 210, 205, 218, 157, 229, 225, 245, 156, 171, 134, 94, 57, 116, 190, 201, 797, 234, 233, 329, 263, 319, 41, 346, 236, 229, 139, 506, 150, 306, 121, 336, 107, 156, 222, 187, 330, 415, 68, 161, 239, 139, 163, 182, 136, 173, 296, 75, 160, 688, 99, 128, 296, 660, 252, 251, 176, 158, 158, 68, 116, 125, 148, 123, 220, 147, 167, 776, 464, 126, 98, 490, 170, 163, 346, 125, 340, 150, 71, 377, 164, 447, 288, 212, 367, 460, 221, 375, 531, 417, 203, 291, 117, 595, 62, 274, 532, 257, 342, 512, 133, 198, 196, 207, 132, 132, 290, 425, 253, 471, 166, 155, 207, 116, 216, 321, 128, 144, 183, 160, 99, 173, 158, 329, 133, 215, 119, 108, 160, 154, 168, 237, 118, 316, 453, 143, 366, 168, 116, 50, 563, 669, 184, 156, 127, 148, 181, 393, 278, 226, 58, 206, 440, 301, 179, 89, 192, 487, 230, 156, 236, 140, 148, 129, 323, 97, 380, 62, 247, 210, 481, 209, 367, 301, 16, 125, 280, 13, 259, 287, 351, 62, 157, 30, 126, 149, 66, 350, 175, 64, 191, 133, 266, 150, 349, 182, 335, 154, 484, 83, 119, 141, 242, 209, 153, 252, 103, 2494, 173, 115, 1002, 137, 477, 227, 128, 202, 806, 211, 138, 246, 316, 540, 329, 155, 410, 135, 731, 158, 215, 174, 627, 383, 147, 149, 133, 95, 361, 136, 67, 146, 78, 124, 272, 201, 178, 220, 675, 173, 347, 82, 1403, 518, 117, 116, 325, 207, 175, 161, 171, 408, 71, 166, 403, 605, 137, 460, 125, 233, 123, 127, 156, 307, 226, 636, 133, 206, 563, 126, 1236, 142, 169, 243, 140, 67, 191, 141, 280, 173, 112, 139, 244, 49, 398, 201, 71, 153, 141, 60, 439, 154, 516, 584, 139, 500, 90, 173, 124, 170, 217, 621, 165, 195, 133, 107, 203, 147, 123, 381, 485, 105, 59, 122, 265, 284, 366, 569, 426, 522, 759, 118, 53, 344, 197, 621, 246, 421, 355, 192, 130, 118, 249, 357, 119, 535, 184, 192, 898, 274, 149, 221, 78, 182, 319, 526, 197, 121, 323, 331, 192, 169, 128, 193, 308, 147, 256, 124, 310, 120, 131, 350, 190, 164, 158, 92, 136, 126, 481, 138, 204, 427, 886, 346, 125, 263, 82, 60, 280, 308, 147, 134, 76, 326, 78, 222, 812, 56, 237, 139, 116, 116, 152, 50, 147, 111, 130, 124, 379, 114, 248, 273, 467, 166, 125, 128, 449, 296, 288, 228, 139, 126, 129, 94, 501, 445, 289, 427, 131, 172, 315, 414, 125, 111, 104, 234, 133, 312, 297, 161, 83, 147, 602, 308, 533, 121, 70, 278, 125, 87, 120, 239, 146, 49, 106, 163, 126, 231, 657, 425, 123, 157, 149, 91, 220, 564, 170, 127, 230, 197, 839, 203, 157, 731, 288, 294, 392, 561, 148, 294, 230, 103, 268, 131, 359, 186, 365, 125, 281, 163, 290, 108, 92, 160, 126, 176, 109, 115, 222, 235, 184, 97, 214, 38, 161, 129, 201, 78, 169, 235, 123, 138, 116, 174, 179, 252, 114, 169, 121, 136, 440, 119, 241, 182, 156, 125, 245, 330, 182, 366, 162, 133, 136, 359, 404, 98, 162, 367, 312, 188, 142, 157, 157, 156, 419, 70, 121, 135, 319, 218, 112, 118, 150, 323, 334, 121, 104, 226, 183, 235, 112, 427, 407, 139, 210, 583, 296, 424, 183, 523, 183, 186, 992, 491, 161, 254, 287, 356, 142, 285, 233, 284, 132, 122, 121, 168, 218, 184, 134, 265, 212, 161, 488, 254, 70, 295, 136, 182, 394, 166, 188, 188, 151, 213, 164, 210, 68, 206, 189, 93, 165, 132, 227, 281, 118, 135, 267, 65, 172, 583, 116, 223, 23, 522, 470, 183, 50, 196, 196, 154, 209, 258, 126, 300, 121, 396, 193, 120, 373, 125, 71, 241, 153, 120, 444, 181, 183, 237, 157, 330, 706, 323, 256, 302, 132, 276, 107, 297, 91, 386, 288, 175, 122, 189, 60, 40, 962, 740, 365, 108, 245, 407, 297, 448, 227, 455, 445, 122, 126, 154, 805, 184, 249, 162, 42, 90, 168, 131, 109, 139, 145, 44, 266, 121, 269, 1010, 111, 105, 157, 420, 184, 130, 503, 148, 170, 155, 344, 169, 258, 365, 280, 100, 342, 725, 223, 283, 469, 184, 97, 158, 255, 169, 88, 115, 74, 168, 231, 66, 253, 139, 360, 60, 146, 804, 724, 469, 166, 175, 266, 163, 643, 51, 118, 258, 159, 135, 565, 31, 367, 121, 344, 383, 184, 194, 178, 188, 292, 471, 180, 294, 361, 428, 299, 101, 271, 156, 24, 88, 136, 366, 143, 133, 155, 45, 114, 156, 119, 167, 510, 170, 177, 134, 352, 518, 538, 152, 202, 208, 188, 86, 290, 95, 478, 126, 63, 320, 192, 41, 259, 178, 182, 248, 218, 216, 200, 144, 75, 188, 168, 576, 237, 133, 160, 213, 133, 178, 158, 365, 387, 553, 121, 131, 423, 61, 538, 238, 206, 133, 166, 125, 194, 191, 561, 155, 234, 123, 81, 143, 290, 746, 387, 288, 157, 140, 229, 174, 296, 531, 163, 52, 172, 206, 161, 16, 124, 189, 147, 141, 128, 109, 177, 359, 127, 76, 415, 132, 164, 866, 218, 148, 129, 160, 215, 183, 190, 454, 185, 241, 95, 249, 173, 206, 101, 157, 406, 572, 272, 230, 163, 375, 115, 194, 186, 156, 213, 54, 405, 228, 161, 88, 201, 163, 928, 263, 137, 117, 436, 224, 211, 113, 186, 198, 134, 217, 137, 137, 226, 283, 165, 207, 125, 162, 164, 44, 622, 193, 284, 140, 79, 93, 122, 255, 133, 76, 113, 252, 234, 344, 108, 130, 112, 321, 155, 714, 115, 399, 148, 195, 152, 61, 143, 142, 245, 183, 182, 103, 151, 201, 224, 200, 117, 89, 152, 186, 46, 158, 114, 124, 110, 526, 35, 262, 125, 153, 125, 164, 155, 123, 217, 231, 558, 202, 128, 302, 171, 391, 137, 137, 171, 269, 509, 120, 42, 189, 791, 623, 326, 141, 466, 366, 166, 160, 296, 138, 720, 453, 144, 155, 129, 377, 377, 412, 150, 725, 216, 124, 615, 218, 167, 176, 405, 448, 528, 60, 138, 323, 1028, 150, 151, 142, 151, 183, 108, 188, 177, 281, 274, 152, 140, 185, 111, 889, 131, 74, 87, 134, 264, 368, 353, 174, 319, 144, 113, 126, 192, 127, 154, 127, 421, 120, 135, 273, 334, 154, 155, 229, 112, 234, 116, 162, 138, 274, 520, 275, 182, 160, 554, 363, 271, 216, 205, 454, 559, 107, 434, 162, 227, 393, 173, 155, 335, 203, 261, 273, 261, 177, 334, 91, 551, 163, 457, 142, 166, 459, 150, 227, 46, 708, 207, 123, 242, 345, 225, 264, 338, 184, 286, 68, 226, 43, 48, 124, 161, 281, 426, 155, 176, 376, 115, 363, 137, 172, 212, 81, 122, 914, 139, 113, 446, 491, 170, 90, 236, 148, 234, 46, 247, 153, 782, 586, 141, 183, 167, 569, 264, 227, 364, 225, 273, 157, 122, 170, 156, 153, 1016, 538, 135, 452, 139, 322, 137, 171, 129, 94, 206, 129, 39, 989, 708, 227, 102, 164, 153, 300, 233, 221, 124, 234, 218, 369, 45, 118, 205, 359, 139, 326, 170, 268, 137, 65, 58, 309, 733, 294, 131, 622, 383, 313, 503, 48, 102, 152, 106, 304, 553, 93, 118, 128, 409, 473, 193, 74, 448, 323, 359, 271, 159, 317, 159, 107, 553, 504, 133, 237, 401, 173, 179, 85, 181, 217, 220, 200, 239, 133, 153, 82, 130, 74, 197, 585, 129, 100, 255, 286, 293, 296, 279, 278, 313, 116, 142, 671, 110, 34, 68, 96, 152, 61, 173, 167, 119, 325, 195, 250, 257, 155, 186, 140, 274, 220, 54, 130, 396, 920, 165, 315, 175, 260, 414, 105, 321, 968, 397, 65, 108, 115, 124, 141, 492, 443, 399, 110, 152, 137, 258, 183, 320, 132, 123, 66, 176, 150, 123, 107, 297, 122, 132, 140, 172, 217, 263, 309, 199, 740, 237, 122, 67, 198, 53, 379, 153, 263, 155, 146, 202, 158, 155, 165, 128, 178, 379, 477, 140, 407, 135, 103, 201, 339, 147, 161, 135, 551, 85, 99, 296, 257, 152, 140, 502, 248, 130, 373, 212, 163, 244, 152, 512, 190, 206, 234, 156, 184, 298, 237, 427, 203, 171, 152, 86, 219, 141, 152, 590, 220, 160, 430, 230, 337, 82, 107, 278, 227, 188, 143, 234, 182, 486, 239, 47, 163, 73, 820, 477, 228, 204, 230, 223, 159, 193, 116, 332, 148, 141, 347, 139, 208, 62, 147, 271, 86, 272, 128, 98, 234, 174, 179, 501, 160, 1000, 262, 466, 136, 340, 171, 125, 168, 303, 225, 205, 113, 193, 125, 120, 239, 123, 77, 130, 240, 418, 146, 123, 170, 226, 418, 117, 291, 94, 581, 142, 206, 189, 225, 125, 141, 159, 196, 184, 174, 137, 140, 160, 172, 252, 457, 76, 137, 189, 159, 408, 108, 199, 170, 396, 209, 74, 315, 70, 71, 187, 429, 195, 299, 253, 463, 525, 729, 165, 165, 403, 784, 257, 87, 149, 177, 324, 137, 439, 243, 90, 158, 307, 133, 442, 350, 143, 441, 164, 56, 362, 153, 246, 170, 225, 116, 249, 274, 200, 254, 92, 452, 403, 65, 188, 177, 104, 156, 90, 133, 67, 340, 183, 884, 274, 133, 179, 139, 503, 122, 137, 95, 81, 167, 371, 827, 123, 382, 56, 182, 386, 240, 106, 117, 174, 240, 337, 814, 123, 318, 555, 360, 141, 244, 257, 76, 95, 140, 142, 33, 265, 75, 173, 327, 130, 104, 274, 30, 123, 116, 365, 92, 118, 200, 82, 124, 632, 119, 128, 400, 140, 152, 383, 458, 126, 307, 188, 273, 176, 396, 310, 361, 193, 214, 469, 114, 159, 171, 174, 244, 124, 120, 131, 207, 246, 127, 167, 127, 386, 45, 138, 117, 36, 153, 50, 61, 747, 366, 146, 140, 218, 163, 166, 123, 151, 325, 132, 935, 307, 132, 170, 144, 124, 216, 194, 72, 463, 594, 263, 210, 182, 118, 260, 271, 172, 129, 163, 213, 149, 151, 320, 93, 295, 98, 935, 64, 153, 118, 256, 246, 209, 597, 249, 374, 130, 266, 114, 73, 201, 150, 137, 47, 107, 111, 158, 191, 717, 441, 142, 123, 174, 88, 214, 115, 494, 142, 537, 303, 147, 191, 86, 126, 154, 223, 138, 127, 138, 716, 274, 167, 100, 225, 126, 129, 862, 143, 53, 267, 323, 131, 162, 176, 122, 125, 220, 113, 166, 156, 133, 314, 131, 301, 135, 246, 654, 214, 132, 158, 367, 167, 255, 597, 267, 50, 972, 145, 96, 283, 270, 318, 149, 118, 138, 200, 49, 190, 334, 167, 127, 223, 80, 113, 89, 164, 491, 234, 634, 463, 167, 135, 119, 183, 102, 277, 398, 141, 161, 1409, 311, 70, 330, 119, 182, 120, 71, 85, 114, 414, 298, 122, 150, 152, 381, 331, 224, 55, 316, 268, 212, 128, 368, 130, 727, 521, 281, 278, 172, 314, 235, 271, 514, 444, 216, 318, 107, 464, 368, 83, 274, 166, 150, 67, 102, 357, 170, 228, 874, 62, 225, 215, 112, 147, 188, 186, 266, 134, 328, 143, 74, 114, 120, 119, 319, 73, 432, 358, 141, 300, 184, 244, 264, 130, 231, 173, 115, 266, 84, 344, 197, 209, 253, 136, 129, 313, 54, 89, 251, 175, 138, 332, 332, 28, 346, 119, 152, 122, 844, 229, 89, 130, 257, 125, 606, 281, 138, 231, 200, 139, 156, 305, 177, 139, 395, 139, 124, 54, 595, 492, 193, 152, 112, 97, 379, 183, 777, 961, 302, 187, 77, 170, 283, 168, 99, 68, 130, 349, 146, 169, 315, 276, 166, 251, 350, 363, 190, 180, 82, 138, 195, 140, 135, 172, 117, 149, 256, 184, 132, 186, 157, 685, 131, 448, 609, 614, 411, 141, 166, 122, 129, 163, 239, 150, 423, 132, 144, 357, 404, 268, 715, 177, 155, 272, 116, 183, 308, 131, 149, 150, 138, 309, 344, 134, 901, 114, 219, 358, 383, 421, 493, 59, 160, 293, 62, 121, 147, 147, 225, 122, 142, 138, 219, 163, 132, 234, 754, 137, 247, 166, 136, 74, 716, 253, 151, 133, 217, 157, 139, 122, 157, 109, 57, 206, 568, 128, 186, 219, 235, 126, 203, 380, 78, 256, 374, 124, 125, 890, 390, 156, 71, 249, 200, 246, 357, 145, 213, 304, 256, 327, 500, 166, 871, 616, 162, 122, 167, 291, 146, 56, 535, 86, 159, 57, 165, 314, 274, 43, 109, 151, 176, 222, 39, 174, 148, 315, 242, 104, 177, 81, 237, 62, 37, 263, 50, 456, 152, 193, 352, 101, 104, 120, 344, 142, 246, 711, 211, 183, 431, 1082, 127, 141, 143, 139, 451, 505, 120, 112, 131, 251, 419, 157, 163, 53, 220, 332, 132, 703, 139, 144, 123, 113, 395, 108, 358, 129, 192, 811, 135, 114, 120, 91, 129, 131, 226, 93, 79, 124, 296, 146, 443, 900, 75, 354, 197, 136, 184, 139, 127, 204, 344, 293, 210, 130, 146, 150, 133, 88, 568, 275, 192, 116, 177, 171, 223, 364, 106, 168, 868, 190, 85, 207, 52, 141, 45, 127, 133, 130, 126, 128, 278, 204, 246, 125, 128, 152, 158, 159, 257, 241, 131, 1016, 45, 244, 53, 178, 200, 123, 890, 462, 293, 389, 469, 136, 322, 186, 297, 294, 126, 36, 508, 384, 174, 687, 133, 140, 471, 48, 98, 289, 171, 272, 299, 143, 627, 178, 275, 487, 125, 790, 262, 310, 401, 54, 138, 122, 52, 83, 219, 173, 187, 563, 246, 659, 151, 158, 500, 154, 275, 302, 124, 265, 203, 126, 146, 132, 116, 150, 121, 294, 110, 117, 45, 432, 221, 330, 123, 248, 258, 73, 85, 97, 115, 213, 175, 241, 116, 915, 450, 252, 118, 67, 198, 53, 525, 151, 123, 263, 179, 427, 151, 114, 122, 172, 182, 135, 220, 487, 432, 99, 975, 157, 63, 371, 212, 156, 54, 723, 178, 222, 38, 225, 134, 232, 261, 199, 193, 238, 349, 107, 204, 47, 156, 536, 402, 552, 175, 135, 771, 138, 255, 472, 556, 94, 210, 145, 63, 593, 60, 124, 121, 810, 278, 172, 112, 413, 134, 403, 197, 201, 145, 114, 334, 134, 115, 166, 350, 62, 1033, 182, 380, 69, 399, 240, 554, 162, 503, 167, 126, 168, 78, 258, 598, 659, 125, 310, 122, 144, 161, 126, 196, 208, 193, 129, 271, 219, 265, 95, 211, 128, 261, 143, 803, 217, 682, 205, 66, 185, 292, 153, 174, 67, 133, 554, 200, 319, 267, 454, 392, 233, 142, 136, 87, 92, 122, 106, 166, 364, 639, 282, 239, 180, 254, 527, 72, 77, 380, 45, 30, 133, 128, 137, 220, 267, 433, 136, 338, 483, 61, 146, 412, 429, 128, 364, 172, 669, 158, 218, 187, 65, 608, 125, 172, 166, 167, 227, 177, 356, 980, 231, 430, 353, 587, 511, 320, 161, 253, 120, 41, 133, 260, 285, 211, 130, 306, 180, 665, 116, 126, 555, 138, 65, 653, 149, 504, 173, 125, 204, 194, 222, 295, 159, 168, 930, 136, 244, 469, 123, 151, 101, 159, 114, 334, 133, 406, 750, 797, 72, 232, 278, 178, 228, 179, 360, 241, 554, 281, 222, 408, 1020, 402, 205, 113, 494, 542, 99, 100, 234, 125, 542, 302, 325, 513, 372, 181, 258, 236, 78, 111, 189, 133, 131, 347, 177, 168, 179, 214, 394, 254, 58, 153, 122, 109, 136, 180, 120, 178, 124, 510, 986, 123, 157, 553, 300, 391, 152, 208, 529, 225, 144, 130, 116, 93, 479, 661, 165, 153, 715, 369, 245, 232, 459, 149, 238, 328, 156, 457, 150, 180, 209, 158, 407, 158, 147, 238, 153, 240, 117, 340, 128, 53, 284, 195, 240, 128, 140, 113, 288, 135, 107, 244, 241, 189, 130, 267, 118, 148, 382, 117, 93, 132, 74, 145, 460, 145, 128, 267, 147, 158, 186, 206, 289, 236, 142, 162, 144, 319, 305, 186, 222, 185, 245, 54, 429, 492, 192, 417, 251, 178, 325, 391, 188, 122, 237, 475, 251, 290, 243, 143, 65, 202, 176, 161, 212, 258, 145, 181, 453, 432, 491, 120, 134, 136, 167, 114, 423, 173, 371, 293, 353, 588, 171, 109, 143, 315, 113, 149, 214, 208, 282, 475, 73, 121, 458, 195, 173, 186, 216, 169, 150, 380, 130, 88, 488, 691, 139, 222, 173, 80, 142, 123, 189, 197, 169, 162, 391, 131, 305, 66, 100, 194, 186, 240, 589, 167, 147, 112, 222, 153, 409, 328, 255, 73, 133, 228, 175, 43, 188, 946, 141, 149, 199, 81, 340, 85, 124, 129, 104, 189, 277, 148, 156, 231, 38, 143, 56, 122, 121, 120, 187, 167, 101, 120, 100, 200, 739, 142, 64, 309, 142, 201, 84, 701, 130, 251, 519, 474, 128, 460, 161, 553, 121, 154, 137, 182, 221, 374, 44, 124, 50, 155, 613, 111, 136, 572, 85, 307, 102, 195, 462, 176, 81, 668, 252, 46, 128, 169, 107, 159, 46, 101, 256, 330, 86, 615, 358, 126, 83, 621, 210, 108, 649, 76, 148, 136, 438, 110, 182, 151, 144, 91, 152, 139, 47, 228, 61, 117, 74, 212, 513, 110, 170, 191, 344, 172, 605, 339, 99, 286, 119, 163, 349, 133, 303, 150, 122, 598, 279, 312, 143, 590, 86, 196, 129, 139, 336, 231, 146, 668, 148, 133, 158, 303, 132, 186, 138, 120, 190, 149, 126, 83, 229, 93, 256, 130, 90, 341, 134, 244, 235, 307, 175, 142, 110, 465, 103, 159, 369, 135, 140, 138, 132, 122, 267, 206, 123, 139, 449, 807, 172, 481, 122, 141, 157, 377, 81, 319, 117, 139, 95, 133, 67, 668, 496, 165, 157, 371, 745, 122, 80, 161, 99, 138, 69, 115, 122, 178, 211, 75, 341, 140, 163, 292, 250, 389, 126, 138, 368, 894, 190, 135, 30, 120, 81, 535, 312, 134, 108, 157, 116, 261, 299, 768, 315, 855, 529, 535, 236, 132, 148, 35, 183, 122, 427, 185, 797, 214, 1024, 134, 479, 422, 68, 471, 174, 367, 429, 116, 76, 121, 122, 241, 172, 245, 552, 371, 131, 305, 643, 175, 191, 110, 116, 502, 993, 137, 143, 529, 297, 270, 157, 177, 122, 136, 194, 791, 62, 197, 188, 79, 137, 78, 862, 330, 158, 135, 58, 117, 136, 280, 128, 330, 193, 179, 1025, 372, 287, 77, 106, 130, 272, 510, 54, 397, 186, 158, 254, 181, 124, 245, 47, 136, 556, 292, 131, 265, 241, 460, 75, 901, 77, 47, 282, 704, 109, 299, 240, 349, 174, 82, 218, 198, 169, 97, 128, 315, 131, 150, 203, 154, 135, 360, 444, 175, 115, 268, 122, 349, 247, 182, 157, 194, 395, 383, 190, 195, 114, 113, 621, 180, 51, 124, 44, 120, 154, 123, 426, 180, 122, 367, 49, 180, 178, 147, 162, 144, 51, 153, 295, 129, 301, 115, 84, 96, 190, 161, 223, 262, 303, 156, 125, 720, 578, 212, 471, 176, 358, 132, 119, 181, 185, 76, 71, 321, 212, 276, 120, 170, 57, 152, 137, 138, 154, 182, 130, 345, 345, 141, 383, 136, 158, 205, 116, 431, 57, 136, 167, 121, 136, 457, 186, 116, 233, 256, 47, 89, 228, 142, 138, 201, 147, 118, 136, 167, 95, 82, 416, 169, 105, 519, 172, 842, 568, 142, 47, 112, 238, 237, 124, 131, 459, 160, 249, 405, 69, 128, 125, 366, 124, 122, 187, 989, 165, 999, 164, 308, 129, 237, 92, 228, 298, 119, 958, 375, 74, 86, 840, 154, 112, 173, 240, 185, 262, 79, 252, 128, 264, 153, 86, 206, 290, 182, 280, 180, 114, 301, 139, 131, 212, 644, 1014, 149, 393, 805, 207, 220, 114, 320, 366, 229, 247, 70, 164, 104, 306, 142, 80, 693, 49, 159, 110, 317, 169, 148, 203, 141, 115, 345, 114, 157, 365, 43, 315, 178, 311, 148, 77, 93, 44, 368, 140, 377, 186, 186, 305, 131, 126, 228, 199, 284, 703, 209, 189, 90, 343, 119, 136, 247, 149, 353, 200, 109, 242, 79, 156, 283, 166, 335, 525, 298, 99, 660, 206, 126, 225, 114, 281, 103, 66, 198, 219, 184, 204, 48, 120, 214, 61, 201, 193, 111, 142, 370, 172, 187, 132, 144, 149, 176, 76, 285, 326, 117, 95, 174, 213, 156, 178, 515, 512, 154, 286, 110, 235, 152, 112, 350, 127, 113, 263, 117, 138, 60, 509, 178, 160, 126, 277, 330, 113, 371, 299, 137, 157, 62, 107, 132, 428, 416, 414, 169, 302, 118, 160, 175, 209, 179, 594, 165, 265, 120, 211, 234, 756, 45, 123, 336, 314, 313, 180, 83, 45, 186, 218, 230, 101, 255, 105, 341, 154, 178, 674, 166, 143, 204, 80, 186, 101, 130, 127, 297, 110, 127, 481, 120, 487, 107, 179, 225, 114, 176, 115, 173, 187, 131, 334, 196, 162, 153, 445, 143, 132, 60, 59, 262, 209, 253, 85, 373, 99, 119, 134, 146, 273, 149, 589, 51, 45, 351, 170, 418, 211, 288, 113, 210, 73, 184, 153, 225, 141, 170, 43, 369, 388, 142, 109, 133, 180, 156, 326, 222, 313, 245, 419, 124, 156, 124, 142, 257, 361, 178, 39, 334, 227, 138, 233, 366, 471, 486, 250, 126, 266, 158, 388, 126, 198, 223, 514, 209, 217, 214, 152, 155, 165, 418, 156, 198, 634, 203, 157, 171, 149, 207, 331, 250, 336, 152, 65, 180, 256, 183, 155, 143, 212, 139, 470, 211, 126, 141, 124, 150, 174, 436, 142, 449, 518, 612, 176, 63, 569, 146, 444, 746, 148, 116, 297, 527, 350, 504, 113, 264, 532, 136, 240, 190, 121, 142, 92, 58, 119, 131, 314, 179, 209, 481, 166, 336, 588, 139, 131, 135, 86, 252, 639, 221, 144, 169, 147, 124, 143, 274, 141, 263, 291, 187, 159, 804, 154, 81, 107, 129, 429, 154, 770, 145, 180, 636, 227, 244, 531, 118, 117, 96, 847, 138, 156, 540, 125, 353, 165, 132, 402, 189, 131, 38, 130, 155, 119, 252, 132, 239, 201, 232, 191, 162, 111, 84, 104, 150, 558, 153, 233, 53, 366, 348, 196, 441, 232, 228, 58, 106, 152, 55, 256, 464, 292, 77, 58, 401, 173, 227, 224, 275, 130, 233, 264, 160, 319, 117, 130, 99, 690, 118, 89, 436, 147, 122, 124, 80, 318, 139, 163, 533, 176, 271, 122, 121, 295, 152, 399, 259, 254, 230, 261, 130, 127, 479, 189, 390, 485, 403, 143, 193, 286, 160, 181, 406, 385, 192, 386, 229, 169, 82, 199, 433, 476, 135, 133, 187, 347, 61, 175, 247, 212, 127, 163, 103, 633, 121, 202, 62, 42, 177, 363, 109, 51, 121, 155, 170, 220, 304, 141, 185, 125, 134, 114, 73, 484, 207, 305, 116, 113, 142, 242, 257, 440, 315, 593, 269, 116, 98, 412, 446, 220, 131, 56, 147, 184, 468, 176, 54, 405, 71, 153, 828, 80, 194, 126, 155, 370, 337, 183, 138, 192, 276, 497, 117, 149, 142, 135, 148, 140, 217, 521, 139, 239, 137, 119, 287, 48, 113, 136, 921, 306, 138, 98, 175, 187, 143, 215, 86, 314, 263, 110, 512, 226, 230, 414, 72, 174, 125, 398, 225, 244, 169, 780, 159, 282, 183, 210, 275, 125, 255, 879, 121, 731, 697, 159, 132, 217, 52, 401, 192, 144, 56, 732, 58, 569, 93, 297, 147, 154, 92, 132, 65, 176, 296, 161, 146, 241, 173, 58, 224, 59, 120, 501, 129, 255, 529, 332, 142, 420, 172, 166, 108, 423, 124, 122, 204, 597, 143, 135, 182, 265, 186, 196, 102, 189, 415, 221, 177, 250, 126, 176, 462, 448, 52, 165, 211, 394, 247, 153, 189, 152, 486, 247, 141, 323, 167, 136, 125, 120, 140, 126, 52, 111, 746, 152, 300, 87, 215, 103, 212, 93, 136, 389, 91, 168, 132, 145, 411, 1006, 204, 545, 51, 689, 356, 52, 53, 235, 186, 110, 62, 214, 83, 188, 308, 123, 1006, 205, 447, 129, 216, 110, 109, 171, 83, 654, 711, 187, 406, 247, 481, 96, 41, 152, 93, 103, 137, 143, 132, 296, 671, 100, 429, 140, 149, 135, 282, 61, 280, 102, 551, 210, 27, 135, 199, 202, 133, 238, 239, 72, 173, 56, 139, 164, 196, 155, 166, 59, 212, 240, 116, 550, 167, 255, 236, 143, 124, 147, 168, 569, 117, 382, 127, 533, 140, 300, 144, 130, 480, 421, 321, 121, 212, 72, 145, 477, 286, 127, 222, 255, 452, 412, 210, 159, 147, 324, 260, 156, 229, 126, 51, 240, 162, 738, 189, 61, 102, 97, 232, 252, 279, 97, 331, 158, 189, 302, 137, 177, 125, 585, 152, 204, 159, 222, 306, 127, 200, 214, 102, 320, 501, 217, 925, 28, 153, 260, 270, 77, 175, 135, 443, 221, 147, 174, 118, 185, 188, 161, 687, 109, 556, 158, 88, 509, 115, 303, 205, 137, 395, 139, 492, 112, 279, 182, 191, 304, 149, 139, 297, 246, 202, 102, 118, 140, 58, 294, 60, 57, 104, 113, 196, 241, 122, 160, 193, 264, 332, 386, 222, 825, 144, 160, 657, 438, 145, 54, 201, 52, 886, 831, 165, 130, 209, 67, 122, 357, 612, 138, 227, 133, 153, 219, 177, 117, 55, 321, 223, 159, 453, 416, 250, 600, 457, 118, 147, 225, 213, 191, 118, 169, 356, 165, 239, 67, 444, 24, 792, 139, 223, 139, 171, 428, 310, 209, 321, 359, 127, 119, 176, 90, 60, 103, 157, 255, 581, 362, 493, 360, 184, 311, 129, 71, 429, 101, 110, 169, 145, 126, 729, 134, 93, 636, 86, 110, 478, 116, 159, 463, 131, 258, 148, 206, 421, 971, 701, 149, 398, 131, 120, 308, 323, 333, 177, 143, 445, 200, 683, 333, 495, 123, 180, 139, 238, 618, 69, 96, 99, 47, 160, 130, 743, 148, 151, 84, 237, 140, 144, 252, 99, 271, 540, 70, 131, 167, 35, 146, 191, 131, 57, 222, 225, 310, 141, 141, 147, 402, 100, 194, 172, 70, 151, 116, 505, 144, 108, 132, 240, 160, 219, 88, 356, 86, 489, 266, 145, 350, 438, 131, 122, 200, 210, 172, 126, 201, 145, 298, 77, 242, 421, 44, 257, 141, 166, 185, 490, 180, 130, 930, 166, 224, 148, 120, 264, 120, 115, 411, 114, 143, 121, 671, 450, 218, 480, 42, 131, 125, 138, 280, 152, 66, 119, 122, 184, 412, 523, 316, 1042, 86, 213, 286, 307, 111, 39, 388, 182, 74, 120, 73, 384, 191, 149, 190, 159, 124, 186, 98, 247, 165, 90, 380, 332, 907, 64, 349, 170, 296, 220, 156, 153, 72, 295, 900, 157, 514, 290, 165, 41, 169, 348, 354, 338, 223, 219, 267, 119, 83, 272, 144, 218, 173, 238, 212, 333, 46, 127, 123, 107, 133, 269, 138, 82, 501, 184, 220, 856, 254, 132, 184, 310, 147, 128, 336, 241, 223, 909, 832, 114, 182, 178, 111, 166, 310, 132, 266, 387, 56, 595, 186, 292, 189, 192, 144, 179, 113, 41, 48, 247, 403, 475, 114, 105, 148, 161, 982, 225, 106, 95, 112, 90, 358, 200, 307, 71, 134, 223, 276, 156, 819, 271, 589, 418, 939, 132, 413, 85, 204, 153, 365, 827, 128, 332, 212, 84, 349, 315, 192, 131, 577, 461, 177, 532, 366, 72, 135, 156, 119, 155, 142, 126, 181, 499, 144, 513, 325, 103, 280, 189, 281, 183, 465, 435, 56, 125, 375, 513, 374, 309, 151, 138, 202, 167, 134, 263, 152, 88, 79, 483, 166, 132, 121, 162, 140, 149, 171, 109, 145, 209, 212, 183, 39, 113, 53, 635, 154, 153, 57, 90, 198, 162, 284, 125, 190, 138, 208, 677, 174, 248, 237, 809, 150, 283, 165, 109, 150, 149, 341, 75, 570, 280, 374, 125, 168, 224, 284, 115, 125, 281, 146, 68, 188, 354, 416, 126, 120, 149, 227, 258, 707, 229, 211, 213, 135, 87, 67, 215, 598, 464, 228, 391, 115, 121, 121, 111, 291, 663, 124, 151, 137, 344, 130, 222, 157, 173, 77, 460, 230, 183, 129, 151, 259, 113, 94, 87, 324, 421, 133, 169, 217, 227, 368, 54, 139, 159, 649, 288, 759, 697, 179, 189, 134, 120, 250, 44, 127, 121, 155, 57, 166, 135, 196, 138, 139, 50, 129, 306, 165, 61, 169, 143, 454, 181, 119, 171, 150, 505, 1029, 325, 303, 223, 223, 441, 273, 161, 143, 74, 128, 198, 145, 125, 367, 134, 190, 49, 161, 163, 383, 171, 125, 680, 171, 71, 135, 827, 635, 177, 111, 91, 186, 491, 132, 401, 363, 220, 139, 115, 193, 510, 148, 245, 120, 124, 728, 79, 913, 154, 379, 182, 239, 142, 243, 84, 111, 447, 203, 190, 378, 150, 192, 98, 529, 175, 192, 148, 144, 138, 176, 148, 162, 149, 253, 242, 195, 620, 147, 144, 168, 221, 216, 106, 347, 120, 142, 461, 150, 225, 119, 127, 142, 243, 186, 110, 436, 117, 1084, 128, 180, 372, 492, 204, 328, 685, 229, 65, 226, 252, 227, 125, 221, 146, 138, 366, 145, 107, 180, 107, 134, 64, 456, 367, 93, 131, 220, 139, 247, 130, 367, 54, 650, 110, 157, 127, 159, 124, 392, 339, 396, 132, 248, 307, 78, 164, 202, 46, 771, 244, 273, 156, 187, 179, 350, 47, 412, 125, 234, 184, 245, 368, 213, 204, 367, 287, 533, 466, 367, 306, 374, 486, 122, 107, 254, 380, 215, 201, 190, 358, 351, 127, 104, 125, 171, 699, 71, 90, 125, 377, 73, 209, 174, 336, 594, 254, 149, 71, 143, 236, 766, 237, 142, 140, 376, 109, 175, 60, 178, 249, 362, 137, 190, 194, 183, 225, 802, 123, 113, 247, 43, 219, 362, 294, 262, 52, 177, 768, 183, 118, 153, 107, 55, 168, 156, 124, 259, 349, 211, 267, 197, 113, 178, 130, 192, 131, 913, 205, 54, 329, 125, 182, 233, 202, 148, 211, 323, 135, 331, 256, 400, 286, 507, 217, 232, 65, 146, 195, 100, 116, 168, 132, 125, 146, 132, 287, 333, 134, 111, 93, 55, 121, 178, 121, 237, 108, 227, 260, 484, 249, 165, 359, 205, 237, 590, 145, 136, 138, 142, 172, 273, 126, 44, 242, 187, 299, 551, 126, 141, 187, 406, 111, 584, 999, 124, 147, 114, 117, 170, 135, 149, 168, 480, 261, 355, 50, 405, 216, 294, 259, 218, 371, 216, 52, 91, 255, 519, 158, 114, 343, 132, 188, 112, 506, 150, 335, 149, 474, 132, 84, 115, 181, 62, 440, 184, 145, 281, 287, 214, 975, 297, 738, 288, 180, 163, 198, 249, 170, 169, 202, 584, 823, 133, 168, 469, 660, 322, 938, 486, 180, 262, 126, 124, 121, 84, 99, 224, 151, 375, 300, 179, 228, 46, 200, 523, 105, 239, 410, 200, 268, 312, 418, 975, 129, 185, 149, 117, 45, 128, 732, 179, 158, 309, 164, 377, 135, 94, 137, 546, 635, 125, 273, 165, 114, 122, 168, 40, 373, 198, 434, 132, 119, 199, 42, 209, 150, 222, 195, 80, 314, 252, 130, 188, 53, 225, 134, 212, 137, 139, 182, 609, 759, 144, 361, 117, 310, 105, 188, 225, 133, 435, 206, 586, 62, 115, 459, 176, 243, 419, 137, 145, 180, 421, 142, 148, 241, 135, 505, 348, 581, 101, 520, 178, 198, 265, 208, 112, 170, 66, 322, 66, 206, 604, 229, 177, 132, 287, 63, 221, 209, 155, 183, 283, 147, 69, 331, 141, 198, 457, 124, 221, 1011, 122, 434, 248, 182, 162, 217, 218, 128, 244, 329, 187, 235, 263, 152, 345, 174, 58, 378, 213, 115, 162, 719, 122, 61, 194, 362, 142, 176, 430, 129, 90, 132, 165, 186, 219, 123, 159, 264, 406, 180, 540, 185, 299, 134, 126, 71, 537, 191, 195, 148, 152, 90, 117, 112, 212, 135, 197, 297, 153, 165, 137, 115, 127, 217, 795, 200, 156, 194, 110, 201, 91, 137, 292, 331, 230, 418, 159, 231, 169, 239, 120, 1057, 191, 182, 178, 143, 765, 244, 108, 840, 210, 207, 83, 181, 51, 245, 231, 155, 549, 255, 160, 295, 280, 384, 357, 169, 50, 150, 367, 134, 71, 84, 128, 138, 68, 328, 427, 42, 41, 271, 142, 132, 138, 200, 159, 114, 88, 123, 128, 174, 137, 135, 179, 222, 350, 532, 192, 223, 222, 69, 147, 908, 376, 671, 409, 701, 152, 165, 235, 61, 401, 147, 175, 295, 199, 188, 339, 151, 131, 515, 137, 44, 157, 198, 142, 790, 188, 175, 83, 180, 338, 187, 166, 146, 211, 286, 317, 33, 220, 180, 72, 80, 119, 122, 493, 95, 289, 540, 177, 778, 227, 146, 185, 414, 345, 494, 141, 53, 59, 180, 161, 273, 239, 64, 73, 146, 288, 442, 251, 185, 128, 187, 134, 311, 50, 454, 154, 76, 442, 86, 123, 209, 205, 167, 74, 295, 315, 325, 187, 169, 287, 623, 423, 368, 307, 225, 147, 163, 142, 570, 161, 201, 273, 287, 171, 256, 262, 418, 262, 190, 149, 396, 179, 79, 183, 119, 341, 579, 463, 171, 748, 905, 174, 311, 331, 213, 134, 78, 154, 115, 120, 56, 136, 131, 446, 274, 308, 224, 128, 156, 612, 349, 166, 192, 494, 163, 280, 189, 55, 300, 188, 452, 944, 412, 110, 41, 334, 165, 166, 149, 215, 55, 192, 85, 80, 46, 183, 129, 104, 617, 600, 175, 116, 124, 368, 413, 126, 349, 179, 150, 48, 122, 199, 206, 150, 209, 252, 316, 344, 151, 220, 63, 470, 334, 564, 226, 105, 189, 123, 136, 151, 467, 76, 138, 165, 921, 122, 254, 313, 241, 421, 197, 313, 47, 416, 145, 257, 391, 151, 419, 203, 135, 162, 639, 330, 508, 152, 370, 472, 256, 147, 663, 110, 61, 174, 290, 222, 140, 120, 102, 151, 224, 193, 373, 117, 184, 219, 318, 173, 200, 110, 176, 176, 169, 403, 201, 294, 681, 108, 161, 321, 168, 444, 259, 444, 117, 201, 153, 50, 213, 176, 69, 179, 166, 187, 377, 69, 135, 133, 121, 149, 161, 182, 367, 327, 58, 104, 493, 145, 205, 117, 368, 233, 531, 120, 437, 119, 141, 112, 1006, 123, 291, 186, 245, 136, 117, 171, 128, 1007, 279, 76, 168, 164, 108, 407, 226, 462, 285, 156, 257, 276, 73, 164, 99, 370, 646, 254, 487, 170, 159, 123, 135, 458, 160, 170, 277, 413, 70, 129, 115, 501, 107, 208, 184, 214, 137, 292, 195, 239, 344, 125, 214, 190, 140, 121, 285, 97, 199, 159, 207, 270, 242, 63, 65, 134, 69, 116, 784, 122, 160, 231, 639, 411, 872, 245, 237, 545, 127, 148, 245, 200, 124, 120, 220, 136, 88, 220, 102, 71, 134, 368, 104, 167, 347, 140, 83, 134, 152, 383, 644, 134, 207, 196, 643, 139, 471, 74, 1063, 271, 228, 124, 84, 185, 807, 123, 164, 77, 279, 123, 143, 148, 843, 49, 224, 412, 284, 59, 110, 166, 308, 76, 119, 366, 128, 132, 192, 139, 127, 85, 465, 151, 122, 222, 115, 311, 263, 124, 132, 345, 295, 449, 124, 163, 122, 140, 179, 67, 230, 364, 128, 668, 303, 168, 26, 319, 429, 385, 138, 465, 229, 147, 116, 92, 583, 58, 761, 340, 160, 139, 158, 117, 290, 176, 213, 144, 368, 193, 139, 380, 516, 237, 129, 114, 128, 243, 152, 257, 347, 328, 170, 191, 384, 265, 65, 284, 270, 38, 352, 73, 141, 121, 113, 376, 74, 113, 197, 82, 133, 324, 178, 407, 43, 362, 705, 146, 169, 57, 127, 103, 156, 132, 188, 173, 171, 218, 151, 235, 572, 114, 167, 636, 148, 210, 112, 1008, 78, 216, 329, 116, 68, 171, 146, 149, 125, 174, 197, 120, 252, 999, 223, 169, 663, 153, 432, 138, 107, 60, 223, 120, 122, 237, 141, 61, 240, 306, 520, 365, 167, 154, 74, 57, 135, 823, 168, 306, 247, 295, 145, 119, 155, 251, 191, 139, 113, 784, 131, 145, 187, 327, 313, 141, 170, 479, 21, 86, 250, 77, 353, 195, 173, 140, 128, 96, 120, 442, 125, 293, 166, 63, 440, 153, 177, 210, 378, 408, 61, 169, 217, 119, 376, 234, 286, 253, 271, 178, 100, 217, 374, 125, 208, 814, 536, 204, 423, 168, 128, 79, 165, 143, 318, 117, 118, 1003, 123, 64, 95, 270, 136, 133, 260, 100, 313, 525, 270, 184, 159, 154, 502, 140, 500, 312, 833, 167, 376, 121, 135, 139, 216, 39, 208, 143, 131, 272, 72, 154, 159, 176, 54, 152, 130, 132, 150, 765, 283, 209, 253, 380, 187, 119, 692, 117, 164, 101, 745, 111, 266, 188, 110, 43, 296, 136, 316, 114, 566, 156, 117, 147, 1007, 130, 84, 140, 157, 199, 173, 290, 148, 305, 104, 117, 171, 155, 206, 703, 370, 155, 186, 360, 126, 383, 99, 314, 773, 118, 294, 153, 80, 169, 246, 186, 209, 116, 578, 119, 90, 220, 136, 201, 140, 814, 318, 355, 427, 138, 168, 156, 146, 556, 123, 295, 154, 127, 452, 123, 109, 148, 360, 647, 137, 189, 132, 114, 598, 122, 172, 191, 295, 133, 405, 65, 75, 419, 730, 135, 48, 268, 158, 362, 438, 64, 118, 159, 48, 138, 157, 861, 95, 125, 231, 538, 131, 139, 311, 523, 101, 202, 445, 975, 56, 129, 125, 84, 362, 269, 410, 164, 197, 157, 215, 207, 158, 140, 181, 178, 136, 271, 297, 240, 138, 170, 191, 255, 144, 109, 597, 253, 462, 173, 190, 60, 140, 95, 194, 439, 245, 263, 354, 248, 267, 269, 552, 143, 300, 192, 449, 445, 271, 132, 230, 159, 139, 92, 211, 175, 657, 131, 314, 489, 153, 296, 56, 153, 361, 112, 219, 385, 257, 152, 235, 154, 534, 184, 211, 118, 185, 234, 397, 162, 919, 448, 70, 196, 148, 138, 332, 134, 338, 351, 84, 116, 138, 266, 726, 95, 224, 141, 596, 62, 478, 53, 114, 903, 136, 159, 448, 135, 125, 143, 559, 146, 307, 154, 257, 250, 116, 951, 149, 153, 515, 184, 873, 155, 491, 183, 162, 376, 170, 182, 422, 363, 115, 237, 232, 390, 158, 182, 136, 156, 265, 147, 109, 75, 977, 321, 1012, 140, 167, 168, 205, 326, 530, 308, 148, 755, 148, 315, 190, 204, 401, 132, 141, 617, 390, 261, 212, 136, 165, 159, 113, 149, 261, 495, 108, 55, 72, 171, 352, 123, 477, 630, 211, 418, 538, 214, 135, 152, 218, 41, 165, 322, 145, 464, 467, 105, 134, 402, 335, 217, 122, 176, 123, 391, 100, 117, 945, 51, 176, 244, 128, 227, 70, 200, 132, 339, 193, 187, 159, 131, 130, 163, 133, 398, 202, 362, 126, 183, 636, 519, 207, 105, 334, 279, 161, 406, 227, 156, 984, 410, 975, 176, 239, 201, 783, 140, 123, 141, 165, 117, 207, 96, 284, 540, 122, 135, 369, 254, 824, 214, 135, 113, 460, 103, 112, 157, 66, 248, 164, 605, 323, 149, 428, 50, 146, 474, 168, 126, 233, 166, 187, 245, 445, 127, 557, 156, 171, 468, 132, 167, 118, 150, 59, 256, 664, 175, 270, 140, 183, 191, 183, 163, 65, 163, 145, 118, 456, 98, 643, 175, 83, 146, 78, 95, 384, 292, 507, 445, 127, 270, 336, 54, 144, 243, 334, 36, 294, 395, 521, 157, 136, 116, 446, 131, 197, 161, 355, 52, 167, 378, 89, 141, 124, 202, 278, 223, 141, 175, 97, 440, 168, 196, 209, 113, 144, 129, 87, 125, 147, 445, 139, 188, 196, 255, 173, 127, 132, 169, 118, 357, 139, 309, 311, 303, 147, 622, 211, 132, 160, 430, 155, 597, 622, 322, 136, 108, 139, 112, 107, 135, 43, 158, 232, 501, 242, 250, 136, 367, 140, 126, 346, 447, 175, 148, 133, 420, 137, 86, 473, 112, 81, 120, 407, 190, 130, 134, 155, 976, 118, 213, 129, 487, 243, 302, 92, 453, 48, 195, 231, 242, 275, 225, 692, 154, 130, 161, 197, 446, 1006, 125, 110, 366, 187, 152, 471, 525, 75, 117, 373, 234, 138, 246, 220, 194, 136, 38, 71, 119, 114, 141, 130, 182, 171, 247, 166, 261, 108, 55, 259, 106, 336, 193, 70, 694, 145, 449, 173, 431, 147, 198, 130, 119, 36, 477, 169, 409, 540, 230, 151, 247, 328, 114, 324, 155, 263, 343, 156, 117, 501, 86, 257, 242, 175, 251, 204, 212, 178, 132, 244, 719, 425, 223, 195, 129, 134, 305, 213, 244, 773, 51, 184, 174, 898, 277, 800, 615, 553, 38, 79, 139, 206, 125, 203, 245, 124, 276, 126, 239, 72, 103, 57, 156, 572, 191, 188, 184, 226, 65, 292, 252, 119, 206, 147, 151, 211, 635, 580, 262, 583, 153, 276, 1571, 207, 188, 142, 209, 325, 123, 217, 206, 162, 382, 147, 201, 132, 30, 157, 123, 230, 348, 233, 175, 403, 161, 101, 145, 150, 114, 79, 153, 124, 390, 132, 484, 592, 348, 281, 163, 134, 171, 152, 111, 466, 136, 273, 399, 306, 373, 102, 243, 116, 29, 485, 194, 515, 139, 335, 150, 353, 639, 238, 178, 133, 79, 159, 135, 184, 99, 72, 51, 174, 549, 149, 147, 579, 168, 515, 201, 273, 175, 198, 313, 163, 165, 182, 170, 384, 149, 370, 138, 232, 134, 101, 153, 327, 137, 109, 241, 121, 117, 100, 366, 170, 162, 162, 325, 384, 236, 200, 501, 173, 461, 174, 613, 115, 714, 293, 294, 380, 144, 123, 46, 379, 481, 315, 110, 216, 324, 162, 211, 148, 111, 289, 221, 533, 183, 151, 224, 157, 146, 124, 321, 208, 117, 124, 332, 182, 259, 134, 45, 110, 110, 36, 255, 117, 464, 59, 185, 385, 44, 96, 142, 153, 160, 151, 113, 74, 184, 292, 216, 123, 150, 114, 788, 645, 255, 196, 202, 154, 315, 125, 153, 222, 144, 135, 228, 248, 322, 129, 495, 210, 366, 128, 213, 515, 309, 276, 189, 114, 799, 44, 121, 502, 173, 149, 117, 260, 137, 449, 101, 451, 398, 516, 136, 164, 249, 112, 117, 228, 218, 177, 289, 1015, 98, 179, 159, 388, 118, 124, 128, 144, 796, 166, 330, 271, 210, 219, 156, 116, 400, 118, 126, 106, 118, 79, 276, 126, 281, 155, 199, 766, 49, 596, 378, 366, 213, 136, 355, 176, 133, 1013, 180, 154, 144, 181, 132, 160, 123, 189, 67, 154, 264, 193, 263, 73, 179, 135, 330, 116, 154, 235, 297, 91, 280, 121, 546, 410, 131, 359, 171, 118, 95, 123, 163, 187, 486, 205, 91, 95, 172, 93, 34, 309, 132, 167, 150, 128, 308, 233, 180, 144, 202, 126, 636, 284, 571, 165, 171, 884, 134, 139, 409, 75, 46, 120, 154, 145, 231, 176, 85, 134, 563, 172, 470, 231, 60, 125, 128, 191, 133, 53, 269, 180, 125, 121, 385, 367, 919, 195, 351, 174, 170, 77, 249, 171, 109, 171, 69, 127, 283, 271, 322, 176, 51, 126, 392, 147, 173, 116, 63, 124, 391, 196, 154, 126, 280, 266, 298, 114, 72, 205, 198, 182, 178, 136, 130, 104, 117, 98, 215, 331, 161, 305, 184, 85, 330, 361, 976, 190, 358, 222, 136, 149, 146, 790, 136, 809, 131, 112, 211, 260, 354, 1097, 220, 135, 366, 213, 451, 172, 64, 266, 138, 131, 254, 116, 239, 124, 340, 132, 338, 302, 70, 345, 298, 176, 96, 165, 245, 300, 400, 281, 124, 464, 133, 745, 262, 25, 129, 175, 153, 149, 83, 336, 370, 403, 147, 115, 256, 243, 264, 132, 345, 297, 94, 69, 134, 124, 707, 264, 85, 93, 59, 436, 419, 226, 125, 360, 144, 743, 446, 121, 240, 179, 243, 329, 60, 149, 102, 297, 145, 139, 496, 207, 122, 116, 225, 320, 153, 949, 255, 223, 114, 164, 170, 373, 107, 71, 138, 226, 341, 125, 211, 430, 194, 387, 148, 415, 130, 118, 110, 130, 637, 63, 649, 315, 501, 551, 395, 91, 176, 52, 173, 661, 133, 208, 296, 222, 186, 188, 95, 337, 573, 175, 149, 983, 246, 516, 175, 156, 131, 338, 61, 205, 158, 286, 118, 224, 95, 269, 132, 318, 168, 443, 168, 229, 78, 55, 385, 122, 184, 180, 328, 184, 150, 153]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To get max value of k</span>
<span class="nb">max</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">&gt;</span><span class="nb">max</span><span class="p">:</span>
        <span class="nb">max</span><span class="o">=</span><span class="n">j</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">max</span><span class="p">)</span>  
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2494
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To get max sequence review index</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="nb">max</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>17934
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#choosing optimul SEQ LEN because previously our model used 20 SEQ LEN where the model performance was not good</span>
<span class="c1">#Max sequence length of any sentences is 2494 which is way too much</span>
<span class="c1">#Therefore choosing value between 20 and 2494</span>
<span class="c1"># this 300 came from the graph above where i plotted avg length and the deviation</span>
<span class="n">SEQ_LEN</span><span class="o">=</span><span class="mi">300</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#padding train and test set</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span>  <span class="n">pad_sequences</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see shape of data if data is padded properly</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(25000, 300)
(25000, 300)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see if variable type </span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;numpy.ndarray&#39;&gt;
&lt;class &#39;numpy.ndarray&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#just to see values in test padded set</span>
<span class="n">X_test</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[49]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[   1,  591,  202, ...,    0,    0,    0],
       [   1,   14,   22, ...,    0,    0,    0],
       [   1,  111,  748, ...,   97,   38,  111],
       ...,
       [   1,   13, 1408, ...,    0,    0,    0],
       [   1,   11,  119, ...,    0,    0,    0],
       [   1,    6,   52, ...,    0,    0,    0]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#just to see values in train padded set</span>
<span class="n">X_train</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[50]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[   1,   14,   22, ...,    0,    0,    0],
       [   1,  194, 1153, ...,    0,    0,    0],
       [   1,   14,   47, ...,    0,    0,    0],
       ...,
       [   1,   11,    6, ...,    0,    0,    0],
       [   1, 1446, 7079, ...,    0,    0,    0],
       [   1,   17,    6, ...,    0,    0,    0]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert &lt;UNK&gt; is an amazing actor and now the same being director &lt;UNK&gt; father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for &lt;UNK&gt; and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also &lt;UNK&gt; to the two little boy&#39;s that played the &lt;UNK&gt; of norman and paul they were just brilliant children are often left out of the &lt;UNK&gt; list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i&#39;ve seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it&#39;s just so damn terribly written the clothes are sickening and funny in equal &lt;UNK&gt; the hair is big lots of boobs &lt;UNK&gt; men wear those cut &lt;UNK&gt; shirts that show off their &lt;UNK&gt; sickening that men actually wore them and the music is just &lt;UNK&gt; trash that plays over and over again in almost every scene there is trashy music boobs and &lt;UNK&gt; taking away bodies and the gym still doesn&#39;t close for &lt;UNK&gt; all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80&#39;s and have a good old laugh at how bad everything was back then &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step</span>
<span class="c1">#Provide values and it return decoded output based on decode function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had &lt;UNK&gt; working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can&#39;t get across how &lt;UNK&gt; this is to watch save yourself an hour a bit of your life &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-building">Model building<a class="anchor-link" href="#Model-building">&#182;</a></h4><p>NOTE: From now on for the rest of the models we will use sequence length of 300</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Model buliding</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span> <span class="c1">#Sequential model</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">))</span>  <span class="c1">#Init embedding layer with no pretrained wts</span>
<span class="c1">#embedding layer takes input of vocabulary size i.e 10000, embedding dimension i.e 50 and input sequence i.e number of columns of dataset i.e 300</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span> <span class="c1">#Use flatten layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span> <span class="c1">#use dropout for regularization</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> <span class="c1">#Hidden layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span> <span class="c1">#use dropout for regularization</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span> <span class="c1">#Output layer</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what our model have, number of layer , output shape ,etc</span>
<span class="c1">#model summary</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_2&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, 300, 50)           500000    
_________________________________________________________________
flatten_2 (Flatten)          (None, 15000)             0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 15000)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                150010    
_________________________________________________________________
dropout_4 (Dropout)          (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11        
=================================================================
Total params: 650,021
Trainable params: 650,021
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see shape of input to our model</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[57]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(25000, 300)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Fitting model to xtrain and ytrain with defined epochs and batch size</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
  <span class="n">X_train</span><span class="p">,</span>
  <span class="n">y_train</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
  <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 18s 701us/step - loss: 0.5398 - accuracy: 0.7072 - val_loss: 0.3430 - val_accuracy: 0.8542
Epoch 2/10
25000/25000 [==============================] - 17s 683us/step - loss: 0.2471 - accuracy: 0.9056 - val_loss: 0.3186 - val_accuracy: 0.8642
Epoch 3/10
25000/25000 [==============================] - 17s 678us/step - loss: 0.1223 - accuracy: 0.9606 - val_loss: 0.3560 - val_accuracy: 0.8599
Epoch 4/10
25000/25000 [==============================] - 18s 702us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.4003 - val_accuracy: 0.8604
Epoch 5/10
25000/25000 [==============================] - 17s 693us/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.4639 - val_accuracy: 0.8581
Epoch 6/10
25000/25000 [==============================] - 17s 694us/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.5269 - val_accuracy: 0.8537
Epoch 7/10
25000/25000 [==============================] - 17s 677us/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.5567 - val_accuracy: 0.8595s - loss: 0.0166 - accuracy: 0.99
Epoch 8/10
25000/25000 [==============================] - 17s 691us/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.5951 - val_accuracy: 0.8577
Epoch 9/10
25000/25000 [==============================] - 17s 678us/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.6708 - val_accuracy: 0.8512s - loss: 0.0143 - accuracy
Epoch 10/10
25000/25000 [==============================] - 17s 678us/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.6995 - val_accuracy: 0.8520
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate test set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 4s 150us/step
Test accuracy:  0.8519600033760071
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate train set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 4s 140us/step
Test accuracy:  0.9999200105667114
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Note">Note<a class="anchor-link" href="#Note">&#182;</a></h4><p>The accuracy increase when we increased sequence length still model is going toward overfitzone
Lets use grid search to increase accuarcy further</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Grid-search">Grid search<a class="anchor-link" href="#Grid-search">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Building layes and setting hparams</span>
<span class="k">def</span> <span class="nf">build_classifier</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="n">neurons</span><span class="p">,</span><span class="n">EMBEDDING_DIM</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">neurons</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="c1">#adam = optimizers.Adam(lr = 0.001)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#declaring hyper parameter such as neurons, batch_size, optimizers and embedding dimension to get their best values</span>
<span class="c1">#Then fitting it to data set</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_fn</span> <span class="o">=</span> <span class="n">build_classifier</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">75</span><span class="p">,</span><span class="mi">125</span><span class="p">],</span>
              <span class="s1">&#39;neurons&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span>
              <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="s1">&#39;rmsprop&#39;</span><span class="p">],</span>
              <span class="s1">&#39;EMBEDDING_DIM&#39;</span><span class="p">:[</span><span class="mi">30</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">70</span><span class="p">]</span>
             <span class="p">}</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
                           <span class="n">param_grid</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">,</span>
                           <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
                           <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Fitting to dataset</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/8
16666/16666 [==============================] - 3s 158us/step - loss: 0.6201 - accuracy: 0.6474
Epoch 2/8
16666/16666 [==============================] - 3s 156us/step - loss: 0.3198 - accuracy: 0.8822
Epoch 3/8
16666/16666 [==============================] - 3s 150us/step - loss: 0.1916 - accuracy: 0.9368
Epoch 4/8
16666/16666 [==============================] - 3s 153us/step - loss: 0.1119 - accuracy: 0.9696
Epoch 5/8
16666/16666 [==============================] - 2s 150us/step - loss: 0.0707 - accuracy: 0.9815
Epoch 6/8
16666/16666 [==============================] - 3s 159us/step - loss: 0.0436 - accuracy: 0.9899
Epoch 7/8
16666/16666 [==============================] - 3s 151us/step - loss: 0.0309 - accuracy: 0.9929
Epoch 8/8
16666/16666 [==============================] - 3s 151us/step - loss: 0.0243 - accuracy: 0.9938
8334/8334 [==============================] - 0s 23us/step
Epoch 1/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.6382 - accuracy: 0.6201
Epoch 2/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.3238 - accuracy: 0.8771
Epoch 3/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.1856 - accuracy: 0.9387
Epoch 4/8
16667/16667 [==============================] - 3s 157us/step - loss: 0.1074 - accuracy: 0.9708
Epoch 5/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0628 - accuracy: 0.9850
Epoch 6/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0427 - accuracy: 0.9913
Epoch 7/8
16667/16667 [==============================] - 2s 150us/step - loss: 0.0302 - accuracy: 0.9929
Epoch 8/8
16667/16667 [==============================] - 3s 153us/step - loss: 0.0239 - accuracy: 0.9939
8333/8333 [==============================] - 0s 27us/step
Epoch 1/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.6282 - accuracy: 0.6391
Epoch 2/8
16667/16667 [==============================] - 3s 162us/step - loss: 0.3302 - accuracy: 0.8740
Epoch 3/8
16667/16667 [==============================] - 3s 155us/step - loss: 0.1954 - accuracy: 0.9348
Epoch 4/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.1101 - accuracy: 0.9687
Epoch 5/8
16667/16667 [==============================] - 3s 163us/step - loss: 0.0693 - accuracy: 0.9820
Epoch 6/8
16667/16667 [==============================] - 3s 167us/step - loss: 0.0447 - accuracy: 0.9893
Epoch 7/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.0305 - accuracy: 0.9932
Epoch 8/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.0234 - accuracy: 0.9951
8333/8333 [==============================] - 0s 29us/step
Epoch 1/8
16666/16666 [==============================] - 2s 149us/step - loss: 0.6344 - accuracy: 0.6362
Epoch 2/8
16666/16666 [==============================] - 2s 144us/step - loss: 0.3647 - accuracy: 0.8589
Epoch 3/8
16666/16666 [==============================] - 2s 145us/step - loss: 0.2499 - accuracy: 0.9080
Epoch 4/8
16666/16666 [==============================] - 2s 146us/step - loss: 0.1859 - accuracy: 0.9356
Epoch 5/8
16666/16666 [==============================] - 2s 144us/step - loss: 0.1380 - accuracy: 0.9539
Epoch 6/8
16666/16666 [==============================] - 3s 154us/step - loss: 0.0989 - accuracy: 0.9657
Epoch 7/8
16666/16666 [==============================] - 2s 145us/step - loss: 0.0711 - accuracy: 0.9771
Epoch 8/8
16666/16666 [==============================] - 2s 145us/step - loss: 0.0529 - accuracy: 0.9851
8334/8334 [==============================] - 0s 30us/step
Epoch 1/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.6334 - accuracy: 0.6336
Epoch 2/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.3717 - accuracy: 0.8552
Epoch 3/8
16667/16667 [==============================] - 2s 147us/step - loss: 0.2525 - accuracy: 0.9059
Epoch 4/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.1832 - accuracy: 0.9380
Epoch 5/8
16667/16667 [==============================] - 2s 147us/step - loss: 0.1380 - accuracy: 0.9540
Epoch 6/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0969 - accuracy: 0.9696
Epoch 7/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.0739 - accuracy: 0.9767
Epoch 8/8
16667/16667 [==============================] - 2s 147us/step - loss: 0.0538 - accuracy: 0.9828
8333/8333 [==============================] - 0s 33us/step
Epoch 1/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.6418 - accuracy: 0.6261
Epoch 2/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.3691 - accuracy: 0.8586
Epoch 3/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.2493 - accuracy: 0.9074
Epoch 4/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.1779 - accuracy: 0.9376
Epoch 5/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.1286 - accuracy: 0.9567
Epoch 6/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.0926 - accuracy: 0.9729
Epoch 7/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0677 - accuracy: 0.9787
Epoch 8/8
16667/16667 [==============================] - 3s 163us/step - loss: 0.0493 - accuracy: 0.9855
8333/8333 [==============================] - 0s 40us/step
Epoch 1/8
16666/16666 [==============================] - 3s 175us/step - loss: 0.6080 - accuracy: 0.6529
Epoch 2/8
16666/16666 [==============================] - 3s 170us/step - loss: 0.2943 - accuracy: 0.8850
Epoch 3/8
16666/16666 [==============================] - 3s 169us/step - loss: 0.1536 - accuracy: 0.9489
Epoch 4/8
16666/16666 [==============================] - 3s 169us/step - loss: 0.0803 - accuracy: 0.9770
Epoch 5/8
16666/16666 [==============================] - 3s 168us/step - loss: 0.0429 - accuracy: 0.9892
Epoch 6/8
16666/16666 [==============================] - 3s 163us/step - loss: 0.0275 - accuracy: 0.99390s -
Epoch 7/8
16666/16666 [==============================] - 3s 155us/step - loss: 0.0202 - accuracy: 0.9942
Epoch 8/8
16666/16666 [==============================] - 3s 156us/step - loss: 0.0191 - accuracy: 0.9947
8334/8334 [==============================] - 0s 37us/step
Epoch 1/8
16667/16667 [==============================] - 3s 163us/step - loss: 0.6183 - accuracy: 0.6370
Epoch 2/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.2984 - accuracy: 0.8818
Epoch 3/8
16667/16667 [==============================] - 3s 164us/step - loss: 0.1581 - accuracy: 0.9474
Epoch 4/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0824 - accuracy: 0.9750
Epoch 5/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.0468 - accuracy: 0.9872
Epoch 6/8
16667/16667 [==============================] - 3s 157us/step - loss: 0.0298 - accuracy: 0.9926
Epoch 7/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0218 - accuracy: 0.9945
Epoch 8/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.0183 - accuracy: 0.9952
8333/8333 [==============================] - 0s 39us/step
Epoch 1/8
16667/16667 [==============================] - 3s 168us/step - loss: 0.6103 - accuracy: 0.64580s - loss: 0.6186 - accuracy: 
Epoch 2/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.2900 - accuracy: 0.8894
Epoch 3/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.1536 - accuracy: 0.9485
Epoch 4/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0818 - accuracy: 0.9759
Epoch 5/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.0489 - accuracy: 0.9866
Epoch 6/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.0314 - accuracy: 0.99190s - loss: 0.031
Epoch 7/8
16667/16667 [==============================] - 3s 167us/step - loss: 0.0229 - accuracy: 0.9946
Epoch 8/8
16667/16667 [==============================] - 3s 159us/step - loss: 0.0178 - accuracy: 0.99510s - loss: 0.017
8333/8333 [==============================] - 0s 43us/step
Epoch 1/8
16666/16666 [==============================] - 3s 159us/step - loss: 0.6055 - accuracy: 0.6662
Epoch 2/8
16666/16666 [==============================] - 2s 147us/step - loss: 0.3231 - accuracy: 0.8732
Epoch 3/8
16666/16666 [==============================] - 3s 152us/step - loss: 0.2163 - accuracy: 0.9170
Epoch 4/8
16666/16666 [==============================] - 3s 153us/step - loss: 0.1476 - accuracy: 0.9462
Epoch 5/8
16666/16666 [==============================] - 3s 155us/step - loss: 0.0985 - accuracy: 0.9657
Epoch 6/8
16666/16666 [==============================] - 2s 150us/step - loss: 0.0665 - accuracy: 0.9774
Epoch 7/8
16666/16666 [==============================] - 2s 150us/step - loss: 0.0500 - accuracy: 0.9834
Epoch 8/8
16666/16666 [==============================] - 2s 150us/step - loss: 0.0353 - accuracy: 0.9887
8334/8334 [==============================] - 0s 43us/step
Epoch 1/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.6155 - accuracy: 0.6455
Epoch 2/8
16667/16667 [==============================] - 3s 150us/step - loss: 0.3344 - accuracy: 0.8634
Epoch 3/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.2207 - accuracy: 0.9173
Epoch 4/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.1539 - accuracy: 0.9456
Epoch 5/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.1017 - accuracy: 0.9666
Epoch 6/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0695 - accuracy: 0.9774
Epoch 7/8
16667/16667 [==============================] - 3s 150us/step - loss: 0.0470 - accuracy: 0.9842
Epoch 8/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.0386 - accuracy: 0.9875
8333/8333 [==============================] - 0s 49us/step
Epoch 1/8
16667/16667 [==============================] - 3s 159us/step - loss: 0.6212 - accuracy: 0.6416
Epoch 2/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.3390 - accuracy: 0.8653
Epoch 3/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.2193 - accuracy: 0.9158
Epoch 4/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.1461 - accuracy: 0.9493
Epoch 5/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.1017 - accuracy: 0.96420s - loss:
Epoch 6/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.0681 - accuracy: 0.9767
Epoch 7/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0458 - accuracy: 0.98500s - loss: 0
Epoch 8/8
16667/16667 [==============================] - 3s 150us/step - loss: 0.0329 - accuracy: 0.9893
8333/8333 [==============================] - 0s 47us/step
Epoch 1/8
16666/16666 [==============================] - 3s 170us/step - loss: 0.5975 - accuracy: 0.6580
Epoch 2/8
16666/16666 [==============================] - 3s 159us/step - loss: 0.2731 - accuracy: 0.8932
Epoch 3/8
16666/16666 [==============================] - 3s 161us/step - loss: 0.1364 - accuracy: 0.9541
Epoch 4/8
16666/16666 [==============================] - 3s 167us/step - loss: 0.0672 - accuracy: 0.9800
Epoch 5/8
16666/16666 [==============================] - 3s 159us/step - loss: 0.0401 - accuracy: 0.9884
Epoch 6/8
16666/16666 [==============================] - 3s 159us/step - loss: 0.0251 - accuracy: 0.99350s - loss: 0.0
Epoch 7/8
16666/16666 [==============================] - 3s 160us/step - loss: 0.0199 - accuracy: 0.9947
Epoch 8/8
16666/16666 [==============================] - 3s 160us/step - loss: 0.0161 - accuracy: 0.9956
8334/8334 [==============================] - 0s 51us/step
Epoch 1/8
16667/16667 [==============================] - 3s 174us/step - loss: 0.5918 - accuracy: 0.6665
Epoch 2/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.2745 - accuracy: 0.8931
Epoch 3/8
16667/16667 [==============================] - 3s 165us/step - loss: 0.1435 - accuracy: 0.9528
Epoch 4/8
16667/16667 [==============================] - 3s 164us/step - loss: 0.0746 - accuracy: 0.9767
Epoch 5/8
16667/16667 [==============================] - 3s 165us/step - loss: 0.0377 - accuracy: 0.9903
Epoch 6/8
16667/16667 [==============================] - 3s 164us/step - loss: 0.0281 - accuracy: 0.9921
Epoch 7/8
16667/16667 [==============================] - 3s 170us/step - loss: 0.0193 - accuracy: 0.9952
Epoch 8/8
16667/16667 [==============================] - 3s 169us/step - loss: 0.0176 - accuracy: 0.9944
8333/8333 [==============================] - 0s 58us/step
Epoch 1/8
16667/16667 [==============================] - 3s 172us/step - loss: 0.6011 - accuracy: 0.6532
Epoch 2/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.2753 - accuracy: 0.89270s - loss: 0
Epoch 3/8
16667/16667 [==============================] - 3s 165us/step - loss: 0.1325 - accuracy: 0.9562
Epoch 4/8
16667/16667 [==============================] - 3s 169us/step - loss: 0.0650 - accuracy: 0.9801
Epoch 5/8
16667/16667 [==============================] - 3s 181us/step - loss: 0.0426 - accuracy: 0.9878
Epoch 6/8
16667/16667 [==============================] - 3s 172us/step - loss: 0.0263 - accuracy: 0.9931
Epoch 7/8
16667/16667 [==============================] - 3s 167us/step - loss: 0.0172 - accuracy: 0.9963
Epoch 8/8
16667/16667 [==============================] - 3s 168us/step - loss: 0.0189 - accuracy: 0.9940
8333/8333 [==============================] - 1s 61us/step
Epoch 1/8
16666/16666 [==============================] - 3s 174us/step - loss: 0.5919 - accuracy: 0.6703
Epoch 2/8
16666/16666 [==============================] - 3s 155us/step - loss: 0.3045 - accuracy: 0.8777
Epoch 3/8
16666/16666 [==============================] - 3s 160us/step - loss: 0.2008 - accuracy: 0.9207
Epoch 4/8
16666/16666 [==============================] - 3s 159us/step - loss: 0.1328 - accuracy: 0.9533
Epoch 5/8
16666/16666 [==============================] - 3s 157us/step - loss: 0.0870 - accuracy: 0.9678
Epoch 6/8
16666/16666 [==============================] - 3s 158us/step - loss: 0.0563 - accuracy: 0.9803
Epoch 7/8
16666/16666 [==============================] - 3s 161us/step - loss: 0.0390 - accuracy: 0.9870
Epoch 8/8
16666/16666 [==============================] - 3s 164us/step - loss: 0.0307 - accuracy: 0.9885
8334/8334 [==============================] - 1s 62us/step
Epoch 1/8
16667/16667 [==============================] - 3s 169us/step - loss: 0.5985 - accuracy: 0.6695
Epoch 2/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.3142 - accuracy: 0.8716
Epoch 3/8
16667/16667 [==============================] - 3s 157us/step - loss: 0.2052 - accuracy: 0.9236
Epoch 4/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.1397 - accuracy: 0.9477
Epoch 5/8
16667/16667 [==============================] - 3s 165us/step - loss: 0.0907 - accuracy: 0.9685
Epoch 6/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0608 - accuracy: 0.9801
Epoch 7/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0455 - accuracy: 0.9844
Epoch 8/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0300 - accuracy: 0.9900
8333/8333 [==============================] - 1s 63us/step
Epoch 1/8
16667/16667 [==============================] - 3s 172us/step - loss: 0.5946 - accuracy: 0.6677
Epoch 2/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.3164 - accuracy: 0.8751
Epoch 3/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.2094 - accuracy: 0.9223
Epoch 4/8
16667/16667 [==============================] - 3s 159us/step - loss: 0.1432 - accuracy: 0.9474
Epoch 5/8
16667/16667 [==============================] - 3s 159us/step - loss: 0.0902 - accuracy: 0.9688
Epoch 6/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.0632 - accuracy: 0.9780
Epoch 7/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.0442 - accuracy: 0.98420s - loss: 0.0443 - accuracy
Epoch 8/8
16667/16667 [==============================] - 3s 166us/step - loss: 0.0327 - accuracy: 0.9893
8333/8333 [==============================] - 1s 67us/step
Epoch 1/8
16666/16666 [==============================] - 3s 186us/step - loss: 0.5908 - accuracy: 0.6612
Epoch 2/8
16666/16666 [==============================] - 3s 172us/step - loss: 0.2684 - accuracy: 0.8945
Epoch 3/8
16666/16666 [==============================] - 3s 179us/step - loss: 0.1283 - accuracy: 0.9549
Epoch 4/8
16666/16666 [==============================] - 3s 175us/step - loss: 0.0643 - accuracy: 0.9800
Epoch 5/8
16666/16666 [==============================] - 3s 183us/step - loss: 0.0401 - accuracy: 0.9875
Epoch 6/8
16666/16666 [==============================] - 3s 176us/step - loss: 0.0274 - accuracy: 0.9920
Epoch 7/8
16666/16666 [==============================] - 3s 175us/step - loss: 0.0200 - accuracy: 0.9938
Epoch 8/8
16666/16666 [==============================] - 3s 176us/step - loss: 0.0199 - accuracy: 0.9935
8334/8334 [==============================] - 1s 71us/step
Epoch 1/8
16667/16667 [==============================] - 3s 187us/step - loss: 0.5991 - accuracy: 0.6591
Epoch 2/8
16667/16667 [==============================] - 3s 177us/step - loss: 0.2740 - accuracy: 0.8916
Epoch 3/8
16667/16667 [==============================] - 3s 176us/step - loss: 0.1317 - accuracy: 0.9542
Epoch 4/8
16667/16667 [==============================] - 3s 176us/step - loss: 0.0616 - accuracy: 0.9821
Epoch 5/8
16667/16667 [==============================] - 3s 176us/step - loss: 0.0406 - accuracy: 0.9872
Epoch 6/8
16667/16667 [==============================] - 3s 175us/step - loss: 0.0268 - accuracy: 0.9920
Epoch 7/8
16667/16667 [==============================] - 3s 182us/step - loss: 0.0188 - accuracy: 0.9947
Epoch 8/8
16667/16667 [==============================] - 3s 177us/step - loss: 0.0209 - accuracy: 0.9930
8333/8333 [==============================] - 1s 72us/step
Epoch 1/8
16667/16667 [==============================] - 3s 190us/step - loss: 0.5953 - accuracy: 0.6623
Epoch 2/8
16667/16667 [==============================] - 3s 172us/step - loss: 0.2713 - accuracy: 0.8937
Epoch 3/8
16667/16667 [==============================] - 3s 175us/step - loss: 0.1298 - accuracy: 0.9551
Epoch 4/8
16667/16667 [==============================] - 3s 183us/step - loss: 0.0643 - accuracy: 0.9800
Epoch 5/8
16667/16667 [==============================] - 3s 177us/step - loss: 0.0397 - accuracy: 0.9888
Epoch 6/8
16667/16667 [==============================] - 3s 176us/step - loss: 0.0277 - accuracy: 0.9913
Epoch 7/8
16667/16667 [==============================] - 3s 177us/step - loss: 0.0225 - accuracy: 0.9932
Epoch 8/8
16667/16667 [==============================] - 3s 176us/step - loss: 0.0195 - accuracy: 0.9931
8333/8333 [==============================] - 1s 74us/step
Epoch 1/8
16666/16666 [==============================] - 3s 181us/step - loss: 0.5775 - accuracy: 0.6841
Epoch 2/8
16666/16666 [==============================] - 3s 164us/step - loss: 0.2958 - accuracy: 0.8786
Epoch 3/8
16666/16666 [==============================] - 3s 165us/step - loss: 0.1942 - accuracy: 0.9236
Epoch 4/8
16666/16666 [==============================] - 3s 169us/step - loss: 0.1293 - accuracy: 0.9514
Epoch 5/8
16666/16666 [==============================] - 3s 167us/step - loss: 0.0829 - accuracy: 0.9715
Epoch 6/8
16666/16666 [==============================] - 3s 173us/step - loss: 0.0575 - accuracy: 0.9807
Epoch 7/8
16666/16666 [==============================] - 3s 170us/step - loss: 0.0394 - accuracy: 0.9870
Epoch 8/8
16666/16666 [==============================] - 3s 167us/step - loss: 0.0320 - accuracy: 0.9894
8334/8334 [==============================] - 1s 77us/step
Epoch 1/8
16667/16667 [==============================] - 3s 184us/step - loss: 0.5926 - accuracy: 0.6671
Epoch 2/8
16667/16667 [==============================] - 3s 165us/step - loss: 0.3017 - accuracy: 0.8792
Epoch 3/8
16667/16667 [==============================] - 3s 171us/step - loss: 0.1947 - accuracy: 0.9262
Epoch 4/8
16667/16667 [==============================] - 3s 169us/step - loss: 0.1366 - accuracy: 0.9498
Epoch 5/8
16667/16667 [==============================] - 3s 168us/step - loss: 0.0862 - accuracy: 0.9686
Epoch 6/8
16667/16667 [==============================] - 3s 168us/step - loss: 0.0585 - accuracy: 0.9800
Epoch 7/8
16667/16667 [==============================] - 3s 170us/step - loss: 0.0435 - accuracy: 0.9849
Epoch 8/8
16667/16667 [==============================] - 3s 168us/step - loss: 0.0306 - accuracy: 0.9882
8333/8333 [==============================] - 1s 86us/step
Epoch 1/8
16667/16667 [==============================] - 3s 188us/step - loss: 0.5938 - accuracy: 0.6687
Epoch 2/8
16667/16667 [==============================] - 3s 166us/step - loss: 0.3086 - accuracy: 0.8745
Epoch 3/8
16667/16667 [==============================] - 3s 167us/step - loss: 0.1930 - accuracy: 0.9249
Epoch 4/8
16667/16667 [==============================] - 3s 170us/step - loss: 0.1251 - accuracy: 0.9533
Epoch 5/8
16667/16667 [==============================] - 3s 171us/step - loss: 0.0811 - accuracy: 0.9711
Epoch 6/8
16667/16667 [==============================] - 3s 177us/step - loss: 0.0558 - accuracy: 0.9799
Epoch 7/8
16667/16667 [==============================] - 3s 170us/step - loss: 0.0382 - accuracy: 0.9870
Epoch 8/8
16667/16667 [==============================] - 3s 171us/step - loss: 0.0294 - accuracy: 0.9891
8333/8333 [==============================] - 1s 81us/step
Epoch 1/8
16666/16666 [==============================] - 3s 157us/step - loss: 0.6685 - accuracy: 0.5922
Epoch 2/8
16666/16666 [==============================] - 2s 139us/step - loss: 0.4059 - accuracy: 0.8433
Epoch 3/8
16666/16666 [==============================] - 2s 144us/step - loss: 0.2449 - accuracy: 0.9155
Epoch 4/8
16666/16666 [==============================] - 2s 142us/step - loss: 0.1576 - accuracy: 0.9518
Epoch 5/8
16666/16666 [==============================] - 2s 142us/step - loss: 0.1047 - accuracy: 0.9726
Epoch 6/8
16666/16666 [==============================] - 2s 142us/step - loss: 0.0740 - accuracy: 0.9800
Epoch 7/8
16666/16666 [==============================] - 2s 143us/step - loss: 0.0470 - accuracy: 0.9911
Epoch 8/8
16666/16666 [==============================] - 2s 142us/step - loss: 0.0346 - accuracy: 0.9947
8334/8334 [==============================] - 1s 76us/step
Epoch 1/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.6728 - accuracy: 0.5732
Epoch 2/8
16667/16667 [==============================] - 2s 141us/step - loss: 0.4134 - accuracy: 0.8388
Epoch 3/8
16667/16667 [==============================] - 2s 141us/step - loss: 0.2462 - accuracy: 0.9135
Epoch 4/8
16667/16667 [==============================] - 2s 144us/step - loss: 0.1592 - accuracy: 0.9513
Epoch 5/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.1018 - accuracy: 0.9738
Epoch 6/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0669 - accuracy: 0.9845
Epoch 7/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.0462 - accuracy: 0.9911
Epoch 8/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.0346 - accuracy: 0.9932
8333/8333 [==============================] - 1s 77us/step
Epoch 1/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.6726 - accuracy: 0.5743
Epoch 2/8
16667/16667 [==============================] - 2s 142us/step - loss: 0.4191 - accuracy: 0.8325
Epoch 3/8
16667/16667 [==============================] - 2s 142us/step - loss: 0.2468 - accuracy: 0.9135
Epoch 4/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.1617 - accuracy: 0.9506
Epoch 5/8
16667/16667 [==============================] - 2s 150us/step - loss: 0.1015 - accuracy: 0.9741
Epoch 6/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0698 - accuracy: 0.9830
Epoch 7/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.0466 - accuracy: 0.9908
Epoch 8/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.0360 - accuracy: 0.9927
8333/8333 [==============================] - ETA:  - 1s 80us/step
Epoch 1/8
16666/16666 [==============================] - 3s 157us/step - loss: 0.6611 - accuracy: 0.5964
Epoch 2/8
16666/16666 [==============================] - 2s 142us/step - loss: 0.4184 - accuracy: 0.8376
Epoch 3/8
16666/16666 [==============================] - 2s 138us/step - loss: 0.2765 - accuracy: 0.8990
Epoch 4/8
16666/16666 [==============================] - 2s 139us/step - loss: 0.2032 - accuracy: 0.9304
Epoch 5/8
16666/16666 [==============================] - 2s 141us/step - loss: 0.1519 - accuracy: 0.9509
Epoch 6/8
16666/16666 [==============================] - 2s 141us/step - loss: 0.1147 - accuracy: 0.9639
Epoch 7/8
16666/16666 [==============================] - 2s 141us/step - loss: 0.0848 - accuracy: 0.9738
Epoch 8/8
16666/16666 [==============================] - 2s 141us/step - loss: 0.0642 - accuracy: 0.9809
8334/8334 [==============================] - 1s 84us/step
Epoch 1/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.6633 - accuracy: 0.5987
Epoch 2/8
16667/16667 [==============================] - 2s 138us/step - loss: 0.4335 - accuracy: 0.8313
Epoch 3/8
16667/16667 [==============================] - 2s 138us/step - loss: 0.2927 - accuracy: 0.8898
Epoch 4/8
16667/16667 [==============================] - 2s 139us/step - loss: 0.2239 - accuracy: 0.9213
Epoch 5/8
16667/16667 [==============================] - 2s 141us/step - loss: 0.1720 - accuracy: 0.9422
Epoch 6/8
16667/16667 [==============================] - 2s 142us/step - loss: 0.1295 - accuracy: 0.9584
Epoch 7/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.0997 - accuracy: 0.9694
Epoch 8/8
16667/16667 [==============================] - 2s 142us/step - loss: 0.0766 - accuracy: 0.9756
8333/8333 [==============================] - 1s 83us/step
Epoch 1/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.6580 - accuracy: 0.6091
Epoch 2/8
16667/16667 [==============================] - 2s 141us/step - loss: 0.4201 - accuracy: 0.8366
Epoch 3/8
16667/16667 [==============================] - 2s 141us/step - loss: 0.2797 - accuracy: 0.8972
Epoch 4/8
16667/16667 [==============================] - 2s 144us/step - loss: 0.2147 - accuracy: 0.9249
Epoch 5/8
16667/16667 [==============================] - 2s 144us/step - loss: 0.1608 - accuracy: 0.9459
Epoch 6/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.1225 - accuracy: 0.9609
Epoch 7/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.0911 - accuracy: 0.9717
Epoch 8/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.0679 - accuracy: 0.9800
8333/8333 [==============================] - 1s 87us/step
Epoch 1/8
16666/16666 [==============================] - 3s 163us/step - loss: 0.6561 - accuracy: 0.5940
Epoch 2/8
16666/16666 [==============================] - 2s 148us/step - loss: 0.3567 - accuracy: 0.8601
Epoch 3/8
16666/16666 [==============================] - 2s 143us/step - loss: 0.2013 - accuracy: 0.9300
Epoch 4/8
16666/16666 [==============================] - 2s 144us/step - loss: 0.1183 - accuracy: 0.9661
Epoch 5/8
16666/16666 [==============================] - 2s 146us/step - loss: 0.0674 - accuracy: 0.9826
Epoch 6/8
16666/16666 [==============================] - 2s 146us/step - loss: 0.0448 - accuracy: 0.9893
Epoch 7/8
16666/16666 [==============================] - 2s 148us/step - loss: 0.0264 - accuracy: 0.9952
Epoch 8/8
16666/16666 [==============================] - 3s 151us/step - loss: 0.0211 - accuracy: 0.9963
8334/8334 [==============================] - 1s 92us/step
Epoch 1/8
16667/16667 [==============================] - 3s 163us/step - loss: 0.6619 - accuracy: 0.5931
Epoch 2/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.3690 - accuracy: 0.8538
Epoch 3/8
16667/16667 [==============================] - 2s 144us/step - loss: 0.2029 - accuracy: 0.9286
Epoch 4/8
16667/16667 [==============================] - 2s 144us/step - loss: 0.1201 - accuracy: 0.9645
Epoch 5/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.0700 - accuracy: 0.9831
Epoch 6/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.0448 - accuracy: 0.9904
Epoch 7/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0290 - accuracy: 0.9947
Epoch 8/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0221 - accuracy: 0.9956
8333/8333 [==============================] - 1s 92us/step
Epoch 1/8
16667/16667 [==============================] - 3s 167us/step - loss: 0.6543 - accuracy: 0.6021
Epoch 2/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.3557 - accuracy: 0.8652
Epoch 3/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.2014 - accuracy: 0.9306
Epoch 4/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.1162 - accuracy: 0.9648
Epoch 5/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.0721 - accuracy: 0.9807
Epoch 6/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.0429 - accuracy: 0.9911
Epoch 7/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.0307 - accuracy: 0.9926
Epoch 8/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.0208 - accuracy: 0.9959
8333/8333 [==============================] - 1s 95us/step
Epoch 1/8
16666/16666 [==============================] - 3s 162us/step - loss: 0.6423 - accuracy: 0.6234
Epoch 2/8
16666/16666 [==============================] - 2s 140us/step - loss: 0.3782 - accuracy: 0.8538
Epoch 3/8
16666/16666 [==============================] - 2s 140us/step - loss: 0.2494 - accuracy: 0.9070
Epoch 4/8
16666/16666 [==============================] - 2s 140us/step - loss: 0.1806 - accuracy: 0.9346
Epoch 5/8
16666/16666 [==============================] - 2s 141us/step - loss: 0.1277 - accuracy: 0.9564
Epoch 6/8
16666/16666 [==============================] - 2s 143us/step - loss: 0.0888 - accuracy: 0.9701
Epoch 7/8
16666/16666 [==============================] - 2s 149us/step - loss: 0.0625 - accuracy: 0.9810
Epoch 8/8
16666/16666 [==============================] - 2s 145us/step - loss: 0.0451 - accuracy: 0.9861
8334/8334 [==============================] - 1s 96us/step
Epoch 1/8
16667/16667 [==============================] - 3s 164us/step - loss: 0.6525 - accuracy: 0.6138
Epoch 2/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.3872 - accuracy: 0.8498
Epoch 3/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.2516 - accuracy: 0.9074
Epoch 4/8
16667/16667 [==============================] - 2s 144us/step - loss: 0.1801 - accuracy: 0.9359
Epoch 5/8
16667/16667 [==============================] - 3s 163us/step - loss: 0.1302 - accuracy: 0.9558
Epoch 6/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.0890 - accuracy: 0.9708
Epoch 7/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0592 - accuracy: 0.9816
Epoch 8/8
16667/16667 [==============================] - 2s 145us/step - loss: 0.0426 - accuracy: 0.9873
8333/8333 [==============================] - 1s 97us/step
Epoch 1/8
16667/16667 [==============================] - 3s 166us/step - loss: 0.6415 - accuracy: 0.6285
Epoch 2/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.3796 - accuracy: 0.8517
Epoch 3/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.2511 - accuracy: 0.9057
Epoch 4/8
16667/16667 [==============================] - 2s 143us/step - loss: 0.1800 - accuracy: 0.9358
Epoch 5/8
16667/16667 [==============================] - 2s 142us/step - loss: 0.1330 - accuracy: 0.9537
Epoch 6/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.0952 - accuracy: 0.9689
Epoch 7/8
16667/16667 [==============================] - 2s 146us/step - loss: 0.0654 - accuracy: 0.9781
Epoch 8/8
16667/16667 [==============================] - 2s 150us/step - loss: 0.0494 - accuracy: 0.9840
8333/8333 [==============================] - 1s 103us/step
Epoch 1/8
16666/16666 [==============================] - 3s 171us/step - loss: 0.6470 - accuracy: 0.6096
Epoch 2/8
16666/16666 [==============================] - 2s 148us/step - loss: 0.3346 - accuracy: 0.8654
Epoch 3/8
16666/16666 [==============================] - 2s 149us/step - loss: 0.1814 - accuracy: 0.9375
Epoch 4/8
16666/16666 [==============================] - 2s 148us/step - loss: 0.1042 - accuracy: 0.9687
Epoch 5/8
16666/16666 [==============================] - 3s 152us/step - loss: 0.0601 - accuracy: 0.9849
Epoch 6/8
16666/16666 [==============================] - 3s 156us/step - loss: 0.0353 - accuracy: 0.9920
Epoch 7/8
16666/16666 [==============================] - 2s 150us/step - loss: 0.0247 - accuracy: 0.9953
Epoch 8/8
16666/16666 [==============================] - 2s 150us/step - loss: 0.0166 - accuracy: 0.9962
8334/8334 [==============================] - 1s 104us/step
Epoch 1/8
16667/16667 [==============================] - 3s 170us/step - loss: 0.6398 - accuracy: 0.6216
Epoch 2/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.3256 - accuracy: 0.8738
Epoch 3/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.1798 - accuracy: 0.9389
Epoch 4/8
16667/16667 [==============================] - 2s 147us/step - loss: 0.0998 - accuracy: 0.9701
Epoch 5/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.0562 - accuracy: 0.98490s - loss: 0.0567 - accuracy: 0.98 - ETA: 0s
Epoch 6/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0357 - accuracy: 0.9915
Epoch 7/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.0258 - accuracy: 0.9939
Epoch 8/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0176 - accuracy: 0.9968
8333/8333 [==============================] - 1s 108us/step
Epoch 1/8
16667/16667 [==============================] - 3s 174us/step - loss: 0.6536 - accuracy: 0.6069
Epoch 2/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.3478 - accuracy: 0.86120s - loss: 0.3497 - accuracy
Epoch 3/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.1888 - accuracy: 0.9336
Epoch 4/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.1053 - accuracy: 0.9668
Epoch 5/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0591 - accuracy: 0.9851
Epoch 6/8
16667/16667 [==============================] - 3s 162us/step - loss: 0.0351 - accuracy: 0.9930
Epoch 7/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.0235 - accuracy: 0.9950
Epoch 8/8
16667/16667 [==============================] - 3s 153us/step - loss: 0.0189 - accuracy: 0.99560s - l
8333/8333 [==============================] - 1s 109us/step
Epoch 1/8
16666/16666 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.65 - 3s 172us/step - loss: 0.6153 - accuracy: 0.6553
Epoch 2/8
16666/16666 [==============================] - 2s 147us/step - loss: 0.3365 - accuracy: 0.8661
Epoch 3/8
16666/16666 [==============================] - 3s 151us/step - loss: 0.2249 - accuracy: 0.9153
Epoch 4/8
16666/16666 [==============================] - 2s 147us/step - loss: 0.1527 - accuracy: 0.9450
Epoch 5/8
16666/16666 [==============================] - 2s 147us/step - loss: 0.1034 - accuracy: 0.9639
Epoch 6/8
16666/16666 [==============================] - 2s 147us/step - loss: 0.0698 - accuracy: 0.9760
Epoch 7/8
16666/16666 [==============================] - 2s 147us/step - loss: 0.0467 - accuracy: 0.9861
Epoch 8/8
16666/16666 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.98 - 2s 149us/step - loss: 0.0354 - accuracy: 0.9878
8334/8334 [==============================] - 1s 112us/step
Epoch 1/8
16667/16667 [==============================] - 3s 172us/step - loss: 0.6382 - accuracy: 0.6333
Epoch 2/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.3654 - accuracy: 0.8531
Epoch 3/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.2372 - accuracy: 0.9091
Epoch 4/8
16667/16667 [==============================] - 2s 149us/step - loss: 0.1693 - accuracy: 0.9392
Epoch 5/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.1150 - accuracy: 0.9624
Epoch 6/8
16667/16667 [==============================] - 3s 151us/step - loss: 0.0827 - accuracy: 0.9731
Epoch 7/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.0527 - accuracy: 0.9833
Epoch 8/8
16667/16667 [==============================] - 3s 150us/step - loss: 0.0408 - accuracy: 0.9868
8333/8333 [==============================] - 1s 114us/step
Epoch 1/8
16667/16667 [==============================] - 3s 174us/step - loss: 0.6326 - accuracy: 0.6408
Epoch 2/8
16667/16667 [==============================] - 2s 147us/step - loss: 0.3600 - accuracy: 0.8532
Epoch 3/8
16667/16667 [==============================] - 3s 150us/step - loss: 0.2371 - accuracy: 0.9089
Epoch 4/8
16667/16667 [==============================] - 2s 147us/step - loss: 0.1685 - accuracy: 0.9362
Epoch 5/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.1191 - accuracy: 0.9584
Epoch 6/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.0844 - accuracy: 0.9710
Epoch 7/8
16667/16667 [==============================] - 2s 148us/step - loss: 0.0569 - accuracy: 0.9809
Epoch 8/8
16667/16667 [==============================] - 2s 150us/step - loss: 0.0404 - accuracy: 0.9857
8333/8333 [==============================] - 1s 115us/step
Epoch 1/8
16666/16666 [==============================] - 3s 182us/step - loss: 0.6245 - accuracy: 0.6370
Epoch 2/8
16666/16666 [==============================] - 3s 156us/step - loss: 0.3097 - accuracy: 0.8765
Epoch 3/8
16666/16666 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9445 - 3s 156us/step - loss: 0.1607 - accuracy: 0.9446
Epoch 4/8
16666/16666 [==============================] - 3s 157us/step - loss: 0.0857 - accuracy: 0.97520s
Epoch 5/8
16666/16666 [==============================] - 3s 157us/step - loss: 0.0518 - accuracy: 0.98640s - loss: 0.0528 - accura
Epoch 6/8
16666/16666 [==============================] - 3s 163us/step - loss: 0.0311 - accuracy: 0.9923
Epoch 7/8
16666/16666 [==============================] - 3s 163us/step - loss: 0.0218 - accuracy: 0.99450s - l
Epoch 8/8
16666/16666 [==============================] - 3s 160us/step - loss: 0.0155 - accuracy: 0.9963
8334/8334 [==============================] - 1s 121us/step
Epoch 1/8
16667/16667 [==============================] - 3s 186us/step - loss: 0.6460 - accuracy: 0.6047
Epoch 2/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.3217 - accuracy: 0.8742
Epoch 3/8
16667/16667 [==============================] - 3s 162us/step - loss: 0.1698 - accuracy: 0.9417
Epoch 4/8
16667/16667 [==============================] - 3s 158us/step - loss: 0.0911 - accuracy: 0.97260s - loss: 0.0911 - accuracy: 0.97
Epoch 5/8
16667/16667 [==============================] - 3s 159us/step - loss: 0.0509 - accuracy: 0.9869
Epoch 6/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.0341 - accuracy: 0.9909
Epoch 7/8
16667/16667 [==============================] - 3s 162us/step - loss: 0.0229 - accuracy: 0.9938
Epoch 8/8
16667/16667 [==============================] - 3s 162us/step - loss: 0.0170 - accuracy: 0.9962
8333/8333 [==============================] - 1s 128us/step
Epoch 1/8
16667/16667 [==============================] - 3s 183us/step - loss: 0.6505 - accuracy: 0.60560s - loss: 0.6623 - accura
Epoch 2/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.3315 - accuracy: 0.8677
Epoch 3/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.1758 - accuracy: 0.9388
Epoch 4/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.0943 - accuracy: 0.9710
Epoch 5/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.0534 - accuracy: 0.9860
Epoch 6/8
16667/16667 [==============================] - 3s 165us/step - loss: 0.0324 - accuracy: 0.9922
Epoch 7/8
16667/16667 [==============================] - 3s 160us/step - loss: 0.0199 - accuracy: 0.9959
Epoch 8/8
16667/16667 [==============================] - 3s 161us/step - loss: 0.0195 - accuracy: 0.9955
8333/8333 [==============================] - 1s 126us/step
Epoch 1/8
16666/16666 [==============================] - 3s 181us/step - loss: 0.6223 - accuracy: 0.6426
Epoch 2/8
16666/16666 [==============================] - 3s 156us/step - loss: 0.3433 - accuracy: 0.8594
Epoch 3/8
16666/16666 [==============================] - 3s 152us/step - loss: 0.2193 - accuracy: 0.9176
Epoch 4/8
16666/16666 [==============================] - 3s 153us/step - loss: 0.1496 - accuracy: 0.9456
Epoch 5/8
16666/16666 [==============================] - 3s 152us/step - loss: 0.1032 - accuracy: 0.9632
Epoch 6/8
16666/16666 [==============================] - 3s 153us/step - loss: 0.0697 - accuracy: 0.9771
Epoch 7/8
16666/16666 [==============================] - 3s 152us/step - loss: 0.0449 - accuracy: 0.9857
Epoch 8/8
16666/16666 [==============================] - 3s 156us/step - loss: 0.0369 - accuracy: 0.9879
8334/8334 [==============================] - 1s 131us/step
Epoch 1/8
16667/16667 [==============================] - 3s 179us/step - loss: 0.6382 - accuracy: 0.6279
Epoch 2/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.3563 - accuracy: 0.8565
Epoch 3/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.2313 - accuracy: 0.9111
Epoch 4/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.1579 - accuracy: 0.9426
Epoch 5/8
16667/16667 [==============================] - 3s 157us/step - loss: 0.1027 - accuracy: 0.9671
Epoch 6/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.0689 - accuracy: 0.9771
Epoch 7/8
16667/16667 [==============================] - 3s 152us/step - loss: 0.0454 - accuracy: 0.9851
Epoch 8/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.0350 - accuracy: 0.9885
8333/8333 [==============================] - 1s 129us/step
Epoch 1/8
16667/16667 [==============================] - 3s 181us/step - loss: 0.6295 - accuracy: 0.6417
Epoch 2/8
16667/16667 [==============================] - 3s 156us/step - loss: 0.3536 - accuracy: 0.8594
Epoch 3/8
16667/16667 [==============================] - 3s 153us/step - loss: 0.2274 - accuracy: 0.9135
Epoch 4/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.1544 - accuracy: 0.9431
Epoch 5/8
16667/16667 [==============================] - 3s 153us/step - loss: 0.1053 - accuracy: 0.9641
Epoch 6/8
16667/16667 [==============================] - 3s 154us/step - loss: 0.0693 - accuracy: 0.9765
Epoch 7/8
16667/16667 [==============================] - 3s 153us/step - loss: 0.0464 - accuracy: 0.9847
Epoch 8/8
16667/16667 [==============================] - 3s 159us/step - loss: 0.0321 - accuracy: 0.9885
8333/8333 [==============================] - 1s 137us/step
Epoch 1/8
16666/16666 [==============================] - 5s 309us/step - loss: 0.6069 - accuracy: 0.6565
Epoch 2/8
16666/16666 [==============================] - 5s 280us/step - loss: 0.2903 - accuracy: 0.8925
Epoch 3/8
16666/16666 [==============================] - 5s 283us/step - loss: 0.1447 - accuracy: 0.9570
Epoch 4/8
16666/16666 [==============================] - 5s 280us/step - loss: 0.0719 - accuracy: 0.9826
Epoch 5/8
16666/16666 [==============================] - 5s 284us/step - loss: 0.0388 - accuracy: 0.9927
Epoch 6/8
16666/16666 [==============================] - 5s 288us/step - loss: 0.0244 - accuracy: 0.9958
Epoch 7/8
16666/16666 [==============================] - 5s 283us/step - loss: 0.0165 - accuracy: 0.9970
Epoch 8/8
16666/16666 [==============================] - 5s 283us/step - loss: 0.0130 - accuracy: 0.9975
8334/8334 [==============================] - 1s 158us/step
Epoch 1/8
16667/16667 [==============================] - 5s 312us/step - loss: 0.6057 - accuracy: 0.6605
Epoch 2/8
16667/16667 [==============================] - 5s 284us/step - loss: 0.2925 - accuracy: 0.8929
Epoch 3/8
16667/16667 [==============================] - 5s 285us/step - loss: 0.1504 - accuracy: 0.9548
Epoch 4/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.0772 - accuracy: 0.9813
Epoch 5/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.0392 - accuracy: 0.9924
Epoch 6/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.0246 - accuracy: 0.9962
Epoch 7/8
16667/16667 [==============================] - 5s 291us/step - loss: 0.0170 - accuracy: 0.9973
Epoch 8/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.0143 - accuracy: 0.9968
8333/8333 [==============================] - 1s 162us/step
Epoch 1/8
16667/16667 [==============================] - 5s 316us/step - loss: 0.6248 - accuracy: 0.6414
Epoch 2/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.3044 - accuracy: 0.8867
Epoch 3/8
16667/16667 [==============================] - 5s 284us/step - loss: 0.1563 - accuracy: 0.9529
Epoch 4/8
16667/16667 [==============================] - 5s 284us/step - loss: 0.0744 - accuracy: 0.9815
Epoch 5/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.0396 - accuracy: 0.9926
Epoch 6/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.0264 - accuracy: 0.9949
Epoch 7/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.0162 - accuracy: 0.9977
Epoch 8/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.0137 - accuracy: 0.9973
8333/8333 [==============================] - 1s 164us/step
Epoch 1/8
16666/16666 [==============================] - 5s 302us/step - loss: 0.6099 - accuracy: 0.6600
Epoch 2/8
16666/16666 [==============================] - 5s 280us/step - loss: 0.3270 - accuracy: 0.8745
Epoch 3/8
16666/16666 [==============================] - 5s 280us/step - loss: 0.2087 - accuracy: 0.9261
Epoch 4/8
16666/16666 [==============================] - 5s 276us/step - loss: 0.1361 - accuracy: 0.95730s - loss: 0.1357 - accuracy: 0.
Epoch 5/8
16666/16666 [==============================] - 5s 276us/step - loss: 0.0840 - accuracy: 0.97440s - loss: 0.081
Epoch 6/8
16666/16666 [==============================] - 5s 285us/step - loss: 0.0538 - accuracy: 0.9839
Epoch 7/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.0340 - accuracy: 0.9903
Epoch 8/8
16666/16666 [==============================] - 6s 343us/step - loss: 0.0227 - accuracy: 0.99390s - loss: 0.0228 - accuracy: 0.99 - ETA: 0s - loss: 0.022
8334/8334 [==============================] - 1s 168us/step
Epoch 1/8
16667/16667 [==============================] - 5s 305us/step - loss: 0.6168 - accuracy: 0.6506
Epoch 2/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.3336 - accuracy: 0.8735
Epoch 3/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.2141 - accuracy: 0.9223
Epoch 4/8
16667/16667 [==============================] - 5s 282us/step - loss: 0.1458 - accuracy: 0.9518
Epoch 5/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.0900 - accuracy: 0.9741
Epoch 6/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.0586 - accuracy: 0.9835
Epoch 7/8
16667/16667 [==============================] - 5s 289us/step - loss: 0.0360 - accuracy: 0.9906
Epoch 8/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0232 - accuracy: 0.9930
8333/8333 [==============================] - 1s 170us/step
Epoch 1/8
16667/16667 [==============================] - 5s 307us/step - loss: 0.6284 - accuracy: 0.6424
Epoch 2/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.3527 - accuracy: 0.8629
Epoch 3/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.2332 - accuracy: 0.9128
Epoch 4/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.1584 - accuracy: 0.9465
Epoch 5/8
16667/16667 [==============================] - 5s 282us/step - loss: 0.1032 - accuracy: 0.9674
Epoch 6/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0663 - accuracy: 0.97980s - loss: 0.0654 - accuracy: 0.
Epoch 7/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0419 - accuracy: 0.9878
Epoch 8/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.0288 - accuracy: 0.9918
8333/8333 [==============================] - 1s 174us/step
Epoch 1/8
16666/16666 [==============================] - 5s 322us/step - loss: 0.5930 - accuracy: 0.6618
Epoch 2/8
16666/16666 [==============================] - 5s 292us/step - loss: 0.2592 - accuracy: 0.9030
Epoch 3/8
16666/16666 [==============================] - 5s 295us/step - loss: 0.1131 - accuracy: 0.9663
Epoch 4/8
16666/16666 [==============================] - 5s 291us/step - loss: 0.0470 - accuracy: 0.9897
Epoch 5/8
16666/16666 [==============================] - 5s 293us/step - loss: 0.0240 - accuracy: 0.9957
Epoch 6/8
16666/16666 [==============================] - 5s 301us/step - loss: 0.0149 - accuracy: 0.9972
Epoch 7/8
16666/16666 [==============================] - 5s 295us/step - loss: 0.0111 - accuracy: 0.9977
Epoch 8/8
16666/16666 [==============================] - 5s 295us/step - loss: 0.0096 - accuracy: 0.9978
8334/8334 [==============================] - 1s 178us/step
Epoch 1/8
16667/16667 [==============================] - 5s 325us/step - loss: 0.5966 - accuracy: 0.6626
Epoch 2/8
16667/16667 [==============================] - 5s 294us/step - loss: 0.2583 - accuracy: 0.9046
Epoch 3/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.1091 - accuracy: 0.9688
Epoch 4/8
16667/16667 [==============================] - 5s 294us/step - loss: 0.0465 - accuracy: 0.9902
Epoch 5/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.0273 - accuracy: 0.9938
Epoch 6/8
16667/16667 [==============================] - 5s 296us/step - loss: 0.0158 - accuracy: 0.9962
Epoch 7/8
16667/16667 [==============================] - 5s 299us/step - loss: 0.0118 - accuracy: 0.9975
Epoch 8/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.0083 - accuracy: 0.9986
8333/8333 [==============================] - 1s 180us/step
Epoch 1/8
16667/16667 [==============================] - 5s 327us/step - loss: 0.5955 - accuracy: 0.6641
Epoch 2/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.2619 - accuracy: 0.9009
Epoch 3/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.1119 - accuracy: 0.9668
Epoch 4/8
16667/16667 [==============================] - 5s 296us/step - loss: 0.0475 - accuracy: 0.9888
Epoch 5/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.0234 - accuracy: 0.9960
Epoch 6/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.0151 - accuracy: 0.9972
Epoch 7/8
16667/16667 [==============================] - 5s 298us/step - loss: 0.0109 - accuracy: 0.9985
Epoch 8/8
16667/16667 [==============================] - 5s 300us/step - loss: 0.0118 - accuracy: 0.9968
8333/8333 [==============================] - 2s 184us/step
Epoch 1/8
16666/16666 [==============================] - 5s 317us/step - loss: 0.5913 - accuracy: 0.6749
Epoch 2/8
16666/16666 [==============================] - 5s 312us/step - loss: 0.3044 - accuracy: 0.8786
Epoch 3/8
16666/16666 [==============================] - 5s 288us/step - loss: 0.1872 - accuracy: 0.9302
Epoch 4/8
16666/16666 [==============================] - 5s 289us/step - loss: 0.1137 - accuracy: 0.9612
Epoch 5/8
16666/16666 [==============================] - 5s 307us/step - loss: 0.0660 - accuracy: 0.9793
Epoch 6/8
16666/16666 [==============================] - 5s 299us/step - loss: 0.0371 - accuracy: 0.9885
Epoch 7/8
16666/16666 [==============================] - 5s 300us/step - loss: 0.0213 - accuracy: 0.9934
Epoch 8/8
16666/16666 [==============================] - 5s 301us/step - loss: 0.0151 - accuracy: 0.9956
8334/8334 [==============================] - 2s 187us/step
Epoch 1/8
16667/16667 [==============================] - 5s 322us/step - loss: 0.5966 - accuracy: 0.6679
Epoch 2/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.3008 - accuracy: 0.8815
Epoch 3/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.1801 - accuracy: 0.9351
Epoch 4/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.1044 - accuracy: 0.9648
Epoch 5/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.0572 - accuracy: 0.9833
Epoch 6/8
16667/16667 [==============================] - 5s 293us/step - loss: 0.0338 - accuracy: 0.9908
Epoch 7/8
16667/16667 [==============================] - 5s 289us/step - loss: 0.0201 - accuracy: 0.9940
Epoch 8/8
16667/16667 [==============================] - 5s 290us/step - loss: 0.0138 - accuracy: 0.9959
8333/8333 [==============================] - 2s 193us/step
Epoch 1/8
16667/16667 [==============================] - 5s 323us/step - loss: 0.6005 - accuracy: 0.6630
Epoch 2/8
16667/16667 [==============================] - 5s 293us/step - loss: 0.3058 - accuracy: 0.8796
Epoch 3/8
16667/16667 [==============================] - 5s 296us/step - loss: 0.1797 - accuracy: 0.9343
Epoch 4/8
16667/16667 [==============================] - 5s 293us/step - loss: 0.1016 - accuracy: 0.9654
Epoch 5/8
16667/16667 [==============================] - 5s 294us/step - loss: 0.0578 - accuracy: 0.9819
Epoch 6/8
16667/16667 [==============================] - 5s 295us/step - loss: 0.0348 - accuracy: 0.9896
Epoch 7/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.0216 - accuracy: 0.9927
Epoch 8/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.0139 - accuracy: 0.9960
8333/8333 [==============================] - 2s 196us/step
Epoch 1/8
16666/16666 [==============================] - 6s 343us/step - loss: 0.5773 - accuracy: 0.6763
Epoch 2/8
16666/16666 [==============================] - 5s 308us/step - loss: 0.2407 - accuracy: 0.9086
Epoch 3/8
16666/16666 [==============================] - 5s 312us/step - loss: 0.0957 - accuracy: 0.9719
Epoch 4/8
16666/16666 [==============================] - 5s 314us/step - loss: 0.0412 - accuracy: 0.9891
Epoch 5/8
16666/16666 [==============================] - 5s 310us/step - loss: 0.0207 - accuracy: 0.9955
Epoch 6/8
16666/16666 [==============================] - 5s 310us/step - loss: 0.0132 - accuracy: 0.9973
Epoch 7/8
16666/16666 [==============================] - 5s 319us/step - loss: 0.0111 - accuracy: 0.9971
Epoch 8/8
16666/16666 [==============================] - 5s 313us/step - loss: 0.0113 - accuracy: 0.9968
8334/8334 [==============================] - 2s 197us/step
Epoch 1/8
16667/16667 [==============================] - 6s 352us/step - loss: 0.5784 - accuracy: 0.6725
Epoch 2/8
16667/16667 [==============================] - 5s 311us/step - loss: 0.2408 - accuracy: 0.9083
Epoch 3/8
16667/16667 [==============================] - 5s 313us/step - loss: 0.0959 - accuracy: 0.9702
Epoch 4/8
16667/16667 [==============================] - 5s 312us/step - loss: 0.0405 - accuracy: 0.9897
Epoch 5/8
16667/16667 [==============================] - 5s 309us/step - loss: 0.0232 - accuracy: 0.9948
Epoch 6/8
16667/16667 [==============================] - 5s 314us/step - loss: 0.0152 - accuracy: 0.9965
Epoch 7/8
16667/16667 [==============================] - 5s 320us/step - loss: 0.0138 - accuracy: 0.9966
Epoch 8/8
16667/16667 [==============================] - 5s 314us/step - loss: 0.0083 - accuracy: 0.9983
8333/8333 [==============================] - 2s 201us/step
Epoch 1/8
16667/16667 [==============================] - 6s 347us/step - loss: 0.5967 - accuracy: 0.6570
Epoch 2/8
16667/16667 [==============================] - 5s 309us/step - loss: 0.2541 - accuracy: 0.9019
Epoch 3/8
16667/16667 [==============================] - 5s 309us/step - loss: 0.0955 - accuracy: 0.9726
Epoch 4/8
16667/16667 [==============================] - 5s 312us/step - loss: 0.0392 - accuracy: 0.9908
Epoch 5/8
16667/16667 [==============================] - 5s 318us/step - loss: 0.0197 - accuracy: 0.9965
Epoch 6/8
16667/16667 [==============================] - 5s 320us/step - loss: 0.0132 - accuracy: 0.9972
Epoch 7/8
16667/16667 [==============================] - 5s 320us/step - loss: 0.0101 - accuracy: 0.9976
Epoch 8/8
16667/16667 [==============================] - 5s 313us/step - loss: 0.0079 - accuracy: 0.9981
8333/8333 [==============================] - 2s 207us/step
Epoch 1/8
16666/16666 [==============================] - 5s 329us/step - loss: 0.5699 - accuracy: 0.6910
Epoch 2/8
16666/16666 [==============================] - 5s 293us/step - loss: 0.2773 - accuracy: 0.8917
Epoch 3/8
16666/16666 [==============================] - 5s 292us/step - loss: 0.1560 - accuracy: 0.9416
Epoch 4/8
16666/16666 [==============================] - 5s 296us/step - loss: 0.0848 - accuracy: 0.9711
Epoch 5/8
16666/16666 [==============================] - 5s 294us/step - loss: 0.0448 - accuracy: 0.9852
Epoch 6/8
16666/16666 [==============================] - 5s 292us/step - loss: 0.0285 - accuracy: 0.9899
Epoch 7/8
16666/16666 [==============================] - 5s 295us/step - loss: 0.0172 - accuracy: 0.9945
Epoch 8/8
16666/16666 [==============================] - 5s 295us/step - loss: 0.0114 - accuracy: 0.9965
8334/8334 [==============================] - 2s 202us/step
Epoch 1/8
16667/16667 [==============================] - 6s 337us/step - loss: 0.5725 - accuracy: 0.6821
Epoch 2/8
16667/16667 [==============================] - 5s 297us/step - loss: 0.2773 - accuracy: 0.8916
Epoch 3/8
16667/16667 [==============================] - 5s 300us/step - loss: 0.1594 - accuracy: 0.9428
Epoch 4/8
16667/16667 [==============================] - 5s 300us/step - loss: 0.0842 - accuracy: 0.9723
Epoch 5/8
16667/16667 [==============================] - 5s 302us/step - loss: 0.0462 - accuracy: 0.9853
Epoch 6/8
16667/16667 [==============================] - 5s 298us/step - loss: 0.0247 - accuracy: 0.9927
Epoch 7/8
16667/16667 [==============================] - 5s 298us/step - loss: 0.0166 - accuracy: 0.9943
Epoch 8/8
16667/16667 [==============================] - 5s 302us/step - loss: 0.0121 - accuracy: 0.9961
8333/8333 [==============================] - 2s 206us/step
Epoch 1/8
16667/16667 [==============================] - 6s 332us/step - loss: 0.5845 - accuracy: 0.6788
Epoch 2/8
16667/16667 [==============================] - 5s 302us/step - loss: 0.2893 - accuracy: 0.8833
Epoch 3/8
16667/16667 [==============================] - 5s 298us/step - loss: 0.1626 - accuracy: 0.9422
Epoch 4/8
16667/16667 [==============================] - 5s 298us/step - loss: 0.0908 - accuracy: 0.9690
Epoch 5/8
16667/16667 [==============================] - 5s 302us/step - loss: 0.0499 - accuracy: 0.9841
Epoch 6/8
16667/16667 [==============================] - 5s 298us/step - loss: 0.0292 - accuracy: 0.9913
Epoch 7/8
16667/16667 [==============================] - 5s 299us/step - loss: 0.0210 - accuracy: 0.9932
Epoch 8/8
16667/16667 [==============================] - 5s 302us/step - loss: 0.0139 - accuracy: 0.9954
8333/8333 [==============================] - 2s 207us/step
Epoch 1/8
16666/16666 [==============================] - 6s 358us/step - loss: 0.5691 - accuracy: 0.6817
Epoch 2/8
16666/16666 [==============================] - 5s 320us/step - loss: 0.2354 - accuracy: 0.9104
Epoch 3/8
16666/16666 [==============================] - 5s 316us/step - loss: 0.0885 - accuracy: 0.9733
Epoch 4/8
16666/16666 [==============================] - 5s 316us/step - loss: 0.0369 - accuracy: 0.9898
Epoch 5/8
16666/16666 [==============================] - 5s 325us/step - loss: 0.0194 - accuracy: 0.9955
Epoch 6/8
16666/16666 [==============================] - 5s 320us/step - loss: 0.0142 - accuracy: 0.9967
Epoch 7/8
16666/16666 [==============================] - 5s 322us/step - loss: 0.0103 - accuracy: 0.9977
Epoch 8/8
16666/16666 [==============================] - 5s 329us/step - loss: 0.0101 - accuracy: 0.9972
8334/8334 [==============================] - 2s 222us/step
Epoch 1/8
16667/16667 [==============================] - 6s 356us/step - loss: 0.5797 - accuracy: 0.6738
Epoch 2/8
16667/16667 [==============================] - 5s 321us/step - loss: 0.2371 - accuracy: 0.9095
Epoch 3/8
16667/16667 [==============================] - 5s 316us/step - loss: 0.0925 - accuracy: 0.9720
Epoch 4/8
16667/16667 [==============================] - 5s 317us/step - loss: 0.0379 - accuracy: 0.9908
Epoch 5/8
16667/16667 [==============================] - 5s 329us/step - loss: 0.0200 - accuracy: 0.9957
Epoch 6/8
16667/16667 [==============================] - 5s 321us/step - loss: 0.0130 - accuracy: 0.9968
Epoch 7/8
16667/16667 [==============================] - 5s 323us/step - loss: 0.0107 - accuracy: 0.9975
Epoch 8/8
16667/16667 [==============================] - 5s 329us/step - loss: 0.0110 - accuracy: 0.9962
8333/8333 [==============================] - 2s 220us/step
Epoch 1/8
16667/16667 [==============================] - 6s 357us/step - loss: 0.5723 - accuracy: 0.6787
Epoch 2/8
16667/16667 [==============================] - 5s 322us/step - loss: 0.2373 - accuracy: 0.9102
Epoch 3/8
16667/16667 [==============================] - 5s 315us/step - loss: 0.0876 - accuracy: 0.9742
Epoch 4/8
16667/16667 [==============================] - 5s 315us/step - loss: 0.0364 - accuracy: 0.9897
Epoch 5/8
16667/16667 [==============================] - 6s 331us/step - loss: 0.0183 - accuracy: 0.9960
Epoch 6/8
16667/16667 [==============================] - 5s 319us/step - loss: 0.0129 - accuracy: 0.9969
Epoch 7/8
16667/16667 [==============================] - 5s 323us/step - loss: 0.0120 - accuracy: 0.9968
Epoch 8/8
16667/16667 [==============================] - 5s 326us/step - loss: 0.0110 - accuracy: 0.9963
8333/8333 [==============================] - 2s 223us/step
Epoch 1/8
16666/16666 [==============================] - 6s 340us/step - loss: 0.5842 - accuracy: 0.6702
Epoch 2/8
16666/16666 [==============================] - 6s 331us/step - loss: 0.2741 - accuracy: 0.8936
Epoch 3/8
16666/16666 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9447 E - 5s 316us/step - loss: 0.1554 - accuracy: 0.9446
Epoch 4/8
16666/16666 [==============================] - 5s 309us/step - loss: 0.0795 - accuracy: 0.9737
Epoch 5/8
16666/16666 [==============================] - 5s 312us/step - loss: 0.0463 - accuracy: 0.9851
Epoch 6/8
16666/16666 [==============================] - 5s 305us/step - loss: 0.0256 - accuracy: 0.9917
Epoch 7/8
16666/16666 [==============================] - 5s 306us/step - loss: 0.0168 - accuracy: 0.9948
Epoch 8/8
16666/16666 [==============================] - 5s 313us/step - loss: 0.0131 - accuracy: 0.9953
8334/8334 [==============================] - 2s 226us/step
Epoch 1/8
16667/16667 [==============================] - 6s 343us/step - loss: 0.5778 - accuracy: 0.6780
Epoch 2/8
16667/16667 [==============================] - 5s 308us/step - loss: 0.2770 - accuracy: 0.8918
Epoch 3/8
16667/16667 [==============================] - 5s 305us/step - loss: 0.1502 - accuracy: 0.9459
Epoch 4/8
16667/16667 [==============================] - 5s 304us/step - loss: 0.0798 - accuracy: 0.9730
Epoch 5/8
16667/16667 [==============================] - 5s 309us/step - loss: 0.0470 - accuracy: 0.9842
Epoch 6/8
16667/16667 [==============================] - 5s 306us/step - loss: 0.0261 - accuracy: 0.9915
Epoch 7/8
16667/16667 [==============================] - 5s 307us/step - loss: 0.0185 - accuracy: 0.9946
Epoch 8/8
16667/16667 [==============================] - 5s 321us/step - loss: 0.0118 - accuracy: 0.9958
8333/8333 [==============================] - 2s 230us/step
Epoch 1/8
16667/16667 [==============================] - 6s 346us/step - loss: 0.5731 - accuracy: 0.6851
Epoch 2/8
16667/16667 [==============================] - 5s 311us/step - loss: 0.2725 - accuracy: 0.8904
Epoch 3/8
16667/16667 [==============================] - 5s 307us/step - loss: 0.1537 - accuracy: 0.9431
Epoch 4/8
16667/16667 [==============================] - 5s 307us/step - loss: 0.0800 - accuracy: 0.9731
Epoch 5/8
16667/16667 [==============================] - 5s 311us/step - loss: 0.0432 - accuracy: 0.9856
Epoch 6/8
16667/16667 [==============================] - 5s 308us/step - loss: 0.0270 - accuracy: 0.9909
Epoch 7/8
16667/16667 [==============================] - 5s 310us/step - loss: 0.0167 - accuracy: 0.9941
Epoch 8/8
16667/16667 [==============================] - 5s 315us/step - loss: 0.0139 - accuracy: 0.9950
8333/8333 [==============================] - 2s 234us/step
Epoch 1/8
16666/16666 [==============================] - 5s 300us/step - loss: 0.6713 - accuracy: 0.5818
Epoch 2/8
16666/16666 [==============================] - 4s 261us/step - loss: 0.3923 - accuracy: 0.8502
Epoch 3/8
16666/16666 [==============================] - 4s 261us/step - loss: 0.2128 - accuracy: 0.9297
Epoch 4/8
16666/16666 [==============================] - 4s 259us/step - loss: 0.1251 - accuracy: 0.9671
Epoch 5/8
16666/16666 [==============================] - 4s 260us/step - loss: 0.0684 - accuracy: 0.9878
Epoch 6/8
16666/16666 [==============================] - 4s 263us/step - loss: 0.0416 - accuracy: 0.9930
Epoch 7/8
16666/16666 [==============================] - 4s 259us/step - loss: 0.0281 - accuracy: 0.9960
Epoch 8/8
16666/16666 [==============================] - 4s 259us/step - loss: 0.0206 - accuracy: 0.9970
8334/8334 [==============================] - 2s 209us/step
Epoch 1/8
16667/16667 [==============================] - 5s 302us/step - loss: 0.6650 - accuracy: 0.5955
Epoch 2/8
16667/16667 [==============================] - 4s 262us/step - loss: 0.3853 - accuracy: 0.8535
Epoch 3/8
16667/16667 [==============================] - 4s 262us/step - loss: 0.2100 - accuracy: 0.9320
Epoch 4/8
16667/16667 [==============================] - 4s 267us/step - loss: 0.1217 - accuracy: 0.9699
Epoch 5/8
16667/16667 [==============================] - 4s 262us/step - loss: 0.0706 - accuracy: 0.9865
Epoch 6/8
16667/16667 [==============================] - 4s 263us/step - loss: 0.0445 - accuracy: 0.9925
Epoch 7/8
16667/16667 [==============================] - 4s 266us/step - loss: 0.0292 - accuracy: 0.9959
Epoch 8/8
16667/16667 [==============================] - 4s 263us/step - loss: 0.0201 - accuracy: 0.9966
8333/8333 [==============================] - 2s 214us/step
Epoch 1/8
16667/16667 [==============================] - 5s 306us/step - loss: 0.6529 - accuracy: 0.6125
Epoch 2/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.3565 - accuracy: 0.8685
Epoch 3/8
16667/16667 [==============================] - 5s 272us/step - loss: 0.1966 - accuracy: 0.9358
Epoch 4/8
16667/16667 [==============================] - 4s 266us/step - loss: 0.1150 - accuracy: 0.9702
Epoch 5/8
16667/16667 [==============================] - 4s 268us/step - loss: 0.0662 - accuracy: 0.9869
Epoch 6/8
16667/16667 [==============================] - 4s 266us/step - loss: 0.0417 - accuracy: 0.9938
Epoch 7/8
16667/16667 [==============================] - 4s 264us/step - loss: 0.0275 - accuracy: 0.9966
Epoch 8/8
16667/16667 [==============================] - 4s 264us/step - loss: 0.0208 - accuracy: 0.9969
8333/8333 [==============================] - 2s 221us/step
Epoch 1/8
16666/16666 [==============================] - 5s 297us/step - loss: 0.6319 - accuracy: 0.6415
Epoch 2/8
16666/16666 [==============================] - 4s 256us/step - loss: 0.3713 - accuracy: 0.8577
Epoch 3/8
16666/16666 [==============================] - 4s 259us/step - loss: 0.2412 - accuracy: 0.9156
Epoch 4/8
16666/16666 [==============================] - 4s 256us/step - loss: 0.1674 - accuracy: 0.9449
Epoch 5/8
16666/16666 [==============================] - 4s 255us/step - loss: 0.1122 - accuracy: 0.9669
Epoch 6/8
16666/16666 [==============================] - 4s 256us/step - loss: 0.0734 - accuracy: 0.9801
Epoch 7/8
16666/16666 [==============================] - 4s 259us/step - loss: 0.0476 - accuracy: 0.9868
Epoch 8/8
16666/16666 [==============================] - 4s 255us/step - loss: 0.0300 - accuracy: 0.9921
8334/8334 [==============================] - 2s 221us/step
Epoch 1/8
16667/16667 [==============================] - 5s 300us/step - loss: 0.6515 - accuracy: 0.6179
Epoch 2/8
16667/16667 [==============================] - 4s 254us/step - loss: 0.3944 - accuracy: 0.8526
Epoch 3/8
16667/16667 [==============================] - 4s 254us/step - loss: 0.2542 - accuracy: 0.9096
Epoch 4/8
16667/16667 [==============================] - 4s 255us/step - loss: 0.1822 - accuracy: 0.9384
Epoch 5/8
16667/16667 [==============================] - 4s 256us/step - loss: 0.1251 - accuracy: 0.9605
Epoch 6/8
16667/16667 [==============================] - 4s 254us/step - loss: 0.0809 - accuracy: 0.9777
Epoch 7/8
16667/16667 [==============================] - 4s 255us/step - loss: 0.0549 - accuracy: 0.9843
Epoch 8/8
16667/16667 [==============================] - 4s 256us/step - loss: 0.0368 - accuracy: 0.9903
8333/8333 [==============================] - 2s 226us/step
Epoch 1/8
16667/16667 [==============================] - 5s 299us/step - loss: 0.6507 - accuracy: 0.6209
Epoch 2/8
16667/16667 [==============================] - 4s 257us/step - loss: 0.4038 - accuracy: 0.8462
Epoch 3/8
16667/16667 [==============================] - 4s 257us/step - loss: 0.2675 - accuracy: 0.9035
Epoch 4/8
16667/16667 [==============================] - 4s 257us/step - loss: 0.1914 - accuracy: 0.9333
Epoch 5/8
16667/16667 [==============================] - 4s 259us/step - loss: 0.1341 - accuracy: 0.9553
Epoch 6/8
16667/16667 [==============================] - 4s 259us/step - loss: 0.0898 - accuracy: 0.9726
Epoch 7/8
16667/16667 [==============================] - 4s 258us/step - loss: 0.0587 - accuracy: 0.9834
Epoch 8/8
16667/16667 [==============================] - 4s 257us/step - loss: 0.0423 - accuracy: 0.9884
8333/8333 [==============================] - 2s 225us/step
Epoch 1/8
16666/16666 [==============================] - 5s 319us/step - loss: 0.6323 - accuracy: 0.6334
Epoch 2/8
16666/16666 [==============================] - 5s 273us/step - loss: 0.3144 - accuracy: 0.8817
Epoch 3/8
16666/16666 [==============================] - 5s 273us/step - loss: 0.1594 - accuracy: 0.9515
Epoch 4/8
16666/16666 [==============================] - 5s 277us/step - loss: 0.0769 - accuracy: 0.9827
Epoch 5/8
16666/16666 [==============================] - 5s 274us/step - loss: 0.0409 - accuracy: 0.9926
Epoch 6/8
16666/16666 [==============================] - 5s 274us/step - loss: 0.0223 - accuracy: 0.9973
Epoch 7/8
16666/16666 [==============================] - 5s 277us/step - loss: 0.0138 - accuracy: 0.9981
Epoch 8/8
16666/16666 [==============================] - 5s 275us/step - loss: 0.0097 - accuracy: 0.9992
8334/8334 [==============================] - 2s 232us/step
Epoch 1/8
16667/16667 [==============================] - 5s 323us/step - loss: 0.6448 - accuracy: 0.6132
Epoch 2/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.3280 - accuracy: 0.8748
Epoch 3/8
16667/16667 [==============================] - 5s 276us/step - loss: 0.1675 - accuracy: 0.9470
Epoch 4/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0795 - accuracy: 0.9817
Epoch 5/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.0407 - accuracy: 0.9933
Epoch 6/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.0237 - accuracy: 0.9974
Epoch 7/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0145 - accuracy: 0.9986
Epoch 8/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0118 - accuracy: 0.9981
8333/8333 [==============================] - 2s 235us/step
Epoch 1/8
16667/16667 [==============================] - 5s 326us/step - loss: 0.6350 - accuracy: 0.6235
Epoch 2/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.3128 - accuracy: 0.8804
Epoch 3/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.1558 - accuracy: 0.9533
Epoch 4/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0813 - accuracy: 0.9793
Epoch 5/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.0409 - accuracy: 0.9930
Epoch 6/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0243 - accuracy: 0.9968
Epoch 7/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0146 - accuracy: 0.9989
Epoch 8/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0108 - accuracy: 0.9986
8333/8333 [==============================] - 2s 245us/step
Epoch 1/8
16666/16666 [==============================] - 5s 316us/step - loss: 0.6296 - accuracy: 0.6390
Epoch 2/8
16666/16666 [==============================] - 5s 271us/step - loss: 0.3452 - accuracy: 0.8647
Epoch 3/8
16666/16666 [==============================] - 5s 274us/step - loss: 0.2102 - accuracy: 0.9262
Epoch 4/8
16666/16666 [==============================] - 5s 271us/step - loss: 0.1305 - accuracy: 0.9564
Epoch 5/8
16666/16666 [==============================] - 5s 272us/step - loss: 0.0749 - accuracy: 0.9782
Epoch 6/8
16666/16666 [==============================] - 5s 273us/step - loss: 0.0446 - accuracy: 0.9882
Epoch 7/8
16666/16666 [==============================] - 5s 273us/step - loss: 0.0265 - accuracy: 0.9931
Epoch 8/8
16666/16666 [==============================] - 5s 271us/step - loss: 0.0169 - accuracy: 0.9954
8334/8334 [==============================] - 2s 242us/step
Epoch 1/8
16667/16667 [==============================] - 5s 316us/step - loss: 0.6268 - accuracy: 0.6420
Epoch 2/8
16667/16667 [==============================] - 5s 270us/step - loss: 0.3433 - accuracy: 0.8673
Epoch 3/8
16667/16667 [==============================] - 5s 272us/step - loss: 0.2172 - accuracy: 0.9180
Epoch 4/8
16667/16667 [==============================] - 5s 273us/step - loss: 0.1389 - accuracy: 0.9532
Epoch 5/8
16667/16667 [==============================] - 5s 271us/step - loss: 0.0854 - accuracy: 0.9746
Epoch 6/8
16667/16667 [==============================] - 5s 272us/step - loss: 0.0484 - accuracy: 0.9856
Epoch 7/8
16667/16667 [==============================] - 5s 273us/step - loss: 0.0315 - accuracy: 0.9912
Epoch 8/8
16667/16667 [==============================] - 5s 273us/step - loss: 0.0183 - accuracy: 0.9959
8333/8333 [==============================] - 2s 244us/step
Epoch 1/8
16667/16667 [==============================] - 5s 321us/step - loss: 0.6420 - accuracy: 0.6254
Epoch 2/8
16667/16667 [==============================] - 5s 276us/step - loss: 0.3561 - accuracy: 0.8631
Epoch 3/8
16667/16667 [==============================] - 5s 274us/step - loss: 0.2146 - accuracy: 0.9219
Epoch 4/8
16667/16667 [==============================] - 5s 275us/step - loss: 0.1360 - accuracy: 0.9539
Epoch 5/8
16667/16667 [==============================] - 5s 292us/step - loss: 0.0801 - accuracy: 0.9759
Epoch 6/8
16667/16667 [==============================] - 5s 284us/step - loss: 0.0477 - accuracy: 0.9861
Epoch 7/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.0293 - accuracy: 0.9924
Epoch 8/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.0175 - accuracy: 0.9954
8333/8333 [==============================] - 2s 250us/step
Epoch 1/8
16666/16666 [==============================] - 6s 334us/step - loss: 0.6248 - accuracy: 0.6365
Epoch 2/8
16666/16666 [==============================] - 5s 288us/step - loss: 0.2958 - accuracy: 0.8832
Epoch 3/8
16666/16666 [==============================] - 5s 284us/step - loss: 0.1399 - accuracy: 0.9585
Epoch 4/8
16666/16666 [==============================] - 5s 285us/step - loss: 0.0656 - accuracy: 0.9842
Epoch 5/8
16666/16666 [==============================] - 5s 287us/step - loss: 0.0338 - accuracy: 0.9932
Epoch 6/8
16666/16666 [==============================] - 5s 286us/step - loss: 0.0171 - accuracy: 0.9975
Epoch 7/8
16666/16666 [==============================] - 5s 286us/step - loss: 0.0126 - accuracy: 0.9983
Epoch 8/8
16666/16666 [==============================] - 5s 286us/step - loss: 0.0091 - accuracy: 0.9987
8334/8334 [==============================] - 2s 257us/step
Epoch 1/8
16667/16667 [==============================] - 5s 329us/step - loss: 0.6388 - accuracy: 0.6144
Epoch 2/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.3044 - accuracy: 0.8826
Epoch 3/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.1424 - accuracy: 0.9543
Epoch 4/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0623 - accuracy: 0.9857
Epoch 5/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0333 - accuracy: 0.9934
Epoch 6/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.0194 - accuracy: 0.9973
Epoch 7/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.0124 - accuracy: 0.9984
Epoch 8/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0085 - accuracy: 0.9993
8333/8333 [==============================] - 2s 257us/step
Epoch 1/8
16667/16667 [==============================] - 6s 332us/step - loss: 0.6356 - accuracy: 0.6180
Epoch 2/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.3029 - accuracy: 0.8842
Epoch 3/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.1374 - accuracy: 0.9578
Epoch 4/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.0648 - accuracy: 0.9845
Epoch 5/8
16667/16667 [==============================] - 5s 282us/step - loss: 0.0329 - accuracy: 0.9932
Epoch 6/8
16667/16667 [==============================] - 5s 284us/step - loss: 0.0181 - accuracy: 0.9976
Epoch 7/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.0127 - accuracy: 0.9978
Epoch 8/8
16667/16667 [==============================] - 5s 282us/step - loss: 0.0092 - accuracy: 0.9988
8333/8333 [==============================] - 2s 261us/step
Epoch 1/8
16666/16666 [==============================] - 5s 329us/step - loss: 0.6200 - accuracy: 0.6466
Epoch 2/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.3302 - accuracy: 0.8709
Epoch 3/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.1930 - accuracy: 0.9309
Epoch 4/8
16666/16666 [==============================] - 5s 283us/step - loss: 0.1152 - accuracy: 0.9620
Epoch 5/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.0660 - accuracy: 0.9798
Epoch 6/8
16666/16666 [==============================] - 5s 281us/step - loss: 0.0372 - accuracy: 0.9893
Epoch 7/8
16666/16666 [==============================] - 5s 282us/step - loss: 0.0228 - accuracy: 0.9941
Epoch 8/8
16666/16666 [==============================] - 5s 278us/step - loss: 0.0130 - accuracy: 0.9964
8334/8334 [==============================] - 2s 267us/step
Epoch 1/8
16667/16667 [==============================] - 6s 335us/step - loss: 0.6198 - accuracy: 0.6442
Epoch 2/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.3233 - accuracy: 0.8705
Epoch 3/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.1908 - accuracy: 0.9301
Epoch 4/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.1106 - accuracy: 0.9638
Epoch 5/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0661 - accuracy: 0.9794
Epoch 6/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0377 - accuracy: 0.9887
Epoch 7/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.0218 - accuracy: 0.9935
Epoch 8/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.0151 - accuracy: 0.9957
8333/8333 [==============================] - 2s 265us/step
Epoch 1/8
16667/16667 [==============================] - 6s 332us/step - loss: 0.6265 - accuracy: 0.6365
Epoch 2/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.3308 - accuracy: 0.8703
Epoch 3/8
16667/16667 [==============================] - 5s 277us/step - loss: 0.1979 - accuracy: 0.9272
Epoch 4/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.1163 - accuracy: 0.9611
Epoch 5/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.0672 - accuracy: 0.9785
Epoch 6/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0390 - accuracy: 0.9886
Epoch 7/8
16667/16667 [==============================] - 5s 278us/step - loss: 0.0222 - accuracy: 0.9935
Epoch 8/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.0157 - accuracy: 0.9955
8333/8333 [==============================] - 2s 273us/step
Epoch 1/8
16666/16666 [==============================] - 6s 343us/step - loss: 0.6138 - accuracy: 0.6472
Epoch 2/8
16666/16666 [==============================] - 5s 294us/step - loss: 0.2757 - accuracy: 0.8948
Epoch 3/8
16666/16666 [==============================] - 5s 286us/step - loss: 0.1214 - accuracy: 0.9629
Epoch 4/8
16666/16666 [==============================] - 5s 287us/step - loss: 0.0542 - accuracy: 0.9877
Epoch 5/8
16666/16666 [==============================] - 5s 290us/step - loss: 0.0281 - accuracy: 0.9942
Epoch 6/8
16666/16666 [==============================] - 5s 287us/step - loss: 0.0168 - accuracy: 0.9966
Epoch 7/8
16666/16666 [==============================] - 5s 288us/step - loss: 0.0117 - accuracy: 0.9981
Epoch 8/8
16666/16666 [==============================] - 5s 296us/step - loss: 0.0086 - accuracy: 0.9987
8334/8334 [==============================] - 2s 280us/step
Epoch 1/8
16667/16667 [==============================] - 6s 339us/step - loss: 0.6235 - accuracy: 0.6404
Epoch 2/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.2847 - accuracy: 0.8918
Epoch 3/8
16667/16667 [==============================] - 5s 286us/step - loss: 0.1276 - accuracy: 0.9582
Epoch 4/8
16667/16667 [==============================] - 5s 290us/step - loss: 0.0564 - accuracy: 0.9867
Epoch 5/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.0264 - accuracy: 0.9951
Epoch 6/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.0177 - accuracy: 0.9971
Epoch 7/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.0118 - accuracy: 0.9977
Epoch 8/8
16667/16667 [==============================] - 5s 288us/step - loss: 0.0079 - accuracy: 0.9989
8333/8333 [==============================] - 2s 283us/step
Epoch 1/8
16667/16667 [==============================] - 7s 405us/step - loss: 0.6108 - accuracy: 0.6491
Epoch 2/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.2778 - accuracy: 0.8949
Epoch 3/8
16667/16667 [==============================] - 5s 285us/step - loss: 0.1268 - accuracy: 0.9617
Epoch 4/8
16667/16667 [==============================] - 5s 284us/step - loss: 0.0562 - accuracy: 0.9855
Epoch 5/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.0301 - accuracy: 0.9935
Epoch 6/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.0185 - accuracy: 0.9962
Epoch 7/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.0117 - accuracy: 0.9980
Epoch 8/8
16667/16667 [==============================] - 5s 287us/step - loss: 0.0075 - accuracy: 0.9989
8333/8333 [==============================] - 2s 286us/step
Epoch 1/8
16666/16666 [==============================] - 6s 331us/step - loss: 0.6073 - accuracy: 0.6602
Epoch 2/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.3148 - accuracy: 0.8766
Epoch 3/8
16666/16666 [==============================] - 5s 280us/step - loss: 0.1848 - accuracy: 0.9327
Epoch 4/8
16666/16666 [==============================] - 5s 278us/step - loss: 0.1054 - accuracy: 0.9622
Epoch 5/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.0564 - accuracy: 0.9822
Epoch 6/8
16666/16666 [==============================] - 5s 281us/step - loss: 0.0347 - accuracy: 0.9894
Epoch 7/8
16666/16666 [==============================] - 5s 278us/step - loss: 0.0196 - accuracy: 0.9944
Epoch 8/8
16666/16666 [==============================] - 5s 279us/step - loss: 0.0144 - accuracy: 0.9955
8334/8334 [==============================] - 2s 288us/step
Epoch 1/8
16667/16667 [==============================] - 6s 332us/step - loss: 0.6186 - accuracy: 0.6452
Epoch 2/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.3122 - accuracy: 0.8742
Epoch 3/8
16667/16667 [==============================] - 5s 282us/step - loss: 0.1837 - accuracy: 0.9333
Epoch 4/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.1049 - accuracy: 0.9657
Epoch 5/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.0618 - accuracy: 0.9800
Epoch 6/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.0349 - accuracy: 0.9892
Epoch 7/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0202 - accuracy: 0.9940
Epoch 8/8
16667/16667 [==============================] - 5s 279us/step - loss: 0.0142 - accuracy: 0.9958
8333/8333 [==============================] - 2s 288us/step
Epoch 1/8
16667/16667 [==============================] - 6s 337us/step - loss: 0.6167 - accuracy: 0.6494
Epoch 2/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.3173 - accuracy: 0.8755
Epoch 3/8
16667/16667 [==============================] - 5s 282us/step - loss: 0.1879 - accuracy: 0.9315
Epoch 4/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.1064 - accuracy: 0.9632
Epoch 5/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0629 - accuracy: 0.9792
Epoch 6/8
16667/16667 [==============================] - 5s 281us/step - loss: 0.0345 - accuracy: 0.9900
Epoch 7/8
16667/16667 [==============================] - 5s 283us/step - loss: 0.0221 - accuracy: 0.9930
Epoch 8/8
16667/16667 [==============================] - 5s 280us/step - loss: 0.0148 - accuracy: 0.9957
8333/8333 [==============================] - 2s 286us/step
Epoch 1/8
16666/16666 [==============================] - 8s 500us/step - loss: 0.6058 - accuracy: 0.6573
Epoch 2/8
16666/16666 [==============================] - 7s 442us/step - loss: 0.2763 - accuracy: 0.8991
Epoch 3/8
16666/16666 [==============================] - 7s 449us/step - loss: 0.1254 - accuracy: 0.9648
Epoch 4/8
16666/16666 [==============================] - 7s 444us/step - loss: 0.0554 - accuracy: 0.9894
Epoch 5/8
16666/16666 [==============================] - 7s 448us/step - loss: 0.0292 - accuracy: 0.9963
Epoch 6/8
16666/16666 [==============================] - 7s 444us/step - loss: 0.0177 - accuracy: 0.9970
Epoch 7/8
16666/16666 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.99 - 7s 448us/step - loss: 0.0121 - accuracy: 0.9982
Epoch 8/8
16666/16666 [==============================] - 7s 444us/step - loss: 0.0094 - accuracy: 0.9983
8334/8334 [==============================] - 3s 315us/step
Epoch 1/8
16667/16667 [==============================] - 8s 504us/step - loss: 0.6274 - accuracy: 0.6327
Epoch 2/8
16667/16667 [==============================] - 8s 450us/step - loss: 0.2963 - accuracy: 0.8869
Epoch 3/8
16667/16667 [==============================] - 7s 448us/step - loss: 0.1378 - accuracy: 0.9607
Epoch 4/8
16667/16667 [==============================] - 8s 451us/step - loss: 0.0585 - accuracy: 0.9884
Epoch 5/8
16667/16667 [==============================] - 7s 446us/step - loss: 0.0295 - accuracy: 0.9951
Epoch 6/8
16667/16667 [==============================] - 8s 452us/step - loss: 0.0188 - accuracy: 0.9967
Epoch 7/8
16667/16667 [==============================] - 7s 448us/step - loss: 0.0135 - accuracy: 0.9980
Epoch 8/8
16667/16667 [==============================] - 8s 450us/step - loss: 0.0097 - accuracy: 0.9984
8333/8333 [==============================] - 3s 320us/step
Epoch 1/8
16667/16667 [==============================] - 9s 516us/step - loss: 0.6109 - accuracy: 0.6587
Epoch 2/8
16667/16667 [==============================] - 8s 455us/step - loss: 0.2844 - accuracy: 0.8939
Epoch 3/8
16667/16667 [==============================] - 8s 455us/step - loss: 0.1329 - accuracy: 0.9629
Epoch 4/8
16667/16667 [==============================] - 8s 450us/step - loss: 0.0597 - accuracy: 0.9875
Epoch 5/8
16667/16667 [==============================] - 8s 451us/step - loss: 0.0310 - accuracy: 0.9949
Epoch 6/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.0181 - accuracy: 0.9973
Epoch 7/8
16667/16667 [==============================] - 7s 450us/step - loss: 0.0134 - accuracy: 0.9984
Epoch 8/8
16667/16667 [==============================] - 8s 452us/step - loss: 0.0102 - accuracy: 0.9980
8333/8333 [==============================] - 3s 328us/step
Epoch 1/8
16666/16666 [==============================] - 8s 496us/step - loss: 0.6012 - accuracy: 0.6666
Epoch 2/8
16666/16666 [==============================] - 7s 430us/step - loss: 0.3120 - accuracy: 0.8807
Epoch 3/8
16666/16666 [==============================] - 7s 435us/step - loss: 0.1907 - accuracy: 0.9356
Epoch 4/8
16666/16666 [==============================] - 7s 429us/step - loss: 0.1087 - accuracy: 0.9657
Epoch 5/8
16666/16666 [==============================] - 7s 433us/step - loss: 0.0643 - accuracy: 0.9817
Epoch 6/8
16666/16666 [==============================] - 7s 427us/step - loss: 0.0353 - accuracy: 0.9912
Epoch 7/8
16666/16666 [==============================] - 7s 432us/step - loss: 0.0194 - accuracy: 0.9953
Epoch 8/8
16666/16666 [==============================] - 7s 428us/step - loss: 0.0130 - accuracy: 0.9963
8334/8334 [==============================] - 3s 332us/step
Epoch 1/8
16667/16667 [==============================] - 8s 492us/step - loss: 0.6244 - accuracy: 0.6494
Epoch 2/8
16667/16667 [==============================] - 7s 439us/step - loss: 0.3371 - accuracy: 0.8735
Epoch 3/8
16667/16667 [==============================] - 7s 436us/step - loss: 0.2086 - accuracy: 0.9293
Epoch 4/8
16667/16667 [==============================] - 7s 433us/step - loss: 0.1242 - accuracy: 0.9602
Epoch 5/8
16667/16667 [==============================] - 7s 438us/step - loss: 0.0683 - accuracy: 0.9806
Epoch 6/8
16667/16667 [==============================] - 7s 432us/step - loss: 0.0410 - accuracy: 0.9871
Epoch 7/8
16667/16667 [==============================] - 7s 437us/step - loss: 0.0220 - accuracy: 0.9944
Epoch 8/8
16667/16667 [==============================] - 7s 435us/step - loss: 0.0129 - accuracy: 0.9965
8333/8333 [==============================] - 3s 339us/step
Epoch 1/8
16667/16667 [==============================] - 8s 492us/step - loss: 0.6074 - accuracy: 0.6603
Epoch 2/8
16667/16667 [==============================] - 7s 437us/step - loss: 0.3102 - accuracy: 0.8809
Epoch 3/8
16667/16667 [==============================] - 7s 430us/step - loss: 0.1859 - accuracy: 0.9345
Epoch 4/8
16667/16667 [==============================] - 7s 433us/step - loss: 0.1044 - accuracy: 0.9666
Epoch 5/8
16667/16667 [==============================] - 7s 430us/step - loss: 0.0590 - accuracy: 0.9833
Epoch 6/8
16667/16667 [==============================] - 7s 434us/step - loss: 0.0320 - accuracy: 0.9916
Epoch 7/8
16667/16667 [==============================] - 7s 432us/step - loss: 0.0210 - accuracy: 0.9935
Epoch 8/8
16667/16667 [==============================] - 7s 431us/step - loss: 0.0137 - accuracy: 0.9960
8333/8333 [==============================] - 3s 345us/step
Epoch 1/8
16666/16666 [==============================] - 9s 536us/step - loss: 0.5684 - accuracy: 0.6866
Epoch 2/8
16666/16666 [==============================] - 8s 469us/step - loss: 0.2300 - accuracy: 0.9146
Epoch 3/8
16666/16666 [==============================] - 8s 475us/step - loss: 0.0835 - accuracy: 0.9782
Epoch 4/8
16666/16666 [==============================] - 8s 471us/step - loss: 0.0320 - accuracy: 0.9944
Epoch 5/8
16666/16666 [==============================] - 8s 479us/step - loss: 0.0162 - accuracy: 0.9974
Epoch 6/8
16666/16666 [==============================] - 8s 474us/step - loss: 0.0101 - accuracy: 0.9990
Epoch 7/8
16666/16666 [==============================] - 8s 473us/step - loss: 0.0064 - accuracy: 0.9993
Epoch 8/8
16666/16666 [==============================] - 8s 473us/step - loss: 0.0051 - accuracy: 0.9995
8334/8334 [==============================] - 3s 351us/step
Epoch 1/8
16667/16667 [==============================] - 9s 533us/step - loss: 0.5912 - accuracy: 0.6671
Epoch 2/8
16667/16667 [==============================] - 8s 477us/step - loss: 0.2460 - accuracy: 0.9060
Epoch 3/8
16667/16667 [==============================] - 8s 475us/step - loss: 0.0895 - accuracy: 0.9754
Epoch 4/8
16667/16667 [==============================] - 8s 475us/step - loss: 0.0349 - accuracy: 0.9933
Epoch 5/8
16667/16667 [==============================] - 8s 474us/step - loss: 0.0173 - accuracy: 0.9974
Epoch 6/8
16667/16667 [==============================] - 8s 477us/step - loss: 0.0095 - accuracy: 0.9990
Epoch 7/8
16667/16667 [==============================] - 8s 473us/step - loss: 0.0061 - accuracy: 0.9993
Epoch 8/8
16667/16667 [==============================] - 8s 477us/step - loss: 0.0048 - accuracy: 0.9998
8333/8333 [==============================] - 3s 352us/step
Epoch 1/8
16667/16667 [==============================] - 9s 538us/step - loss: 0.5835 - accuracy: 0.6762
Epoch 2/8
16667/16667 [==============================] - 8s 475us/step - loss: 0.2423 - accuracy: 0.9080
Epoch 3/8
16667/16667 [==============================] - 8s 477us/step - loss: 0.0942 - accuracy: 0.9737
Epoch 4/8
16667/16667 [==============================] - 8s 474us/step - loss: 0.0331 - accuracy: 0.9934
Epoch 5/8
16667/16667 [==============================] - 8s 476us/step - loss: 0.0179 - accuracy: 0.9973
Epoch 6/8
16667/16667 [==============================] - 8s 474us/step - loss: 0.0096 - accuracy: 0.9992
Epoch 7/8
16667/16667 [==============================] - 8s 477us/step - loss: 0.0070 - accuracy: 0.9993
Epoch 8/8
16667/16667 [==============================] - 8s 474us/step - loss: 0.0047 - accuracy: 0.9995
8333/8333 [==============================] - 3s 361us/step
Epoch 1/8
16666/16666 [==============================] - 8s 509us/step - loss: 0.5850 - accuracy: 0.6798
Epoch 2/8
16666/16666 [==============================] - 8s 451us/step - loss: 0.2792 - accuracy: 0.8916
Epoch 3/8
16666/16666 [==============================] - 7s 447us/step - loss: 0.1475 - accuracy: 0.9492
Epoch 4/8
16666/16666 [==============================] - 7s 447us/step - loss: 0.0753 - accuracy: 0.9776
Epoch 5/8
16666/16666 [==============================] - 7s 446us/step - loss: 0.0346 - accuracy: 0.9900
Epoch 6/8
16666/16666 [==============================] - 7s 448us/step - loss: 0.0175 - accuracy: 0.9951
Epoch 7/8
16666/16666 [==============================] - 7s 449us/step - loss: 0.0112 - accuracy: 0.9965
Epoch 8/8
16666/16666 [==============================] - 8s 455us/step - loss: 0.0070 - accuracy: 0.9979
8334/8334 [==============================] - 3s 365us/step
Epoch 1/8
16667/16667 [==============================] - 8s 507us/step - loss: 0.5825 - accuracy: 0.6814
Epoch 2/8
16667/16667 [==============================] - 7s 444us/step - loss: 0.2755 - accuracy: 0.89362s - loss:
Epoch 3/8
16667/16667 [==============================] - 7s 448us/step - loss: 0.1438 - accuracy: 0.9507
Epoch 4/8
16667/16667 [==============================] - 7s 446us/step - loss: 0.0746 - accuracy: 0.9775
Epoch 5/8
16667/16667 [==============================] - 7s 445us/step - loss: 0.0352 - accuracy: 0.9900
Epoch 6/8
16667/16667 [==============================] - 7s 447us/step - loss: 0.0179 - accuracy: 0.9957
Epoch 7/8
16667/16667 [==============================] - 7s 443us/step - loss: 0.0124 - accuracy: 0.9968
Epoch 8/8
16667/16667 [==============================] - 7s 447us/step - loss: 0.0064 - accuracy: 0.9980
8333/8333 [==============================] - 3s 372us/step
Epoch 1/8
16667/16667 [==============================] - 9s 514us/step - loss: 0.5917 - accuracy: 0.6720
Epoch 2/8
16667/16667 [==============================] - 7s 446us/step - loss: 0.2785 - accuracy: 0.8912
Epoch 3/8
16667/16667 [==============================] - 8s 452us/step - loss: 0.1507 - accuracy: 0.9470
Epoch 4/8
16667/16667 [==============================] - 7s 449us/step - loss: 0.0740 - accuracy: 0.9764
Epoch 5/8
16667/16667 [==============================] - 7s 449us/step - loss: 0.0374 - accuracy: 0.9890
Epoch 6/8
16667/16667 [==============================] - 7s 445us/step - loss: 0.0202 - accuracy: 0.9947
Epoch 7/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.0119 - accuracy: 0.9969
Epoch 8/8
16667/16667 [==============================] - 7s 449us/step - loss: 0.0082 - accuracy: 0.9974
8333/8333 [==============================] - 3s 367us/step
Epoch 1/8
16666/16666 [==============================] - 9s 541us/step - loss: 0.5758 - accuracy: 0.6705
Epoch 2/8
16666/16666 [==============================] - 8s 477us/step - loss: 0.2118 - accuracy: 0.9194
Epoch 3/8
16666/16666 [==============================] - 8s 475us/step - loss: 0.0713 - accuracy: 0.9810
Epoch 4/8
16666/16666 [==============================] - 8s 478us/step - loss: 0.0281 - accuracy: 0.9942
Epoch 5/8
16666/16666 [==============================] - 8s 475us/step - loss: 0.0142 - accuracy: 0.9980
Epoch 6/8
16666/16666 [==============================] - 8s 479us/step - loss: 0.0092 - accuracy: 0.9986
Epoch 7/8
16666/16666 [==============================] - 8s 476us/step - loss: 0.0074 - accuracy: 0.9986
Epoch 8/8
16666/16666 [==============================] - 8s 478us/step - loss: 0.0068 - accuracy: 0.9983
8334/8334 [==============================] - 3s 372us/step
Epoch 1/8
16667/16667 [==============================] - 9s 548us/step - loss: 0.5691 - accuracy: 0.6809
Epoch 2/8
16667/16667 [==============================] - 8s 478us/step - loss: 0.2240 - accuracy: 0.9158
Epoch 3/8
16667/16667 [==============================] - 8s 478us/step - loss: 0.0719 - accuracy: 0.9828
Epoch 4/8
16667/16667 [==============================] - 8s 478us/step - loss: 0.0289 - accuracy: 0.9945
Epoch 5/8
16667/16667 [==============================] - 8s 479us/step - loss: 0.0140 - accuracy: 0.9977
Epoch 6/8
16667/16667 [==============================] - 8s 478us/step - loss: 0.0096 - accuracy: 0.9978
Epoch 7/8
16667/16667 [==============================] - 8s 479us/step - loss: 0.0068 - accuracy: 0.9989
Epoch 8/8
16667/16667 [==============================] - 8s 479us/step - loss: 0.0066 - accuracy: 0.9987
8333/8333 [==============================] - 3s 381us/step
Epoch 1/8
16667/16667 [==============================] - 9s 553us/step - loss: 0.5724 - accuracy: 0.6787
Epoch 2/8
16667/16667 [==============================] - 8s 480us/step - loss: 0.2273 - accuracy: 0.9147
Epoch 3/8
16667/16667 [==============================] - 8s 483us/step - loss: 0.0736 - accuracy: 0.9792
Epoch 4/8
16667/16667 [==============================] - 8s 480us/step - loss: 0.0282 - accuracy: 0.9948
Epoch 5/8
16667/16667 [==============================] - 8s 483us/step - loss: 0.0145 - accuracy: 0.9972
Epoch 6/8
16667/16667 [==============================] - 8s 481us/step - loss: 0.0081 - accuracy: 0.9989
Epoch 7/8
16667/16667 [==============================] - 8s 485us/step - loss: 0.0069 - accuracy: 0.9989
Epoch 8/8
16667/16667 [==============================] - 8s 485us/step - loss: 0.0051 - accuracy: 0.9990
8333/8333 [==============================] - 3s 381us/step
Epoch 1/8
16666/16666 [==============================] - 9s 524us/step - loss: 0.5642 - accuracy: 0.6922
Epoch 2/8
16666/16666 [==============================] - 8s 460us/step - loss: 0.2602 - accuracy: 0.9004
Epoch 3/8
16666/16666 [==============================] - 8s 458us/step - loss: 0.1348 - accuracy: 0.9531
Epoch 4/8
16666/16666 [==============================] - 8s 460us/step - loss: 0.0632 - accuracy: 0.9785
Epoch 5/8
16666/16666 [==============================] - 8s 459us/step - loss: 0.0316 - accuracy: 0.9902
Epoch 6/8
16666/16666 [==============================] - 8s 461us/step - loss: 0.0170 - accuracy: 0.9945
Epoch 7/8
16666/16666 [==============================] - 8s 459us/step - loss: 0.0098 - accuracy: 0.9968
Epoch 8/8
16666/16666 [==============================] - 8s 469us/step - loss: 0.0064 - accuracy: 0.9979
8334/8334 [==============================] - 3s 384us/step
Epoch 1/8
16667/16667 [==============================] - 9s 534us/step - loss: 0.5819 - accuracy: 0.6756
Epoch 2/8
16667/16667 [==============================] - 8s 461us/step - loss: 0.2671 - accuracy: 0.8967
Epoch 3/8
16667/16667 [==============================] - 8s 464us/step - loss: 0.1341 - accuracy: 0.9536
Epoch 4/8
16667/16667 [==============================] - 8s 463us/step - loss: 0.0617 - accuracy: 0.9803
Epoch 5/8
16667/16667 [==============================] - 8s 467us/step - loss: 0.0295 - accuracy: 0.9911
Epoch 6/8
16667/16667 [==============================] - 8s 464us/step - loss: 0.0156 - accuracy: 0.9954
Epoch 7/8
16667/16667 [==============================] - 8s 466us/step - loss: 0.0105 - accuracy: 0.9963
Epoch 8/8
16667/16667 [==============================] - 8s 464us/step - loss: 0.0073 - accuracy: 0.9975
8333/8333 [==============================] - 3s 387us/step
Epoch 1/8
16667/16667 [==============================] - 9s 533us/step - loss: 0.5738 - accuracy: 0.6851
Epoch 2/8
16667/16667 [==============================] - 8s 465us/step - loss: 0.2629 - accuracy: 0.8964
Epoch 3/8
16667/16667 [==============================] - 8s 462us/step - loss: 0.1333 - accuracy: 0.9540
Epoch 4/8
16667/16667 [==============================] - 8s 466us/step - loss: 0.0629 - accuracy: 0.9809
Epoch 5/8
16667/16667 [==============================] - 8s 463us/step - loss: 0.0326 - accuracy: 0.9903
Epoch 6/8
16667/16667 [==============================] - 8s 465us/step - loss: 0.0159 - accuracy: 0.9956
Epoch 7/8
16667/16667 [==============================] - 8s 464us/step - loss: 0.0123 - accuracy: 0.9964
Epoch 8/8
16667/16667 [==============================] - 8s 466us/step - loss: 0.0087 - accuracy: 0.9974
8333/8333 [==============================] - 3s 390us/step
Epoch 1/8
16666/16666 [==============================] - 10s 577us/step - loss: 0.5526 - accuracy: 0.6982
Epoch 2/8
16666/16666 [==============================] - 8s 501us/step - loss: 0.2083 - accuracy: 0.9244
Epoch 3/8
16666/16666 [==============================] - 8s 499us/step - loss: 0.0627 - accuracy: 0.9837
Epoch 4/8
16666/16666 [==============================] - 8s 501us/step - loss: 0.0244 - accuracy: 0.9950
Epoch 5/8
16666/16666 [==============================] - 8s 499us/step - loss: 0.0119 - accuracy: 0.9982
Epoch 6/8
16666/16666 [==============================] - 8s 502us/step - loss: 0.0082 - accuracy: 0.9984
Epoch 7/8
16666/16666 [==============================] - 8s 499us/step - loss: 0.0074 - accuracy: 0.9981
Epoch 8/8
16666/16666 [==============================] - 8s 503us/step - loss: 0.0069 - accuracy: 0.9983
8334/8334 [==============================] - 3s 405us/step
Epoch 1/8
16667/16667 [==============================] - 10s 574us/step - loss: 0.5638 - accuracy: 0.6784
Epoch 2/8
16667/16667 [==============================] - 8s 496us/step - loss: 0.2172 - accuracy: 0.9189
Epoch 3/8
16667/16667 [==============================] - 8s 499us/step - loss: 0.0650 - accuracy: 0.9836
Epoch 4/8
16667/16667 [==============================] - 8s 496us/step - loss: 0.0251 - accuracy: 0.9939
Epoch 5/8
16667/16667 [==============================] - 8s 498us/step - loss: 0.0136 - accuracy: 0.9974
Epoch 6/8
16667/16667 [==============================] - 8s 498us/step - loss: 0.0092 - accuracy: 0.9981
Epoch 7/8
16667/16667 [==============================] - 8s 498us/step - loss: 0.0056 - accuracy: 0.9993
Epoch 8/8
16667/16667 [==============================] - 9s 525us/step - loss: 0.0049 - accuracy: 0.9991
8333/8333 [==============================] - 3s 417us/step
Epoch 1/8
16667/16667 [==============================] - 10s 588us/step - loss: 0.5625 - accuracy: 0.6816
Epoch 2/8
16667/16667 [==============================] - 9s 510us/step - loss: 0.2100 - accuracy: 0.9220
Epoch 3/8
16667/16667 [==============================] - 8s 501us/step - loss: 0.0662 - accuracy: 0.9813
Epoch 4/8
16667/16667 [==============================] - 8s 499us/step - loss: 0.0247 - accuracy: 0.9941
Epoch 5/8
16667/16667 [==============================] - 8s 502us/step - loss: 0.0136 - accuracy: 0.9975
Epoch 6/8
16667/16667 [==============================] - 8s 500us/step - loss: 0.0084 - accuracy: 0.9983
Epoch 7/8
16667/16667 [==============================] - 8s 505us/step - loss: 0.0068 - accuracy: 0.9985
Epoch 8/8
16667/16667 [==============================] - 8s 502us/step - loss: 0.0062 - accuracy: 0.9983
8333/8333 [==============================] - 4s 421us/step
Epoch 1/8
16666/16666 [==============================] - 9s 551us/step - loss: 0.5660 - accuracy: 0.6879
Epoch 2/8
16666/16666 [==============================] - 8s 472us/step - loss: 0.2515 - accuracy: 0.9020
Epoch 3/8
16666/16666 [==============================] - 8s 474us/step - loss: 0.1215 - accuracy: 0.9579
Epoch 4/8
16666/16666 [==============================] - 8s 473us/step - loss: 0.0568 - accuracy: 0.9812
Epoch 5/8
16666/16666 [==============================] - 8s 476us/step - loss: 0.0285 - accuracy: 0.9906
Epoch 6/8
16666/16666 [==============================] - 8s 474us/step - loss: 0.0160 - accuracy: 0.9949
Epoch 7/8
16666/16666 [==============================] - 8s 477us/step - loss: 0.0107 - accuracy: 0.9965
Epoch 8/8
16666/16666 [==============================] - 8s 472us/step - loss: 0.0097 - accuracy: 0.9966
8334/8334 [==============================] - 3s 419us/step
Epoch 1/8
16667/16667 [==============================] - 9s 551us/step - loss: 0.5684 - accuracy: 0.6906
Epoch 2/8
16667/16667 [==============================] - 8s 481us/step - loss: 0.2547 - accuracy: 0.8991
Epoch 3/8
16667/16667 [==============================] - 8s 476us/step - loss: 0.1245 - accuracy: 0.9570
Epoch 4/8
16667/16667 [==============================] - 9s 546us/step - loss: 0.0598 - accuracy: 0.9800
Epoch 5/8
16667/16667 [==============================] - 8s 478us/step - loss: 0.0278 - accuracy: 0.9909
Epoch 6/8
16667/16667 [==============================] - 8s 481us/step - loss: 0.0168 - accuracy: 0.9951
Epoch 7/8
16667/16667 [==============================] - 8s 480us/step - loss: 0.0116 - accuracy: 0.9963
Epoch 8/8
16667/16667 [==============================] - 8s 482us/step - loss: 0.0079 - accuracy: 0.9973
8333/8333 [==============================] - 4s 421us/step
Epoch 1/8
16667/16667 [==============================] - 9s 551us/step - loss: 0.5715 - accuracy: 0.6875
Epoch 2/8
16667/16667 [==============================] - 8s 480us/step - loss: 0.2560 - accuracy: 0.9005
Epoch 3/8
16667/16667 [==============================] - 8s 478us/step - loss: 0.1223 - accuracy: 0.9591
Epoch 4/8
16667/16667 [==============================] - 8s 482us/step - loss: 0.0576 - accuracy: 0.9809
Epoch 5/8
16667/16667 [==============================] - 8s 479us/step - loss: 0.0288 - accuracy: 0.9911
Epoch 6/8
16667/16667 [==============================] - 8s 483us/step - loss: 0.0168 - accuracy: 0.9942
Epoch 7/8
16667/16667 [==============================] - 8s 481us/step - loss: 0.0122 - accuracy: 0.9960
Epoch 8/8
16667/16667 [==============================] - 8s 482us/step - loss: 0.0073 - accuracy: 0.9977
8333/8333 [==============================] - 4s 422us/step
Epoch 1/8
16666/16666 [==============================] - 8s 486us/step - loss: 0.6388 - accuracy: 0.6244
Epoch 2/8
16666/16666 [==============================] - 7s 403us/step - loss: 0.3265 - accuracy: 0.8796
Epoch 3/8
16666/16666 [==============================] - 7s 407us/step - loss: 0.1674 - accuracy: 0.9529
Epoch 4/8
16666/16666 [==============================] - 7s 406us/step - loss: 0.0875 - accuracy: 0.9809
Epoch 5/8
16666/16666 [==============================] - 7s 405us/step - loss: 0.0453 - accuracy: 0.9941
Epoch 6/8
16666/16666 [==============================] - 7s 406us/step - loss: 0.0294 - accuracy: 0.9960
Epoch 7/8
16666/16666 [==============================] - 7s 403us/step - loss: 0.0184 - accuracy: 0.9982
Epoch 8/8
16666/16666 [==============================] - 7s 408us/step - loss: 0.0139 - accuracy: 0.9984
8334/8334 [==============================] - 3s 382us/step
Epoch 1/8
16667/16667 [==============================] - 8s 490us/step - loss: 0.6413 - accuracy: 0.6219
Epoch 2/8
16667/16667 [==============================] - 7s 432us/step - loss: 0.3278 - accuracy: 0.8787
Epoch 3/8
16667/16667 [==============================] - 7s 422us/step - loss: 0.1720 - accuracy: 0.9494
Epoch 4/8
16667/16667 [==============================] - 17s 1ms/step - loss: 0.0901 - accuracy: 0.9812
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0465 - accuracy: 0.9932
Epoch 6/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0301 - accuracy: 0.9962
Epoch 7/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0193 - accuracy: 0.9974
Epoch 8/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0153 - accuracy: 0.9982
8333/8333 [==============================] - 9s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 24s 1ms/step - loss: 0.6521 - accuracy: 0.6140
Epoch 2/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.3477 - accuracy: 0.8734
Epoch 3/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.1813 - accuracy: 0.9432
Epoch 4/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0981 - accuracy: 0.9777
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0502 - accuracy: 0.9923
Epoch 6/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0307 - accuracy: 0.9962
Epoch 7/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0213 - accuracy: 0.9976
Epoch 8/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0146 - accuracy: 0.9983
8333/8333 [==============================] - 9s 1ms/step
Epoch 1/8
16666/16666 [==============================] - 23s 1ms/step - loss: 0.6229 - accuracy: 0.6486
Epoch 2/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.3493 - accuracy: 0.8682
Epoch 3/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.2258 - accuracy: 0.9215
Epoch 4/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.1444 - accuracy: 0.9533
Epoch 5/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.0893 - accuracy: 0.9762
Epoch 6/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.0556 - accuracy: 0.9859
Epoch 7/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.0349 - accuracy: 0.9911
Epoch 8/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.0196 - accuracy: 0.9954
8334/8334 [==============================] - 9s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 23s 1ms/step - loss: 0.6427 - accuracy: 0.6335
Epoch 2/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.3782 - accuracy: 0.8579
Epoch 3/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.2377 - accuracy: 0.9154
Epoch 4/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.1624 - accuracy: 0.9467
Epoch 5/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.1014 - accuracy: 0.9716
Epoch 6/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0680 - accuracy: 0.9823
Epoch 7/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0398 - accuracy: 0.9901
Epoch 8/8
16667/16667 [==============================] - 19s 1ms/step - loss: 0.0233 - accuracy: 0.9941
8333/8333 [==============================] - 9s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 23s 1ms/step - loss: 0.6235 - accuracy: 0.6484
Epoch 2/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.3406 - accuracy: 0.8737
Epoch 3/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.2047 - accuracy: 0.9301
Epoch 4/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.1264 - accuracy: 0.9610
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0757 - accuracy: 0.9797
Epoch 6/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0437 - accuracy: 0.9894
Epoch 7/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0289 - accuracy: 0.9939
Epoch 8/8
16667/16667 [==============================] - 20s 1ms/step - loss: 0.0173 - accuracy: 0.9956
8333/8333 [==============================] - 9s 1ms/step
Epoch 1/8
16666/16666 [==============================] - 25s 1ms/step - loss: 0.6181 - accuracy: 0.6424
Epoch 2/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.2838 - accuracy: 0.8949
Epoch 3/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.1281 - accuracy: 0.9636
Epoch 4/8
16666/16666 [==============================] - 22s 1ms/step - loss: 0.0546 - accuracy: 0.9890
Epoch 5/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.0259 - accuracy: 0.9966
Epoch 6/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.0156 - accuracy: 0.9984
Epoch 7/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.0097 - accuracy: 0.9995
Epoch 8/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.0065 - accuracy: 0.9999
8334/8334 [==============================] - 10s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 24s 1ms/step - loss: 0.6312 - accuracy: 0.6245
Epoch 2/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.3005 - accuracy: 0.8886
Epoch 3/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.1356 - accuracy: 0.9613
Epoch 4/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0560 - accuracy: 0.9894
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0292 - accuracy: 0.9959
Epoch 6/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0169 - accuracy: 0.9981
Epoch 7/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0104 - accuracy: 0.9993
Epoch 8/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0076 - accuracy: 0.9995
8333/8333 [==============================] - 10s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 25s 1ms/step - loss: 0.6472 - accuracy: 0.6054
Epoch 2/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.3110 - accuracy: 0.8840
Epoch 3/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.1377 - accuracy: 0.9581
Epoch 4/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0592 - accuracy: 0.9885
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0286 - accuracy: 0.9962
Epoch 6/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0166 - accuracy: 0.9976
Epoch 7/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0113 - accuracy: 0.9987
Epoch 8/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0069 - accuracy: 0.9995
8333/8333 [==============================] - 10s 1ms/step
Epoch 1/8
16666/16666 [==============================] - 24s 1ms/step - loss: 0.6143 - accuracy: 0.6515
Epoch 2/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.3222 - accuracy: 0.8745
Epoch 3/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.1904 - accuracy: 0.9326
Epoch 4/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.1108 - accuracy: 0.9650
Epoch 5/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.0579 - accuracy: 0.9833
Epoch 6/8
16666/16666 [==============================] - 23s 1ms/step - loss: 0.0315 - accuracy: 0.9917
Epoch 7/8
16666/16666 [==============================] - 21s 1ms/step - loss: 0.0165 - accuracy: 0.9961
Epoch 8/8
16666/16666 [==============================] - 20s 1ms/step - loss: 0.0095 - accuracy: 0.9975
8334/8334 [==============================] - 10s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 24s 1ms/step - loss: 0.6244 - accuracy: 0.6461
Epoch 2/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.3295 - accuracy: 0.8742
Epoch 3/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.1951 - accuracy: 0.9308
Epoch 4/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.1107 - accuracy: 0.9652
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0616 - accuracy: 0.9825
Epoch 6/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0309 - accuracy: 0.9923
Epoch 7/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0170 - accuracy: 0.9959
Epoch 8/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0098 - accuracy: 0.9977
8333/8333 [==============================] - 10s 1ms/step
Epoch 1/8
16667/16667 [==============================] - 25s 1ms/step - loss: 0.6219 - accuracy: 0.6497
Epoch 2/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.3279 - accuracy: 0.8740
Epoch 3/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.1909 - accuracy: 0.9363
Epoch 4/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.1118 - accuracy: 0.9661
Epoch 5/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0571 - accuracy: 0.9852
Epoch 6/8
16667/16667 [==============================] - 22s 1ms/step - loss: 0.0318 - accuracy: 0.9917
Epoch 7/8
16667/16667 [==============================] - 21s 1ms/step - loss: 0.0165 - accuracy: 0.9962
Epoch 8/8
16667/16667 [==============================] - 22s 1ms/step - loss: 0.0104 - accuracy: 0.9977
8333/8333 [==============================] - 10s 1ms/step
Epoch 1/8
16666/16666 [==============================] - 10s 616us/step - loss: 0.6103 - accuracy: 0.6531
Epoch 2/8
16666/16666 [==============================] - 7s 433us/step - loss: 0.2779 - accuracy: 0.8902
Epoch 3/8
16666/16666 [==============================] - 7s 430us/step - loss: 0.1153 - accuracy: 0.9671
Epoch 4/8
16666/16666 [==============================] - 7s 432us/step - loss: 0.0455 - accuracy: 0.9902
Epoch 5/8
16666/16666 [==============================] - 7s 435us/step - loss: 0.0221 - accuracy: 0.9971
Epoch 6/8
16666/16666 [==============================] - 7s 431us/step - loss: 0.0120 - accuracy: 0.9989
Epoch 7/8
16666/16666 [==============================] - 7s 434us/step - loss: 0.0078 - accuracy: 0.9993
Epoch 8/8
16666/16666 [==============================] - 7s 431us/step - loss: 0.0053 - accuracy: 0.9997
8334/8334 [==============================] - 4s 446us/step
Epoch 1/8
16667/16667 [==============================] - 9s 523us/step - loss: 0.6229 - accuracy: 0.6360
Epoch 2/8
16667/16667 [==============================] - 7s 430us/step - loss: 0.2726 - accuracy: 0.8984
Epoch 3/8
16667/16667 [==============================] - 7s 432us/step - loss: 0.1130 - accuracy: 0.9677
Epoch 4/8
16667/16667 [==============================] - 7s 431us/step - loss: 0.0446 - accuracy: 0.9915
Epoch 5/8
16667/16667 [==============================] - 7s 431us/step - loss: 0.0227 - accuracy: 0.9960
Epoch 6/8
16667/16667 [==============================] - 7s 434us/step - loss: 0.0132 - accuracy: 0.9984
Epoch 7/8
16667/16667 [==============================] - 7s 431us/step - loss: 0.0083 - accuracy: 0.9992
Epoch 8/8
16667/16667 [==============================] - 7s 441us/step - loss: 0.0066 - accuracy: 0.9991
8333/8333 [==============================] - 4s 464us/step
Epoch 1/8
16667/16667 [==============================] - 9s 525us/step - loss: 0.6247 - accuracy: 0.6354
Epoch 2/8
16667/16667 [==============================] - 7s 434us/step - loss: 0.2815 - accuracy: 0.8934
Epoch 3/8
16667/16667 [==============================] - 7s 433us/step - loss: 0.1128 - accuracy: 0.9686
Epoch 4/8
16667/16667 [==============================] - 7s 432us/step - loss: 0.0446 - accuracy: 0.9908
Epoch 5/8
16667/16667 [==============================] - 7s 435us/step - loss: 0.0221 - accuracy: 0.9965
Epoch 6/8
16667/16667 [==============================] - 7s 433us/step - loss: 0.0131 - accuracy: 0.9983
Epoch 7/8
16667/16667 [==============================] - 7s 435us/step - loss: 0.0082 - accuracy: 0.9991
Epoch 8/8
16667/16667 [==============================] - 7s 433us/step - loss: 0.0050 - accuracy: 0.9997
8333/8333 [==============================] - 4s 453us/step
Epoch 1/8
16666/16666 [==============================] - 9s 518us/step - loss: 0.6144 - accuracy: 0.6497
Epoch 2/8
16666/16666 [==============================] - 7s 424us/step - loss: 0.3121 - accuracy: 0.8779
Epoch 3/8
16666/16666 [==============================] - 7s 424us/step - loss: 0.1748 - accuracy: 0.9368
Epoch 4/8
16666/16666 [==============================] - 7s 427us/step - loss: 0.0927 - accuracy: 0.9709
Epoch 5/8
16666/16666 [==============================] - 7s 425us/step - loss: 0.0466 - accuracy: 0.9869
Epoch 6/8
16666/16666 [==============================] - 7s 427us/step - loss: 0.0239 - accuracy: 0.9935
Epoch 7/8
16666/16666 [==============================] - 7s 420us/step - loss: 0.0133 - accuracy: 0.9962
Epoch 8/8
16666/16666 [==============================] - 7s 420us/step - loss: 0.0071 - accuracy: 0.9983
8334/8334 [==============================] - 4s 455us/step
Epoch 1/8
16667/16667 [==============================] - 9s 518us/step - loss: 0.5977 - accuracy: 0.6677
Epoch 2/8
16667/16667 [==============================] - 7s 418us/step - loss: 0.2992 - accuracy: 0.8827
Epoch 3/8
16667/16667 [==============================] - 7s 420us/step - loss: 0.1670 - accuracy: 0.9409
Epoch 4/8
16667/16667 [==============================] - 7s 420us/step - loss: 0.0891 - accuracy: 0.9742
Epoch 5/8
16667/16667 [==============================] - 7s 420us/step - loss: 0.0423 - accuracy: 0.9890
Epoch 6/8
16667/16667 [==============================] - 7s 417us/step - loss: 0.0228 - accuracy: 0.9935
Epoch 7/8
16667/16667 [==============================] - 7s 417us/step - loss: 0.0125 - accuracy: 0.9963
Epoch 8/8
16667/16667 [==============================] - 7s 422us/step - loss: 0.0073 - accuracy: 0.9984
8333/8333 [==============================] - 4s 453us/step
Epoch 1/8
16667/16667 [==============================] - 9s 513us/step - loss: 0.6004 - accuracy: 0.6659
Epoch 2/8
16667/16667 [==============================] - 7s 423us/step - loss: 0.2946 - accuracy: 0.8858
Epoch 3/8
16667/16667 [==============================] - 7s 423us/step - loss: 0.1584 - accuracy: 0.9451
Epoch 4/8
16667/16667 [==============================] - 7s 437us/step - loss: 0.0822 - accuracy: 0.9741
Epoch 5/8
16667/16667 [==============================] - 7s 432us/step - loss: 0.0395 - accuracy: 0.9888
Epoch 6/8
16667/16667 [==============================] - 7s 426us/step - loss: 0.0245 - accuracy: 0.9933
Epoch 7/8
16667/16667 [==============================] - 7s 426us/step - loss: 0.0132 - accuracy: 0.9965
Epoch 8/8
16667/16667 [==============================] - 7s 424us/step - loss: 0.0093 - accuracy: 0.9974
8333/8333 [==============================] - 4s 472us/step
Epoch 1/8
16666/16666 [==============================] - 9s 550us/step - loss: 0.6107 - accuracy: 0.6470
Epoch 2/8
16666/16666 [==============================] - 7s 444us/step - loss: 0.2645 - accuracy: 0.8991
Epoch 3/8
16666/16666 [==============================] - 7s 446us/step - loss: 0.0979 - accuracy: 0.9743
Epoch 4/8
16666/16666 [==============================] - 7s 444us/step - loss: 0.0373 - accuracy: 0.9931
Epoch 5/8
16666/16666 [==============================] - 7s 447us/step - loss: 0.0176 - accuracy: 0.9978
Epoch 6/8
16666/16666 [==============================] - 7s 445us/step - loss: 0.0098 - accuracy: 0.9990
Epoch 7/8
16666/16666 [==============================] - 7s 445us/step - loss: 0.0066 - accuracy: 0.9995
Epoch 8/8
16666/16666 [==============================] - 7s 446us/step - loss: 0.0044 - accuracy: 0.9998
8334/8334 [==============================] - 4s 480us/step
Epoch 1/8
16667/16667 [==============================] - 9s 550us/step - loss: 0.6179 - accuracy: 0.6450
Epoch 2/8
16667/16667 [==============================] - 8s 452us/step - loss: 0.2683 - accuracy: 0.8987
Epoch 3/8
16667/16667 [==============================] - 8s 451us/step - loss: 0.1065 - accuracy: 0.9687
Epoch 4/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.0412 - accuracy: 0.9908
Epoch 5/8
16667/16667 [==============================] - 7s 449us/step - loss: 0.0198 - accuracy: 0.9969
Epoch 6/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.0112 - accuracy: 0.9983
Epoch 7/8
16667/16667 [==============================] - 7s 449us/step - loss: 0.0063 - accuracy: 0.9997
Epoch 8/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.0051 - accuracy: 0.9995
8333/8333 [==============================] - 4s 476us/step
Epoch 1/8
16667/16667 [==============================] - 9s 557us/step - loss: 0.6153 - accuracy: 0.6477
Epoch 2/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.2613 - accuracy: 0.9028
Epoch 3/8
16667/16667 [==============================] - 8s 455us/step - loss: 0.0989 - accuracy: 0.9727
Epoch 4/8
16667/16667 [==============================] - 8s 451us/step - loss: 0.0391 - accuracy: 0.9919
Epoch 5/8
16667/16667 [==============================] - 8s 456us/step - loss: 0.0196 - accuracy: 0.9969
Epoch 6/8
16667/16667 [==============================] - 8s 451us/step - loss: 0.0109 - accuracy: 0.9978
Epoch 7/8
16667/16667 [==============================] - 8s 454us/step - loss: 0.0076 - accuracy: 0.9990
Epoch 8/8
16667/16667 [==============================] - 8s 453us/step - loss: 0.0049 - accuracy: 0.9995
8333/8333 [==============================] - 4s 494us/step
Epoch 1/8
16666/16666 [==============================] - 9s 539us/step - loss: 0.6020 - accuracy: 0.6637
Epoch 2/8
16666/16666 [==============================] - 7s 438us/step - loss: 0.2927 - accuracy: 0.8832
Epoch 3/8
16666/16666 [==============================] - 7s 441us/step - loss: 0.1599 - accuracy: 0.9431
Epoch 4/8
16666/16666 [==============================] - 7s 436us/step - loss: 0.0763 - accuracy: 0.9776
Epoch 5/8
16666/16666 [==============================] - 7s 439us/step - loss: 0.0384 - accuracy: 0.9898
Epoch 6/8
16666/16666 [==============================] - 7s 440us/step - loss: 0.0207 - accuracy: 0.9933
Epoch 7/8
16666/16666 [==============================] - 7s 436us/step - loss: 0.0108 - accuracy: 0.9971
Epoch 8/8
16666/16666 [==============================] - 7s 440us/step - loss: 0.0061 - accuracy: 0.9980
8334/8334 [==============================] - 4s 493us/step
Epoch 1/8
16667/16667 [==============================] - 9s 544us/step - loss: 0.6138 - accuracy: 0.6482
Epoch 2/8
16667/16667 [==============================] - 7s 443us/step - loss: 0.3042 - accuracy: 0.8798
Epoch 3/8
16667/16667 [==============================] - 7s 443us/step - loss: 0.1575 - accuracy: 0.9435
Epoch 4/8
16667/16667 [==============================] - 7s 443us/step - loss: 0.0758 - accuracy: 0.9762
Epoch 5/8
16667/16667 [==============================] - 7s 442us/step - loss: 0.0380 - accuracy: 0.9888
Epoch 6/8
16667/16667 [==============================] - 7s 443us/step - loss: 0.0166 - accuracy: 0.9959
Epoch 7/8
16667/16667 [==============================] - 7s 441us/step - loss: 0.0116 - accuracy: 0.9965
Epoch 8/8
16667/16667 [==============================] - 7s 440us/step - loss: 0.0068 - accuracy: 0.9982
8333/8333 [==============================] - 4s 492us/step
Epoch 1/8
16667/16667 [==============================] - 9s 560us/step - loss: 0.6137 - accuracy: 0.6545
Epoch 2/8
16667/16667 [==============================] - 7s 442us/step - loss: 0.2999 - accuracy: 0.8819
Epoch 3/8
16667/16667 [==============================] - 7s 446us/step - loss: 0.1608 - accuracy: 0.9426
Epoch 4/8
16667/16667 [==============================] - 7s 440us/step - loss: 0.0806 - accuracy: 0.9746
Epoch 5/8
16667/16667 [==============================] - 7s 444us/step - loss: 0.0383 - accuracy: 0.9881
Epoch 6/8
16667/16667 [==============================] - 7s 442us/step - loss: 0.0216 - accuracy: 0.9935
Epoch 7/8
16667/16667 [==============================] - 7s 445us/step - loss: 0.0116 - accuracy: 0.9965
Epoch 8/8
16667/16667 [==============================] - 7s 443us/step - loss: 0.0082 - accuracy: 0.9975
8333/8333 [==============================] - 4s 491us/step
Epoch 1/8
25000/25000 [==============================] - 8s 308us/step - loss: 0.6242 - accuracy: 0.6412
Epoch 2/8
25000/25000 [==============================] - 6s 238us/step - loss: 0.3266 - accuracy: 0.87365s - l - ETA: 4s - loss: 0.3
Epoch 3/8
25000/25000 [==============================] - 6s 239us/step - loss: 0.2094 - accuracy: 0.9276TA: 3s - loss: 0.2148 - accura - ETA: 3s - loss: 0.2137 - accuracy: 0.92 - ETA: 3s - loss: 0.2148  - ETA - ETA: 1s - loss: 0.2116 - accuracy - ETA: 1s - loss: 0.2121 - ac - ETA: 0s -
Epoch 4/8
25000/25000 [==============================] - 6s 239us/step - loss: 0.1377 - accuracy: 0.95713s - loss: 0.138 - ETA: 3s - ETA: 2s -
Epoch 5/8
25000/25000 [==============================] - 6s 230us/step - loss: 0.0894 - accuracy: 0.9742
Epoch 6/8
25000/25000 [==============================] - 6s 234us/step - loss: 0.0638 - accuracy: 0.98303s - loss: 0.0655 - accuracy: 0.98 - ETA: 3s - loss: 0.065
Epoch 7/8
25000/25000 [==============================] - 6s 236us/step - loss: 0.0432 - accuracy: 0.9895
Epoch 8/8
25000/25000 [==============================] - 6s 234us/step - loss: 0.0345 - accuracy: 0.9904
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print best hyperparameter based on above run</span>
<span class="n">best_parameters</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_parameters</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;EMBEDDING_DIM&#39;: 30, &#39;batch_size&#39;: 125, &#39;neurons&#39;: 5, &#39;optimizer&#39;: &#39;adam&#39;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print best accuracy</span>
<span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.87368
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Final-model">Final model<a class="anchor-link" href="#Final-model">&#182;</a></h2><p>This model is bulit after getting optimal hparameter from grid search</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Model buliding</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span> <span class="c1">#Sequential model</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">))</span>  <span class="c1">#Init embedding layer with no pretrained wts</span>
<span class="c1">#embedding layer takes input of vocabulary size i.e 10000, embedding dimension i.e 50 and input sequence i.e number of columns of dataset i.e 300</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span> <span class="c1">#Use flatten layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span> <span class="c1">#use dropout for regularization</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="c1">#Hidden layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span> <span class="c1">#use dropout for regularization</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span> <span class="c1">#Output layer</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what our model have, number of layer , output shape ,etc</span>
<span class="c1">#model summary</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_3&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 300, 30)           300000    
_________________________________________________________________
flatten_3 (Flatten)          (None, 9000)              0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 9000)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 5)                 45005     
_________________________________________________________________
dropout_6 (Dropout)          (None, 5)                 0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 6         
=================================================================
Total params: 345,011
Trainable params: 345,011
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check step to see shape of input to our model</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[66]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(25000, 300)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Define early stop and reduced lr</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span>
<span class="n">reduce_lr</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Fitting model to xtrain and ytrain with defined epochs and batch size</span>
<span class="c1">#Here I have used requlaization and model performance tech such as reduced lr and early stop</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
  <span class="n">X_train</span><span class="p">,</span>
  <span class="n">y_train</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="mi">125</span><span class="p">,</span>
  <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
 <span class="c1"># callbacks=[reduce_lr, stop],</span>
  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 4s 160us/step - loss: 0.6175 - accuracy: 0.6468 - val_loss: 0.4197 - val_accuracy: 0.8282
Epoch 2/10
25000/25000 [==============================] - 4s 153us/step - loss: 0.3155 - accuracy: 0.8812 - val_loss: 0.3153 - val_accuracy: 0.8675
Epoch 3/10
25000/25000 [==============================] - 4s 161us/step - loss: 0.2062 - accuracy: 0.9272 - val_loss: 0.3119 - val_accuracy: 0.8716
Epoch 4/10
25000/25000 [==============================] - 4s 155us/step - loss: 0.1387 - accuracy: 0.9565 - val_loss: 0.3361 - val_accuracy: 0.8670
Epoch 5/10
25000/25000 [==============================] - 4s 156us/step - loss: 0.0941 - accuracy: 0.9727 - val_loss: 0.3674 - val_accuracy: 0.8657
Epoch 6/10
25000/25000 [==============================] - 4s 158us/step - loss: 0.0629 - accuracy: 0.9826 - val_loss: 0.4043 - val_accuracy: 0.8644
Epoch 7/10
25000/25000 [==============================] - 4s 156us/step - loss: 0.0460 - accuracy: 0.9880 - val_loss: 0.4493 - val_accuracy: 0.8597
Epoch 8/10
25000/25000 [==============================] - 4s 153us/step - loss: 0.0383 - accuracy: 0.9894 - val_loss: 0.4808 - val_accuracy: 0.8620
Epoch 9/10
25000/25000 [==============================] - 4s 153us/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.5205 - val_accuracy: 0.8589
Epoch 10/10
25000/25000 [==============================] - 4s 153us/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.5578 - val_accuracy: 0.8586
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate test set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 1s 30us/step
Test accuracy:  0.8585600256919861
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate train set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 1s 30us/step
Test accuracy:  0.9999200105667114
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Getting prediction of test set and train set</span>
<span class="n">prediction_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">prediction_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print prediction</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[0.00270584]
 [1.        ]
 [0.9998786 ]
 ...
 [0.00501606]
 [0.41706505]
 [0.5904646 ]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Set threshold</span>
<span class="c1">#we want the value to be either 0 or 1</span>
<span class="n">pred</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">25000</span><span class="p">,))</span>
<span class="n">count</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prediction_test</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>  <span class="c1">#Got .5 after many hit and try</span>
        <span class="n">pred</span><span class="p">[</span><span class="n">count</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pred</span><span class="p">[</span><span class="n">count</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
    
    <span class="n">count</span><span class="o">+=</span><span class="mi">1</span>

<span class="c1">#Threshold is 0.5</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print value after threshold</span>
<span class="n">pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[74]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0., 1., 1., ..., 0., 0., 1.])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print accuracy score, f1 score, precision, recall and classification report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1 score : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;precision score : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recall score : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>accuracy : 0.8586
F1 score : 0.8548
precision score : 0.8784
recall score : 0.8324
              precision    recall  f1-score   support

           0       0.84      0.88      0.86     12500
           1       0.88      0.83      0.85     12500

    accuracy                           0.86     25000
   macro avg       0.86      0.86      0.86     25000
weighted avg       0.86      0.86      0.86     25000

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Plotting-model-performance">Plotting model performance<a class="anchor-link" href="#Plotting-model-performance">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what out model stores info so that these can be plotted</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;val_loss&#39;: [0.41967814072966575, 0.31534422516822813, 0.31188236258924007, 0.3360690650343895, 0.3673982647806406, 0.40433042369782923, 0.44931577399373057, 0.4807850980758667, 0.5205187710374594, 0.5577785823494196], &#39;val_accuracy&#39;: [0.8281999826431274, 0.8674799799919128, 0.8715599775314331, 0.8670399785041809, 0.8656799793243408, 0.8644400238990784, 0.8596799969673157, 0.8620399832725525, 0.8589199781417847, 0.8585600256919861], &#39;loss&#39;: [0.6174829252064228, 0.3154584526270628, 0.20619698014110327, 0.1386769899353385, 0.09410732259973884, 0.0628730616811663, 0.04597682327032089, 0.03829919936135411, 0.027760785922873767, 0.022568860789760947], &#39;accuracy&#39;: [0.6468, 0.88124, 0.9272, 0.95652, 0.97268, 0.98264, 0.988, 0.98936, 0.99252, 0.99392]}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># plot model loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#plot model accuracies</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="AUC">AUC<a class="anchor-link" href="#AUC">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print AUC for train set</span>
<span class="n">aucs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">prediction_train</span><span class="p">)</span>
    <span class="n">aucs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">aucs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.9999995520000001
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print AUC for test set</span>
<span class="n">aucs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction_test</span><span class="p">)</span>
    <span class="n">aucs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">aucs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.9339280992
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Some-predictions">Some predictions<a class="anchor-link" href="#Some-predictions">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Init value for that prediction</span>
<span class="n">n</span><span class="o">=</span><span class="mi">4</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_test shape = &quot;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#To see shape of X_test</span>

<span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>  <span class="c1">#Put test value in x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x = &quot;</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#AS you can see it is out of shape when comared to x_test because it is a single value therefore we need to reshape it</span>

<span class="n">x2</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">SEQ_LEN</span><span class="p">)</span> <span class="c1">#Reshape to (1,300) so to put in our model if not done this step it will throw error as our model accept this shape only</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New Shape of x = &quot;</span><span class="p">,</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#Cross check step to see our new shape</span>

<span class="n">P</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> <span class="c1">#predict x based on our model</span>

<span class="n">P2</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">P</span><span class="o">&gt;</span><span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1">#Setting threshold if value less than 0.5 it is -ve review otherwise poistive</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted review = &quot;</span><span class="p">,</span><span class="n">P2</span><span class="p">)</span> <span class="c1">#predicted review</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Actual value = &quot;</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X_test shape =  (25000, 300)
Shape of x =  (300,)
New Shape of x =  (1, 300)


Predicted review =  1
Actual value =  1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#This returns the decoded value by using above decoded function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; like some other people wrote i&#39;m a die hard mario fan and i loved this game br br this game starts slightly boring but trust me it&#39;s worth it as soon as you start your hooked the levels are fun and &lt;UNK&gt; they will hook you &lt;UNK&gt; your mind turns to &lt;UNK&gt; i&#39;m not kidding this game is also &lt;UNK&gt; and is beautifully done br br to keep this spoiler free i have to keep my mouth shut about details but please try this game it&#39;ll be worth it br br story 9 9 action 10 1 it&#39;s that good &lt;UNK&gt; 10 attention &lt;UNK&gt; 10 average 10 &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;
</pre>
</div>
</div>

</div>
</div>

</div>Note:
The model is better in performance but again it tends to overfit. Lets use LSTM for this task and see what is the performance of that.
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM-WOTHOUT-PRE-TRAINED-WTS">LSTM WOTHOUT PRE-TRAINED WTS<a class="anchor-link" href="#LSTM-WOTHOUT-PRE-TRAINED-WTS">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Model buliding</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>  <span class="c1">#Sequential model</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">))</span> <span class="c1">#Init embedding layer with no pretrained wts</span>
<span class="c1">#embedding layer takes input of vocabulary size i.e 10000, embedding dimension i.e 50 and input sequence i.e number of columns of dataset i.e 300</span>
<span class="c1">#Here I am not using pretrained glove vector</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span> <span class="c1">#use dropout for regularization</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>  <span class="c1">#Hidden layer with dropout Here return_sequences=true as I want to get output from all layer than apply global max pool over all the output so that I dont miss out important info</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalMaxPool1D</span><span class="p">())</span> <span class="c1">#This is to get values from all states and not missing important info</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">))</span> <span class="c1">#Final dense layer </span>

<span class="c1">#Note:GlobalMaxPool1D requires output from all lSTMs therfore reurn_sequences = True, this returns output from all LSTM not just final LSTM </span>
<span class="c1">#ALso GlobalMaxPool1D takes max of all output in very special way this step is done so that every words wether at start or at he end is given importance. </span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what our model have, number of layer , output shape ,etc</span>
<span class="c1">#model summary</span>
<span class="n">model2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_4&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (None, 300, 50)           500000    
_________________________________________________________________
dropout_7 (Dropout)          (None, 300, 50)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 300, 100)          60400     
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 101       
=================================================================
Total params: 560,501
Trainable params: 560,501
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy</span>
<span class="n">model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
  <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Fitting model to xtrain and ytrain with defined epochs and batch size</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
  <span class="n">X_train</span><span class="p">,</span>
  <span class="n">y_train</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
  <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 102s 4ms/step - loss: 0.6099 - accuracy: 0.6868 - val_loss: 0.3755 - val_accuracy: 0.8482
Epoch 2/10
25000/25000 [==============================] - 101s 4ms/step - loss: 0.3049 - accuracy: 0.8752 - val_loss: 0.3984 - val_accuracy: 0.8370
Epoch 3/10
25000/25000 [==============================] - 103s 4ms/step - loss: 0.2254 - accuracy: 0.9136 - val_loss: 0.3031 - val_accuracy: 0.8720
Epoch 4/10
25000/25000 [==============================] - 102s 4ms/step - loss: 0.1829 - accuracy: 0.9315 - val_loss: 0.3496 - val_accuracy: 0.8636
Epoch 5/10
25000/25000 [==============================] - 102s 4ms/step - loss: 0.1544 - accuracy: 0.9450 - val_loss: 0.3445 - val_accuracy: 0.8596
Epoch 6/10
25000/25000 [==============================] - 103s 4ms/step - loss: 0.1336 - accuracy: 0.9532 - val_loss: 0.3732 - val_accuracy: 0.8585
Epoch 7/10
25000/25000 [==============================] - 103s 4ms/step - loss: 0.1171 - accuracy: 0.9600 - val_loss: 0.3746 - val_accuracy: 0.8587
Epoch 8/10
25000/25000 [==============================] - 122s 5ms/step - loss: 0.1010 - accuracy: 0.9658 - val_loss: 0.4519 - val_accuracy: 0.8568
Epoch 9/10
25000/25000 [==============================] - 110s 4ms/step - loss: 0.0853 - accuracy: 0.9704 - val_loss: 0.4761 - val_accuracy: 0.8561
Epoch 10/10
25000/25000 [==============================] - 103s 4ms/step - loss: 0.0750 - accuracy: 0.9752 - val_loss: 0.4876 - val_accuracy: 0.8523
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate test set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 31s 1ms/step
Test accuracy:  0.8523200154304504
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate train set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 35s 1ms/step
Test accuracy:  0.9905200004577637
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NOTE:">NOTE:<a class="anchor-link" href="#NOTE:">&#182;</a></h4><p>This LSTM without pretrained wts is also overfitting and results are also not that good lets use LSTM with glove vector.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM-WITH-PRE-TRAINED-GLOVE-VECTOR">LSTM WITH PRE-TRAINED GLOVE VECTOR<a class="anchor-link" href="#LSTM-WITH-PRE-TRAINED-GLOVE-VECTOR">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Load-glove-vector">Load glove vector<a class="anchor-link" href="#Load-glove-vector">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#load Pretrained glove vector from file</span>
<span class="c1">#Note the pretrained are of 100 dim long as I am using it from &#39;glove.6B.100d. This embed each word with 100 dimensions</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading word vectors...&#39;</span><span class="p">)</span>
<span class="n">word2vec</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1">#This dict contain all wrod to vec of golve model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">glove.6B.100d.txt&#39;</span><span class="p">),</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1">#import data from file</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> 
        <span class="n">word2</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1">#Store value in the variable</span>
        <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="c1">#store vector of that word to different variable</span>
        <span class="n">word2vec</span><span class="p">[</span><span class="n">word2</span><span class="p">]</span> <span class="o">=</span> <span class="n">vec</span>
        <span class="c1">#print(values)</span>
        
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Found </span><span class="si">%s</span><span class="s1"> word vectors.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2vec</span><span class="p">))</span> <span class="c1">#print lenth of the dict that stored value</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading word vectors...
Found 400000 word vectors.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#this is that embedding from word2vec that are in word2idx in our dataset</span>
<span class="c1">#This steps store only those vectors that are there in our dictionary word2idx</span>
<span class="c1">#Only those word&#39;s vectors that are there in our vocabulary</span>
<span class="n">EMBEDDING_DIM</span><span class="o">=</span><span class="mi">100</span> <span class="c1">#As we are using GLOVE 100</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Filling pre-trained embeddings...&#39;</span><span class="p">)</span>
<span class="n">num_words</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2idx</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1">#Set threshold</span>
<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_words</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">))</span> <span class="c1">#init array to store embedding</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word2idx</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">MAX_VOCAB</span><span class="p">:</span>
        <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="c1">#Get pretrained glove vector from word2vec that are there in our vocalbulary and stroe in some other variable one by one</span>
        <span class="c1">#print(embedding_vector)</span>
        <span class="k">if</span> <span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># words not found in embedding index will be all zeros.</span>
            <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
        
<span class="c1">#Note the embedding_matrix is nothing but the pretrained glove vector from file &#39;glove.6B.100d.txt&#39; but has only those words that are there in our dictionary</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Filling pre-trained embeddings...
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#cross check step</span>
<span class="c1">#To see if everthing is done properly</span>

<span class="nb">print</span><span class="p">(</span><span class="n">num_words</span><span class="p">)</span> <span class="c1">#To see threshold </span>

<span class="nb">print</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#AS you can see the output of embedding_matrix which is 10000 in length and 50 in dim</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>10000
(10000, 100)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Cross check to see a dummy value</span>
<span class="n">embedding_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[64]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-Building-LSTM">Model Building LSTM<a class="anchor-link" href="#Model-Building-LSTM">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Model buliding</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>  <span class="c1">#Sequential model</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_VOCAB</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="c1">#Init embedding layer with no pretrained wts</span>
<span class="c1">#embedding layer takes input of vocabulary size i.e 10000, embedding dimension i.e 50 and input sequence i.e number of columns of dataset i.e 300</span>
<span class="c1">#Here I am using pretrained glove vector stored in variable </span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span> <span class="c1">#use dropout for regularization embedding_matrix</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.4</span><span class="p">))</span>  <span class="c1">#Hidden layer with dropout Here return_sequences=true as I want to get output from all layer than apply global max pool over all the output so that I dont miss out important info</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalMaxPool1D</span><span class="p">())</span> <span class="c1">#This is to get values from all states and not missing important info</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">))</span> <span class="c1">#Final dense layer </span>
<span class="c1">#Note:GlobalMaxPool1D requires output from all lSTMs therfore reurn_sequences = True, this returns output from all LSTM not just final LSTM </span>
<span class="c1">#ALso GlobalMaxPool1D takes max of all output in very special way this step is done so that every words wether at start or at he end is given importance. </span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what our model have, number of layer , output shape ,etc</span>
<span class="c1">#model summary</span>
<span class="n">model2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_5&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_5 (Embedding)      (None, 300, 100)          1000000   
_________________________________________________________________
dropout_7 (Dropout)          (None, 300, 100)          0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 300, 100)          80400     
_________________________________________________________________
global_max_pooling1d_3 (Glob (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 101       
=================================================================
Total params: 1,080,501
Trainable params: 1,080,501
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy</span>
<span class="n">model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
  <span class="c1">#optimizer=Adam(lr=0.01),  #best</span>
  <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Define checkpoint, early stop and reduced lr</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span>
<span class="n">reduce_lr</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Fitting model to xtrain and ytrain with defined epochs and batch size</span>
<span class="c1">#Here I have used requlaization and model performance tech such as reduced lr, check point and early stop</span>
<span class="n">EPOCHS</span><span class="o">=</span><span class="mi">10</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
  <span class="n">X_train</span><span class="p">,</span>
  <span class="n">y_train</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
  <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span>
  <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">reduce_lr</span><span class="p">,</span> <span class="n">stop</span><span class="p">],</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 173s 7ms/step - loss: 0.6027 - acc: 0.6603 - val_loss: 0.4449 - val_acc: 0.7908
Epoch 2/10
25000/25000 [==============================] - 175s 7ms/step - loss: 0.4264 - acc: 0.8055 - val_loss: 0.3397 - val_acc: 0.8537
Epoch 3/10
25000/25000 [==============================] - 174s 7ms/step - loss: 0.3593 - acc: 0.8464 - val_loss: 0.3648 - val_acc: 0.8523
Epoch 4/10
25000/25000 [==============================] - 174s 7ms/step - loss: 0.3220 - acc: 0.8634 - val_loss: 0.3266 - val_acc: 0.8714
Epoch 5/10
25000/25000 [==============================] - 175s 7ms/step - loss: 0.2985 - acc: 0.8749 - val_loss: 0.2887 - val_acc: 0.8834
Epoch 6/10
25000/25000 [==============================] - 175s 7ms/step - loss: 0.2777 - acc: 0.8850 - val_loss: 0.2818 - val_acc: 0.8842
Epoch 7/10
25000/25000 [==============================] - 176s 7ms/step - loss: 0.2590 - acc: 0.8927 - val_loss: 0.2766 - val_acc: 0.8894
Epoch 8/10
25000/25000 [==============================] - 175s 7ms/step - loss: 0.2435 - acc: 0.9019 - val_loss: 0.2689 - val_acc: 0.8927
Epoch 9/10
25000/25000 [==============================] - 176s 7ms/step - loss: 0.2343 - acc: 0.9030 - val_loss: 0.2709 - val_acc: 0.8946
Epoch 10/10
25000/25000 [==============================] - 175s 7ms/step - loss: 0.2229 - acc: 0.9114 - val_loss: 0.2657 - val_acc: 0.8956
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate test set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 36s 1ms/step
Test accuracy:  0.8956400156021118
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Evaluate train set and then print accuracy</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: &#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>25000/25000 [==============================] - 36s 1ms/step
Test accuracy:  0.9401999711990356
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Getting prediction of test set and train set</span>
<span class="n">prediction_train2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">prediction_test2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print prediction</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction_test2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[0.01150385]
 [0.9953797 ]
 [0.9725683 ]
 ...
 [0.0026525 ]
 [0.03272676]
 [0.15806133]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Set threshold</span>
<span class="c1">#we want the value to be either 0 or 1</span>
<span class="n">pred2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">25000</span><span class="p">,))</span>
<span class="n">count</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prediction_test2</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>  <span class="c1">#Got .5 after many hit and try</span>
        <span class="n">pred2</span><span class="p">[</span><span class="n">count</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pred2</span><span class="p">[</span><span class="n">count</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
    
    <span class="n">count</span><span class="o">+=</span><span class="mi">1</span>
        
<span class="c1">#threshold is 0.5</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print value after threshold</span>
<span class="n">pred2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[86]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0., 1., 1., ..., 0., 0., 0.])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print accuracy score, f1 score, precision, recall and classification report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1 score : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;precision score : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recall score : </span><span class="si">{0:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>accuracy : 0.8956
F1 score : 0.8966
precision score : 0.8888
recall score : 0.9045
              precision    recall  f1-score   support

           0       0.90      0.89      0.89     12500
           1       0.89      0.90      0.90     12500

    accuracy                           0.90     25000
   macro avg       0.90      0.90      0.90     25000
weighted avg       0.90      0.90      0.90     25000

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Plotting-model-performance">Plotting model performance<a class="anchor-link" href="#Plotting-model-performance">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#To see what out model stores info so that these can be plotted</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;val_loss&#39;: [0.4449035955667496, 0.3396933563947678, 0.3648205891251564, 0.326638181656599, 0.2887175160348415, 0.28176495325565337, 0.2765772679448128, 0.26885333260893823, 0.2709451336562633, 0.26571866223216056], &#39;val_acc&#39;: [0.7908400297164917, 0.8537200093269348, 0.8523200154304504, 0.8713600039482117, 0.8833600282669067, 0.8842399716377258, 0.8893600106239319, 0.8927199840545654, 0.894599974155426, 0.8956400156021118], &#39;loss&#39;: [0.602748440861702, 0.4264164352416992, 0.35930150574445724, 0.322038579583168, 0.29847083616256714, 0.27765644431114195, 0.25904917052388193, 0.24345125898718833, 0.23433869951963424, 0.22287024840712547], &#39;acc&#39;: [0.66032, 0.80552, 0.84636, 0.86336, 0.87488, 0.885, 0.89272, 0.90192, 0.903, 0.9114], &#39;lr&#39;: [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># plot model loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#plot model accuracies</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="AUC">AUC<a class="anchor-link" href="#AUC">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print AUC for train set</span>
<span class="n">aucs2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">auc2</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">prediction_train2</span><span class="p">)</span>
    <span class="n">aucs2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">aucs2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.984149616
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print AUC for test set</span>
<span class="n">aucs2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">auc2</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction_test2</span><span class="p">)</span>
    <span class="n">aucs2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">aucs2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.9623555615999999
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Some-predictions">Some predictions<a class="anchor-link" href="#Some-predictions">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Init value for that prediction</span>
<span class="n">n</span><span class="o">=</span><span class="mi">4</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_test shape = &quot;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#To see shape of X_test</span>

<span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>  <span class="c1">#Put test value in x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x = &quot;</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#AS you can see it is out of shape when comared to x_test because it is a single value therefore we need to reshape it</span>

<span class="n">x2</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">SEQ_LEN</span><span class="p">)</span> <span class="c1">#Reshape to (1,300) so to put in our model if not done this step it will throw error as our model accept this shape only</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New Shape of x = &quot;</span><span class="p">,</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#Cross check step to see our new shape</span>

<span class="n">P</span><span class="o">=</span><span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> <span class="c1">#predict x based on our model</span>

<span class="n">P2</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">P</span><span class="o">&gt;</span><span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1">#Setting threshold if value less than 0.5 it is -ve review otherwise poistive</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted review = &quot;</span><span class="p">,</span><span class="n">P2</span><span class="p">)</span> <span class="c1">#predicted review</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Actual value = &quot;</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X_test shape =  (25000, 300)
Shape of x =  (300,)
New Shape of x =  (1, 300)


Predicted review =  1
Actual value =  1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#This returns the decoded value by using above decoded function</span>
<span class="n">k</span><span class="o">=</span><span class="n">decode</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;START&gt; like some other people wrote i&#39;m a die hard mario fan and i loved this game br br this game starts slightly boring but trust me it&#39;s worth it as soon as you start your hooked the levels are fun and &lt;UNK&gt; they will hook you &lt;UNK&gt; your mind turns to &lt;UNK&gt; i&#39;m not kidding this game is also &lt;UNK&gt; and is beautifully done br br to keep this spoiler free i have to keep my mouth shut about details but please try this game it&#39;ll be worth it br br story 9 9 action 10 1 it&#39;s that good &lt;UNK&gt; 10 attention &lt;UNK&gt; 10 average 10 &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Note:">Note:<a class="anchor-link" href="#Note:">&#182;</a></h4><p>This model of LSTM with wts is best till now it has best performance without overfitting</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Retrive-the-output-of-each-layer-in-keras-for-a-given-single-test-sample-from-the-trained-model-you-built">Retrive the output of each layer in keras for a given single test sample from the trained model you built<a class="anchor-link" href="#Retrive-the-output-of-each-layer-in-keras-for-a-given-single-test-sample-from-the-trained-model-you-built">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="OUTPUT-FOR-NORMAL-SEQUENTIAL-MODEL">OUTPUT FOR NORMAL SEQUENTIAL MODEL<a class="anchor-link" href="#OUTPUT-FOR-NORMAL-SEQUENTIAL-MODEL">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Here you can see what all layers are used, shape of each layer an dtype</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor(&#34;embedding_2/embedding_lookup/Identity_1:0&#34;, shape=(?, 300, 50), dtype=float32)
Tensor(&#34;flatten_2/Reshape:0&#34;, shape=(?, ?), dtype=float32)
Tensor(&#34;dropout_3/cond/Merge:0&#34;, shape=(?, ?), dtype=float32)
Tensor(&#34;dense_3/BiasAdd:0&#34;, shape=(?, 10), dtype=float32)
Tensor(&#34;dropout_4/cond/Merge:0&#34;, shape=(?, 10), dtype=float32)
Tensor(&#34;dense_4/Sigmoid:0&#34;, shape=(?, 1), dtype=float32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n</span><span class="o">=</span><span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_test shape = &quot;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#To see shape of X_test</span>

<span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>  <span class="c1">#Put test value in x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x = &quot;</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#AS you can see it is out of shape when comared to x_test because it is a single value therefore we need to reshape it</span>

<span class="n">x2</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">SEQ_LEN</span><span class="p">)</span> <span class="c1">#Reshape to (1,300) so to put in our model if not done this step it will throw error as our model accept this shape only</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New Shape of x = &quot;</span><span class="p">,</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#Cross check step to see our new shape</span>

<span class="n">P</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> <span class="c1">#predict x based on our model</span>

<span class="n">P2</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">P</span><span class="o">&gt;</span><span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1">#Setting threshold if value less than 0.5 it is -ve review otherwise poistive</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted review&quot;</span><span class="p">,</span><span class="n">P2</span><span class="p">)</span> <span class="c1">#predicted review</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Actual review&quot;</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">n</span><span class="p">])</span> <span class="c1">#To compare pridicted result with actual result</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X_test shape =  (25000, 300)
Shape of x =  (300,)
New Shape of x =  (1, 300)
Predicted review 1
Actual review 1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#use this step to cross check output shape</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_2&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, 300, 50)           500000    
_________________________________________________________________
flatten_2 (Flatten)          (None, 15000)             0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 15000)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                150010    
_________________________________________________________________
dropout_4 (Dropout)          (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11        
=================================================================
Total params: 650,021
Trainable params: 650,021
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Here you can see I made use of keras backend to initliaze, It returns the output of each layer when invoked </span>
<span class="c1">#As the model is sequential I have to provide value to first layer and it will give output till final layer </span>
<span class="c1">#Here inside function you can see model.layer which are model layer followed by index which mean that particular layer, followed by the input which is the input to that layer or out is we will get output from that layer</span>
<span class="c1">#This is done for all layers that are in my model</span>
<span class="n">get_embed_out0</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out1</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out3</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out4</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out5</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Shape, type and length of each layer from embedding till dense final layer</span>
<span class="c1">#Here input is the x2(reshaped of x)</span>
<span class="c1">#This step gives us important details about the what shape each layers gives out</span>
<span class="n">layer_output0</span> <span class="o">=</span> <span class="n">get_embed_out0</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span> <span class="c1">#Init our input to above function and creating object of it similarly for rest</span>
<span class="n">layer_output1</span> <span class="o">=</span> <span class="n">get_embed_out1</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output2</span> <span class="o">=</span> <span class="n">get_embed_out2</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output3</span> <span class="o">=</span> <span class="n">get_embed_out3</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output4</span> <span class="o">=</span> <span class="n">get_embed_out4</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output5</span> <span class="o">=</span> <span class="n">get_embed_out5</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 1st i.e Flatten layer =   &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer_output0</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output0</span><span class="p">),</span> <span class="n">layer_output0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 2nd i.e Flatten layer =   &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer_output1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output1</span><span class="p">),</span> <span class="n">layer_output1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 3rd i.e 1st Dropout layer =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output2</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output2</span><span class="p">),</span> <span class="n">layer_output2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 4th i.e Dense layer =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output3</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output3</span><span class="p">),</span> <span class="n">layer_output3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 5th i.e 2nd Dropout layer =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output4</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output4</span><span class="p">),</span> <span class="n">layer_output4</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 6th i.e dense layer =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output5</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output5</span><span class="p">),</span> <span class="n">layer_output5</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>for layer 1st i.e Flatten layer =    &lt;class &#39;list&#39;&gt; 1 (1, 300, 50)
for layer 2nd i.e Flatten layer =    &lt;class &#39;list&#39;&gt; 1 (1, 15000)
for layer 3rd i.e 1st Dropout layer =    &lt;class &#39;list&#39;&gt; 1 (1, 15000)
for layer 4th i.e Dense layer =    &lt;class &#39;list&#39;&gt; 1 (1, 10)
for layer 5th i.e 2nd Dropout layer =    &lt;class &#39;list&#39;&gt; 1 (1, 10)
for layer 6th i.e dense layer =    &lt;class &#39;list&#39;&gt; 1 (1, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Output for all layers from embedding till dense final layer</span>
<span class="c1">#Here I have show each layer output based on our input value x2(reshaped of x)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For layer 1 i.e Embedding layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 2 i.e Flatten layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 3 i.e 1st Dropout layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 4 i.e Dense layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 5 i.e 2nd Dropout layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output4</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 6 i.e dense layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>For layer 1 i.e Embedding layer
[array([[[ 5.66664312e-05, -1.79680102e-02,  8.28240719e-03, ...,
          3.40049528e-03, -2.71884049e-03,  4.18313732e-03],
        [-7.95939714e-02,  1.58535223e-02, -1.65786128e-02, ...,
          7.43049458e-02, -2.50634663e-02,  4.92246076e-02],
        [-1.31525407e-02, -1.58749130e-02,  4.36166413e-02, ...,
          1.32223743e-03, -1.60870922e-03, -2.37565897e-02],
        ...,
        [ 6.48019984e-02,  6.91158175e-02, -4.78430912e-02, ...,
          6.13603331e-02,  3.37494463e-02,  1.21757602e-02],
        [-2.71052518e-03,  2.82813944e-02, -4.88941781e-02, ...,
         -1.83668882e-02,  1.02251165e-01, -3.11347526e-02],
        [-7.95939714e-02,  1.58535223e-02, -1.65786128e-02, ...,
          7.43049458e-02, -2.50634663e-02,  4.92246076e-02]]],
      dtype=float32)]


 For layer 2 i.e Flatten layer
[array([[ 5.6666431e-05, -1.7968010e-02,  8.2824072e-03, ...,
         7.4304946e-02, -2.5063466e-02,  4.9224608e-02]], dtype=float32)]


 For layer 3 i.e 1st Dropout layer
[array([[ 5.6666431e-05, -1.7968010e-02,  8.2824072e-03, ...,
         7.4304946e-02, -2.5063466e-02,  4.9224608e-02]], dtype=float32)]


 For layer 4 i.e Dense layer
[array([[ 1.4233767, -1.454182 , -1.2959054,  1.4426725, -1.083765 ,
         1.1942524,  1.4471122,  1.2649356,  0.784304 , -1.1838924]],
      dtype=float32)]


 For layer 5 i.e 2nd Dropout layer
[array([[ 1.4233767, -1.454182 , -1.2959054,  1.4426725, -1.083765 ,
         1.1942524,  1.4471122,  1.2649356,  0.784304 , -1.1838924]],
      dtype=float32)]


 For layer 6 i.e dense layer
[array([[0.99999976]], dtype=float32)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="OUTPUT-FOR-LSTM-MODEL-(with-pretrained-weights)">OUTPUT FOR LSTM MODEL (with pretrained weights)<a class="anchor-link" href="#OUTPUT-FOR-LSTM-MODEL-(with-pretrained-weights)">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Here you can see what all layers are used, shape of each layer an dtype</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor(&#34;embedding_5/embedding_lookup/Identity_1:0&#34;, shape=(?, 300, 100), dtype=float32)
Tensor(&#34;dropout_7/cond/Merge:0&#34;, shape=(?, 300, 100), dtype=float32)
Tensor(&#34;lstm_3/transpose_1:0&#34;, shape=(?, 300, 100), dtype=float32)
Tensor(&#34;global_max_pooling1d_3/Max:0&#34;, shape=(?, 100), dtype=float32)
Tensor(&#34;dense_7/Sigmoid:0&#34;, shape=(?, 1), dtype=float32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_test shape = &quot;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#To see shape of X_test</span>

<span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>  <span class="c1">#Put test value in x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x = &quot;</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#AS you can see it is out of shape when comared to x_test because it is a single value therefore we need to reshape it</span>

<span class="n">x2</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">SEQ_LEN</span><span class="p">)</span> <span class="c1">#Reshape to (1,300) so to put in our model if not done this step it will throw error as our model accept this shape only</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New Shape of x = &quot;</span><span class="p">,</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#Cross check step to see our new shape</span>

<span class="n">P</span><span class="o">=</span><span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> <span class="c1">#predict x based on our model</span>

<span class="n">P2</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">P</span><span class="o">&gt;</span><span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1">#Setting threshold if value less than 0.5 it is -ve review otherwise poistive</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted review&quot;</span><span class="p">,</span><span class="n">P2</span><span class="p">)</span> <span class="c1">#predicted review</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Actual review&quot;</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">n</span><span class="p">])</span> <span class="c1">#To compare pridicted result with actual result</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X_test shape =  (25000, 300)
Shape of x =  (300,)
New Shape of x =  (1, 300)
Predicted review 1
Actual review 1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#use this step to cross check output shape </span>
<span class="n">model2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_5&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_5 (Embedding)      (None, 300, 100)          1000000   
_________________________________________________________________
dropout_7 (Dropout)          (None, 300, 100)          0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 300, 100)          80400     
_________________________________________________________________
global_max_pooling1d_3 (Glob (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 101       
=================================================================
Total params: 1,080,501
Trainable params: 1,080,501
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Here you can see I made use of keras backend to initliaze, It returns the output of each layer when invoked </span>
<span class="c1">#As the model is sequential I have to provide value to first layer and it will give output till final layer </span>
<span class="c1">#Here inside function you can see model.layer which are model layer followed by index which mean that particular layer, followed by the input which is the input to that layer or out is we will get output from that layer</span>
<span class="c1">#This is done for all layers that are in my model</span>
<span class="n">get_embed_out0</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out1</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out3</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

<span class="n">get_embed_out4</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span>
    <span class="p">[</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Shape, type and length of each layer from embedding till dense final layer</span>
<span class="c1">#Here input is the x2(reshaped of x)</span>
<span class="c1">#This step gives us important details about the what shape each layers gives out</span>
<span class="n">layer_output0</span> <span class="o">=</span> <span class="n">get_embed_out0</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span> <span class="c1">#Init our input to above function and creating object of it similarly for rest </span>
<span class="n">layer_output1</span> <span class="o">=</span> <span class="n">get_embed_out1</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output2</span> <span class="o">=</span> <span class="n">get_embed_out2</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output3</span> <span class="o">=</span> <span class="n">get_embed_out3</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>
<span class="n">layer_output4</span> <span class="o">=</span> <span class="n">get_embed_out4</span><span class="p">([</span><span class="n">x2</span><span class="p">])</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 1st i.e Embedding layer =   &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer_output0</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output0</span><span class="p">),</span> <span class="n">layer_output0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 2nd i.e Dropout layer =   &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer_output1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output1</span><span class="p">),</span> <span class="n">layer_output1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 3rd i.e LSTM layer =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output2</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output2</span><span class="p">),</span> <span class="n">layer_output2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 4th i.e global_max_pooling1d =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output3</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output3</span><span class="p">),</span> <span class="n">layer_output3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;for layer 5th i.e Dense layer =   &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">layer_output4</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_output4</span><span class="p">),</span> <span class="n">layer_output4</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>for layer 1st i.e Embedding layer =    &lt;class &#39;list&#39;&gt; 1 (1, 300, 100)
for layer 2nd i.e Dropout layer =    &lt;class &#39;list&#39;&gt; 1 (1, 300, 100)
for layer 3rd i.e LSTM layer =    &lt;class &#39;list&#39;&gt; 1 (1, 300, 100)
for layer 4th i.e global_max_pooling1d =    &lt;class &#39;list&#39;&gt; 1 (1, 100)
for layer 5th i.e Dense layer =    &lt;class &#39;list&#39;&gt; 1 (1, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[110]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Output for all layers from embedding till dense final layer</span>
<span class="c1">#Here I have show each layer output based on our input value x2(reshaped of x)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For layer 1 i.e Embedding layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 2 i.e Dropout layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 3 i.e LSTM layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 4 i.e global_max_pooling1d&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> For layer 5 i.e Dense layer&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">layer_output4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>For layer 1 i.e Embedding layer
[array([[[ 0.04729347,  0.04208159,  0.04265385, ...,  0.06871387,
          0.05492609, -0.00377948],
        [-0.30647343,  0.78726465, -0.20184797, ..., -0.06453719,
          0.58388066,  0.5944857 ],
        [ 0.4920982 ,  0.21363993, -0.03415488, ..., -0.521059  ,
          0.84319484,  0.11655941],
        ...,
        [-0.18036468,  0.071647  ,  0.197794  , ..., -0.5258234 ,
          0.648752  ,  0.05700096],
        [-0.42847362,  0.41960958,  0.5360627 , ..., -0.20482133,
         -0.10294092,  0.2667207 ],
        [-0.30647343,  0.78726465, -0.20184797, ..., -0.06453719,
          0.58388066,  0.5944857 ]]], dtype=float32)]


 For layer 2 i.e Dropout layer
[array([[[ 0.04729347,  0.04208159,  0.04265385, ...,  0.06871387,
          0.05492609, -0.00377948],
        [-0.30647343,  0.78726465, -0.20184797, ..., -0.06453719,
          0.58388066,  0.5944857 ],
        [ 0.4920982 ,  0.21363993, -0.03415488, ..., -0.521059  ,
          0.84319484,  0.11655941],
        ...,
        [-0.18036468,  0.071647  ,  0.197794  , ..., -0.5258234 ,
          0.648752  ,  0.05700096],
        [-0.42847362,  0.41960958,  0.5360627 , ..., -0.20482133,
         -0.10294092,  0.2667207 ],
        [-0.30647343,  0.78726465, -0.20184797, ..., -0.06453719,
          0.58388066,  0.5944857 ]]], dtype=float32)]


 For layer 3 i.e LSTM layer
[array([[[ 0.00058593, -0.04326791, -0.00521626, ..., -0.02140813,
         -0.00674273, -0.01120373],
        [ 0.00579395, -0.05400041, -0.17517124, ..., -0.08464328,
         -0.08379809,  0.0207662 ],
        [ 0.13990936, -0.07573938, -0.2226643 , ..., -0.1520586 ,
          0.16098736,  0.0728052 ],
        ...,
        [-0.06268351, -0.03837064, -0.29780003, ..., -0.07628812,
         -0.2502994 , -0.06532285],
        [-0.04537094, -0.03457071, -0.13634764, ..., -0.05128488,
         -0.18292272, -0.04940049],
        [-0.05200253, -0.05093808, -0.28842887, ..., -0.13301402,
         -0.23665042, -0.02541872]]], dtype=float32)]


 For layer 4 i.e global_max_pooling1d
[array([[ 0.41327313,  0.03306616, -0.00521626,  0.15293595,  0.02784829,
         0.08256047,  0.5155799 , -0.02874551,  0.15717655, -0.02785311,
         0.01718166,  0.22874159,  0.30958277,  0.63073975,  0.4774018 ,
         0.5875051 ,  0.47188714,  0.609735  ,  0.00229769, -0.01533988,
        -0.01855648, -0.02612569, -0.02534891,  0.49740484,  0.02291668,
         0.46703544,  0.35225967, -0.02427171,  0.1638305 ,  0.00984725,
         0.28630912,  0.076772  ,  0.7755257 ,  0.2206463 ,  0.16526225,
         0.0246842 ,  0.05382042,  0.4097593 ,  0.15773004,  0.02800423,
         0.34634495,  0.7284284 ,  0.44941214,  0.86647594,  0.00835111,
         0.19448186,  0.47351173,  0.1584568 ,  0.07903234,  0.12237645,
         0.5128136 ,  0.1948194 ,  0.6489978 ,  0.63034415,  0.38938418,
         0.01978613,  0.38939694,  0.41222757,  0.15158711,  0.47917774,
         0.55224514, -0.00558464, -0.0038351 ,  0.01778492,  0.6903438 ,
         0.06080435,  0.6128018 ,  0.33289215,  0.53571373, -0.01980456,
         0.00205751, -0.03734275,  0.14059062,  0.5400655 ,  0.04458598,
         0.09469576,  0.4717455 ,  0.5476319 ,  0.6835195 ,  0.84632736,
         0.1065859 ,  0.06415015,  0.33098432, -0.02998896,  0.0112371 ,
         0.22641869,  0.02402317,  0.2876454 ,  0.8096525 ,  0.45610118,
         0.0177958 , -0.01430814,  0.05492949,  0.7739554 ,  0.76029444,
         0.59583926, -0.0079925 ,  0.28649294,  0.43417087,  0.0728052 ]],
      dtype=float32)]


 For layer 5 i.e Dense layer
[array([[0.97256833]], dtype=float32)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Conclusion:">Conclusion:<a class="anchor-link" href="#Conclusion:">&#182;</a></h1><p>I have performed various important steps in this project starting from EDA which helped me to know my dataset proper than I Done embedding step which include various sub step like creating different dictionary eg word2idx and idx2word also in in this I have created a function which maps the sequences back to word. Then next step comes is Model biluding step here I have created various model strating from normal Neural network dense model with sequence length of 20 then cearted sam emodel with 300 sequence length then performed grid search on that and prepared final model with improved hyperparameter with 300 sequence length but again the model was overfitting, Then I decided to make LSTM model with and withour pretrained word embeddings, the one with pretrained wts performed very well and I have also printed its results and predictions alsong with performance graph. At the end I have shown each layers output and output shape for lstm with pretrained wts and normal dense neural network with improved hyyperparameter. Also now I would finally conclude in production I would use LSTM with pretrained wts because it was giving great results without overfitting</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
